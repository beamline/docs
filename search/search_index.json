{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"Beamline <p>Streaming Process Mining</p> <p>Beamline is a framework meant to simplify the research and the development of streaming process mining, by providing a set of tools that can lift researchers from the burden of setting up streams and running experiments.</p> <p></p>"},{"location":"about/","title":"About","text":"<p>Beamline is a project developed at the Technical University of Denmark. For further information you can contact</p> <p>Andrea Burattin https://andrea.burattin.net andbur@dtu.dk</p> <p>People who contributed to the project:</p> <ul> <li>Lasse Starklit (DCR miner for JBeamline)</li> <li>Aleksander Jarmolkowicz (Split Miner for JBeamline)</li> <li>Magnus Frederiksen (initial core of pyBeamline)</li> <li>Jeppe Mikkelsen (Object Centric discovery for pyBeamline)</li> <li>Arturo Cortes (pyBeamline Designer)</li> <li>Sotero Romero (pyBeamline Designer)</li> <li>Mih\u00e1ly Tass (pyBeamline 2.0 architecture)</li> </ul>"},{"location":"about/#citation","title":"Citation","text":"<p>Please, cite this work as:</p> <p>Andrea Burattin. \"Beamline: A comprehensive toolkit for research and development of streaming process mining\". In Software Impacts, vol. 17 (2023).</p> BibTeX for citation <pre><code>@article{BURATTIN2023100551,\n  title = {Beamline: A comprehensive toolkit for research and development of streaming process mining},\n  journal = {Software Impacts},\n  volume = {17},\n  pages = {100551},\n  year = {2023},\n  issn = {2665-9638},\n  doi = {https://doi.org/10.1016/j.simpa.2023.100551},\n  url = {https://www.sciencedirect.com/science/article/pii/S266596382300088X},\n  author = {Andrea Burattin},\n  keywords = {Process mining, Streaming process mining, Apache Flink, Reactive programming},\n  abstract = {Beamline is a software library to support the research and development of streaming process mining algorithms. Specifically, it comprises a Java library, built on top of Apache Flink, which fosters high performance and deployment. The second component is a Python library (called pyBeamline, built using ReactiveX) which allows the quick prototyping and development of new streaming process mining algorithms. The two libraries share the same underlying data structures (BEvent) as well as the same fundamental principles, thus making the prototypes (built by researchers using pyBeamline) quickly transferrable to full-fledged and highly scalable applications (using Java Beamline).}\n}\n</code></pre> <p>Other relevant peer-review publication where the framework is presented:</p> <ul> <li>A. Cortes, S. Romero and A. Burattin. \"pyBeamline Designer: A No-Code Platform for Streaming Process Mining Pipelines\".In ICPM Doctoral Consortium and Demo Track 2025, October 20-24, 2025, Montevideo, Uruguay, CEUR Workshop Proceedings, 2025.</li> <li>A. Burattin. \"Streaming Process Mining with Beamline (Extended Abstract)\". In Proceedings of ICPM Doctoral Consortium and Tool Demonstration Track, CEUR Workshop Proceedings, 2022: 75-79. </li> <li>A. Burattin. \"Online Soft Conformance Checking: Any Perspective Can Indicate Deviations\". In arXiv:2201.09222, Jan. 2022.</li> <li>A. Burattin, H. A. L\u00f3pez, L. Starklit. \"Uncovering Change: A Streaming Approach for Declarative Processes. In Proceedings of 3rd International Workshop on Streaming Analytics for Process Mining (SA4PM); October 2022.</li> </ul> <p>Implemented techniques have corresponding citation information on their respective documentation page.</p>"},{"location":"intro/beamline-framework/","title":"Beamline Framework","text":"<p>Beamline is a framework designed to facilitate the prototyping and the development of streaming process mining algorithms.</p> <p>The framework comprises both Python and Java libraries: pyBeamline for Python JBeamline Java.</p> <p>pyBeamline is built on ReactiveX and its Python implementation, RxPY - a library for composing asynchronous, event-driven programs using observable sequences and pipable query operators. pyBeamline is suitable for prototyping algorithm very quickly, without necessarily bothering with performance aspects. It also simplifies collaboration by, for example, leveraging online notebook services (like Google Colab). JBeamline, the Java library, is designed on top of Apache Flink which makes it suitable for extremely efficient computation due to the distributed and stateful nature of its components.</p> <p>[py|J]Beamline consists of algorithms, data structures, sources, and sinks to facilitate the development of streaming process mining applications. While redefining the concept of event, Beamline tries to maintain compatibility with OpenXES and the IEEE XES standard.</p> <p> </p> <p>A complete Jupyter notebook presenting all techniques implemented in pyBeamline is available at https://github.com/beamline/pybeamline/blob/master/tutorial.ipynb.</p> <p>Deveolpment of JBeamline</p> <p>Currently the development of JBeamline is on hold whereas pyBeamline is under active development.</p>"},{"location":"intro/beamline-framework/#differences-between-pybeamline-and-jbeamline","title":"Differences between pyBeamline and JBeamline","text":"<p>The main difference between JBeamline and pyBeamline is the language they are built in (JBeamline is written in Java, pyBeamline is written in Python). However, differences do not stop here. In particular, JBeamline is built on top of Apache Flink, which makes it suitable for extremely efficient computation due to the distributed and stateful nature of its components. pyBeamline, on the other end, is built on top of ReactiveX which is</p> <p>an extension of the observer pattern to support sequences of data and/or events and adds operators that allow you to compose sequences together declaratively while abstracting away concerns about things like low-level threading, synchronization, thread-safety, concurrent data structures, and non-blocking I/O. (From https://reactivex.io/intro.html)</p> <p>Therefore, pyBeamline is suited for prototyping algorithm very quickly, without necessarily bothering with performance aspects. In a sense, it simplifies the construction of proof of concepts, before translating the algorithms into JBeamline for proper testing and verification. Also, it simplifies collaboration by, for example, leveraging online services (like Google Colab).</p> <p>To give an example of such simplicity, this is the complete code to discover a DFG using a sliding window from a stream generated from a <code>test.xes</code> file (a file is used instead of a proper stream, as we are in a very controlled setting):</p> <pre><code>from pybeamline.sources import xes_log_source_from_file\nfrom pybeamline.mappers import sliding_window_to_log\nfrom reactivex.operators import window_with_count\nfrom pm4py import discover_dfg_typed\n\nxes_log_source_from_file(\"test.xes\").pipe(\n    window_with_count(6),\n    sliding_window_to_log()\n).subscribe(lambda log: print(discover_dfg_typed(log)))\n</code></pre>"},{"location":"intro/beamline-framework/#on-the-name-beamline","title":"On the name \"Beamline\"","text":"<p>The term Beamline is borrowed from high energy physics, where it indicates the physical structure used to define experiments, i.e., where the accelerated particles travel. In the streaming process mining case, Beamline is used to set up experiments where process mining events are processed and consumed.</p> <p>Beamline comprises utility classes as well as some algorithms already implemented that can be used for comparing new techniques with the state of the art.</p>"},{"location":"intro/streaming-process-mining/","title":"Streaming process mining","text":"<p>Process mining is a well establish discipline, aiming at bridging data science and process science together, with the ultimate goal of improving processes and their corresponding executions.</p> <p>Classical process mining techniques take as input so-called event log files: static files containing executions to be analyzed. These event log files are typically structured as XML files according to the IEEE XES standard. These files contain events referring to a fixed period of time and, therefore, the results of the process mining analyses refer to the same time frame.</p> <p>In streaming process mining, the input is not a static file, but an event stream. As in event stream processing, in streaming process mining the goal is to analyze data immediately and update the analysis immediately.</p> <p>The picture below refers to the control-flow discovery case but, obviously, the same principle applies when conformance checking or enhancement algorithms are considered.</p> <p> </p> <p>Conceptualization of the streaming process discovery.</p> <p> Image adapted from: A. Burattin, A. Sperduti, and W. van der Aalst. Control- flow Discovery from Event Streams. In Proc. of IEEE WCCI-CEC, 2014.</p>"},{"location":"jbeamline/","title":"Getting Started","text":"<p>In this page JBeamline is presented.</p>"},{"location":"jbeamline/#hello-world-with-jbeamline","title":"Hello world with JBeamline","text":"<p>The following code represents a minimum running example that, once implemented in the <code>main</code> method of a Java class should provide some basic understanding of the concepts:</p> <pre><code>// step 1: configuration of the event source (in this case a static file, for reproducibility)\nXesLogSource source = new XesLogSource(\"log-file.xes\");\n\n// step 2: configuration of the algorithm\nDiscoveryMiner miner = new DiscoveryMiner();\nminer.setMinDependency(0.3);\n\n// step 3: construction of the dataflow from the environment\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv.addSource(source)\n   .keyBy(BEvent::getProcessName)\n   .flatMap(miner)\n   .addSink(new SinkFunction&lt;ProcessMap&gt;(){\n       public void invoke(ProcessMap value, Context context) throws Exception {\n           value.generateDot().exportToSvg(new File(\"output.svg\"));\n       };\n   });\n\n// step 4: consumption of the results\nenv.execute();\n</code></pre> <p>In step 1 the stream source is configured and, in this specific case, the stream is defined as coming from a static IEEE XES file.</p> <p>In step 2, an hypothetical miner is created and configured, using custom methods (such as the <code>setMinDependency</code> method).</p> <p>Step 3 consists of the definition of the chain of operations to be performed on each event of the stream. In this case, after the source is connected (<code>addSource</code>), we inform Flink that events can be distributed but all those that belong to the same process should be treated together (<code>keyBy</code>); then the events are <code>flatMap</code>ped - meaning that not all events will result in a mining result - by the miner; and finally a sink is connected to save the SVG map to file (<code>addSink</code>).</p> <p>In step 4, the defined pipeline is finally executed.</p>"},{"location":"jbeamline/basic-concepts/","title":"Basic concepts","text":"<p>In this page the basic concepts of the JBeamline framework are presented.</p>"},{"location":"jbeamline/basic-concepts/#streaming-dataflow","title":"Streaming dataflow","text":"<p>Each application based on Apache Flink relies on the concept of streaming dataflow. A streaming dataflow consists of the basic transformations applied to each event, from its origin (called source) until the end (called sink). In between, different operators can be chained together in order to transform the data according to the requirements. Once this pipeline of operations is defined, it can be deployed and Apache Flink will take care of the actual execution, including parallelizing possible operations and distributing the data across the network.</p> <p> </p> <p>Conceptualization of the streaming dataflow as operated by Apache Flink. Picture from https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/learn-flink/overview.   </p>"},{"location":"jbeamline/basic-concepts/#events","title":"Events","text":"<p>While Apache Flink can be designed to transmit any type of event, the JBeamline framework comes with its own definition of event, called <code>BEvent</code>. Here some of the corresponding methods are highlighted:</p>  classDiagram class BEvent {     +Map~String, Serializable~ processAttributes     +Map~String, Serializable~ traceAttributes     +Map~String, Serializable~ eventAttributes     +getProcessName(): String     +getTraceName(): String     +getEventName(): String     +getEventTime(): Date     +setProcessAttribute(String name, XAttribute value)     +setTraceAttribute(String name, XAttribute value)     +setEventAttribute(String name, XAttribute value) }  <p>Essentially, a JBeamline event, consists of 3 maps for attributes referring to the process, to the trace, and to the event itself. While it's possible to set all the attributes individually, some convenience methods are proposed as well, such as <code>getTraceName</code> which returns the name of the trace (i.e., the case id). Internally, a <code>BEvent</code> stores the basic information using as attribute names the same provided by the standard extension of OpenXES. Additionally, setters for attributes defined in the context of OpenXES are provided too, thus providing some level of interoperability between the platforms.</p> <p>Comparison with OpenXES</p> <p>While the usage of OpenXES has been considered, it has been decided that it is better to have a proper definition of event which embeds all information. This is due to the fact that in streaming processing each event is an atomic independent unit, i.e., it is not really possible to have collections of traces or collections of events part of the same happening.</p>"},{"location":"jbeamline/basic-concepts/#sources","title":"Sources","text":"<p>In the context of JBeamline it is possible to define sources to create any possible type of event. The framework comes with some sources already defined for the generation of <code>BEvent</code>s. The base class of all sources is called <code>BeamlineAbstractSource</code> which implements a <code>RichSourceFunction</code>. In Apache Flink, a \"rich\" function is a function which can have access to the distributed state and thus become stateful. Sources already implemented are <code>XesLogSource</code>, <code>MQTTXesSource</code>, <code>CSVLogSource</code>, and <code>StringTestSource</code>. A <code>XesLogSource</code> creates a source from a static log (useful for testing purposes). An <code>MQTTXesSource</code> generates an source from an MQTT-XES stream. <code>CSVLogSource</code> is a source which reads events from a text file, and <code>StringTestSource</code> allows the definition of simple log directly in its constructor (useful for testing purposes). The class diagram of the observable sources available in JBeamline Framework is reported below:</p>  classDiagram RichSourceFunction~OUT~ &lt;|-- BeamlineAbstractSource : \u00abbind\u00bb OUT\ua789\ua789BEvent BeamlineAbstractSource &lt;|.. XesLogSource BeamlineAbstractSource &lt;|.. CSVLogSource BeamlineAbstractSource &lt;|.. MQTTXesSource BeamlineAbstractSource &lt;|.. StringTestSource RichSourceFunction : +run(SourceContext~OUT~ ctx) void  &lt;&lt; abstract &gt;&gt; RichSourceFunction BeamlineAbstractSource  <p>In order to use any source, it is possible to provide it to the <code>addSource</code> method: <pre><code>BeamlineAbstractSource source = ...\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nDataStream&lt;BEvent&gt; stream = env.addSource(source);\n// add all other transformation operators here...\nenv.execute();\n</code></pre></p> Details on <code>XesLogSource</code> <p>Emits all events from an XES event log. Example usage: <pre><code>XLog l = ...\nXesLogSource source = new XesLogSource(l);\n</code></pre> Or, alternatively, providing directly the path to the log file: <pre><code>XesLogSource source = new XesLogSource(\"path/to/log.xes\"); // any file format supported by OpenXES can be used\n</code></pre></p> Details on <code>CSVLogSource</code> <p>Emits all events from a CSV file, column numbers for case id and activity name must be provided in the constructor. Example usage: <pre><code>int caseIdColumn = 0;\nint activityColumn = 1;\nCSVLogSource source = new CSVLogSource(\"filename.csv\", caseIdColumn, activityColumn);\n</code></pre> Additional configuration parameters can be provided, like the separator: <pre><code>CSVLogSource source = new CSVLogSource(\n    \"filename.csv\",\n    caseIdColumn,\n    activityColumn,\n    new CSVLogSource.ParserConfiguration().withSeparator('|'));\n</code></pre></p> Details on <code>MQTTXesSource</code> <p>Forwards all events on an MQTT broker respecting the MQTT-XES protocol. Example usage: <pre><code>MQTTXesSource source = new MQTTXesSource(\"tcp://broker.hivemq.com:1883\", \"root\", \"processName\");\nsource.prepare();\n</code></pre></p> Details on <code>StringTestSource</code> <p>Source that considers each trace as a string provided in the constructor and each event as one character of the string. Example usage: <pre><code>StringTestSource s = new StringTestSource(\"ABC\", \"ADCE\");\n</code></pre> This source is going to emit 7 events as part of 2 traces.</p>"},{"location":"jbeamline/basic-concepts/#filters","title":"Filters","text":"<p>The filter operators, in Apache Flink, do not change the type of  stream, but filters the events so that only those passing a predicate test can pass. In JBeamline there are some filters already implemented that can be used as follows:</p> <pre><code>BeamlineAbstractSource source = ...\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .filter(new RetainActivitiesFilter(\"A\", \"B\", \"C\"))\n    // add all other transformation operators here...\nenv.execute();\n</code></pre> <p>In line 5 a filter is specified so that only events referring to activities <code>A</code>, <code>B</code>, and <code>C</code> are maintained (while all others are discarded).</p> <p>Filters can operate on event attributes or trace attributes and the following are currently available:</p> Details on <code>RetainOnEventAttributeEqualityFilter</code> <p>Retains events based on the equality of an event attribute. Example: <pre><code>FilterFunction filter = new RetainOnEventAttributeEqualityFilter&lt;String&gt;(\"attribute-name\", \"v1\", \"v2\");\n</code></pre></p> Details on <code>ExcludeOnEventAttributeEqualityFilter</code> <p>Exclude events based on the equality of an event attribute. <pre><code>FilterFunction filter = new ExcludeOnEventAttributeEqualityFilter&lt;String&gt;(\"attribute-name\", \"v1\", \"v2\");\n</code></pre></p> Details on <code>RetainOnCaseAttributeEqualityFilter</code> <p>Retains events based on the equality of a trace attribute. <pre><code>FilterFunction filter = new RetainOnCaseAttributeEqualityFilter&lt;String&gt;(\"attribute-name\", \"v1\", \"v2\");\n</code></pre></p> Details on <code>ExcludeOnCaseAttributeEqualityFilter</code> <p>Excludes events based on the equality of a trace attribute. <pre><code>FilterFunction filter = new ExcludeOnCaseAttributeEqualityFilter&lt;String&gt;(\"attribute-name\", \"v1\", \"v2\");\n</code></pre></p> Details on <code>RetainActivitiesFilter</code> <p>Retains activities base on their name (<code>concept:name</code>). <pre><code>FilterFunction filter = new RetainActivitiesFilter(\"act-1\", \"act2\");\n</code></pre></p> Details on <code>ExcludeActivitiesFilter</code> <p>Excludes activities base on their name (<code>concept:name</code>). <pre><code>FilterFunction filter = new ExcludeActivitiesFilter(\"act-1\", \"act2\");\n</code></pre></p> <p>Please note that filters can be chained together in order to achieve the desired result.</p>"},{"location":"jbeamline/basic-concepts/#mining-algorithms","title":"Mining algorithms","text":"<p>A mining algorithm is a <code>flatMap</code>er consuming events generated from a source. All mining algorithms must extend the abstract class <code>StreamMiningAlgorithm</code>. This class is structured as:</p>  classDiagram class RichFlatMapFunction~IN, OUT~ class StreamMiningAlgorithm~T extends Response~ &lt;&lt; abstract &gt;&gt; StreamMiningAlgorithm StreamMiningAlgorithm:+ingest(BEvent event)* T StreamMiningAlgorithm:+getProcessedEvents() long  &lt;&lt; abstract &gt;&gt; RichFlatMapFunction  RichFlatMapFunction &lt;|-- StreamMiningAlgorithm : \u00abbind\u00bb IN\ua789\ua789BEvent  <p>The generic types <code>T</code> refers to the type of the generated output (i.e., the result of the mining algorithm). The only abstract method that needs to be implemented by a mining algorithm is <code>ingest(BEvent event) : K</code> which receives an event as actual parameter and returns the result of the ingestion of the event as value or the special value <code>null</code>. If <code>null</code> is returned, nothing will be propagated down to the pipeline, for example, it might not be interesting to mine a process for each event observed, but maybe every 100 events (and thus the reason for having a <code>flatMap</code>). The other method offered is <code>getProcessedEvents() : long</code> that returns the number of events processed up to now.</p> <p>Since a <code>StreamMiningAlgorithm</code> is a \"rich\" function, it is possible to have access to the status information. Additionally, since this operator might be distributed, it is necessary to apply it on a keyed stream. A key can be used to split the stream into independent \"branches\" that can be processed in parallel by different instances of the operators occurring afterwards. It is therefore extremely important to choose wisely how to key a stream. Instances of the same operator that are applied on different \"branches\" (obtained by keying the stream) cannot communicate between each other. Examples of keys in different contexts:</p> <ul> <li>If the goal is to perform control-flow discovery, probably it is necessary to key the stream based on the process name (using <code>keyBy(BEvent::getProcessName)</code>): all events that belong to the same process should be considered by the same instance of the mining algorithm to extract the same process;</li> <li>If the goal is to perform conformance checking, probably it is enough to key the stream based on the process instance (a.k.a., trace name or case id; using <code>keyBy(BEvent::getTraceName)</code>): in a streaming context, each trace is independent from the others with respect to the goal of calculating their conformance, and hence there is no need to share information regarding the whole process.</li> </ul> <p>At the core of the JBeamline library there is only one mining algorithm implemented (though other are available as additional dependencies):</p> Details on <code>InfiniteSizeDirectlyFollowsMapper</code> <p>An algorithm that transforms each pair of consequent event appearing in the same case as a directly follows operator (generating an object with type <code>DirectlyFollowsRelation</code>). This mapper is called infinite because it's memory footprint will grow as the case ids grow. The mapper produces results as <code>DirectlyFollowsRelation</code>s.</p> <p>An example of how the algorithm can be used is the following:</p> <pre><code>BeamlineAbstractSource source = ...\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .keyBy(BEvent::getProcessName)\n    .flatMap(new InfiniteSizeDirectlyFollowsMapper())\n    .addSink(new SinkFunction&lt;DirectlyFollowsRelation&gt;() {\n        public void invoke(ProcessMap value, Context context) throws Exception {\n            System.out.println(value.getFrom() + \" -&gt; \" + value.getTo());\n        };\n    });\nenv.execute();\n</code></pre>"},{"location":"jbeamline/basic-concepts/#responses","title":"Responses","text":"<p>Responses are produced by miners as events are processed. Currently, JBeamline supports an empty <code>Response</code> class which might be extended to custom behavior as well as a Graphviz graphical representation in a <code>GraphvizResponse</code> abstract class and some others. On all <code>Response</code> objects it is possible to invoke the <code>getProcessedEvents()</code> method, which indicates how many events that response has processed. Hence this is the hierarchy of results:</p>  classDiagram class Response &lt;&lt; abstract &gt;&gt; Response Response : getProcessedEvents() long  class StringResponse StringResponse : get() String  class GraphvizResponse &lt;&lt; abstract &gt;&gt; GraphvizResponse GraphvizResponse : generateDot()* Dot  class DirectlyFollowsRelation DirectlyFollowsRelation : getCaseId() String DirectlyFollowsRelation : getFrom() BEvent DirectlyFollowsRelation : getTo() BEvent  Response &lt;|-- StringResponse Response &lt;|-- DirectlyFollowsRelation Response &lt;|-- GraphvizResponse  <p>An example of a way to consume these results is reported in the following code:</p> <pre><code>BeamlineAbstractSource source = ...\nDiscoveryMiner miner = new DiscoveryMiner();\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner)\n    .addSink(new SinkFunction&lt;GraphvizResponse&gt;() {\n        public void invoke(GraphvizResponse value, Context context) throws Exception {\n            value.generateDot().exportToSvg(new File(\"output-\" + value.getProcessedEvents() + \".svg\"));\n        };\n    });\nenv.execute();\n</code></pre> <p>In this code, we assume the existence of a miner called <code>DiscoveryMiner</code> which produces output as an object with (sub)type <code>GraphvizResponse</code>.</p>"},{"location":"jbeamline/installation/","title":"Installation","text":"<p>To use JBeamline in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the package repository: <pre><code>&lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;jitpack.io&lt;/id&gt;\n        &lt;url&gt;https://jitpack.io&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n</code></pre> Then you can include the dependency to the version you are interested, for example: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;framework&lt;/artifactId&gt;\n    &lt;version&gt;x.y.z&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See https://jitpack.io/#beamline/framework for further details (e.g., using it with Gradle).</p>"},{"location":"jbeamline/mqtt-xes/","title":"MQTT-XES","text":"<p>MQTT-XES is a lightweight library for real-time logging over MQTT, for process mining purposes.  The MQTT-XES library is described in the corresponding paper:</p> <ul> <li>MQTT-XES: Real-time Telemetry for Process Event Data A. Burattin, M. Eigenmann, R. Seiger, B. Weber In Online Proceedings of the BPM Demo Track 2020; Sevilla, Spain; September, 13-18 2020; CEUR-WS.org 2020.</li> </ul>"},{"location":"jbeamline/mqtt-xes/#installing-the-library","title":"Installing the library","text":"<p>To use the library in your Maven project it is necessary to include, in the <code>pom.xml</code> file, the package repository: <pre><code>&lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;jitpack.io&lt;/id&gt;\n        &lt;url&gt;https://jitpack.io&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n</code></pre> Then you can include the dependency to the version you are interested, for example: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;mqtt-xes&lt;/artifactId&gt;\n    &lt;version&gt;0.3.5&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See https://jitpack.io/#beamline/mqtt-xes for further details (e.g., using it with Gradle).</p>"},{"location":"jbeamline/mqtt-xes/#sending-events","title":"Sending events","text":"<p>To generate events to be sent using MQTT-XES it is possible to use the following code snippet, first to create the client: <pre><code>XesMqttProducer client = new XesMqttProducer(\"broker.hivemq.com\", \"BASE\");\n</code></pre> It is also necessary to create the event that has to be sent: <pre><code>XesMqttEvent event = new XesMqttEvent(\"source-id\", \"case-id\", \"activity\")\n    .addTraceAttribute(\"name\", \"value\")\n    .addEventAttribute(\"name\", \"value\");\n</code></pre> Finally, it is possible to send the event using the client object previously defined: <pre><code>client.connect();\nclient.send(event);\nclient.disconnect();\n</code></pre></p>"},{"location":"jbeamline/mqtt-xes/#consuming-events","title":"Consuming events","text":"<p>To consume events, it is first necessary to create a consumer client, using the following code snippet: <pre><code>XesMqttConsumer client = new XesMqttConsumer(\"broker.hivemq.com\", \"BASE\");\n</code></pre> Once the client is set, it is possible to subscribe to the MQTT-XES events being sent and a callback class need to be provided. Please note that the <code>accept</code> method of <code>XesMqttEventCallback</code> receives a XesMqttEvent: <pre><code>client.subscribe(new XesMqttEventCallback() {\n    @Override\n    public void accept(XesMqttEvent e) {\n        System.out.println(e.getProcessName() + \" - \" + e.getCaseId() + \" - \" + e.getActivityName());\n    }\n});\n</code></pre></p>"},{"location":"jbeamline/simple-pnml/","title":"Simple PNML","text":"<p><code>simple-pnml</code> is a library to describe Petri nets and [de]serialize them as PNML XML files.</p> <p>Attention: this library is actually the porting of the ProM PetriNets package, which has been isolated out of the ProM environment and has been made available as Maven dependency. Therefore, the authors of this simple-pnml library are the authors of the ProM version of the PetriNets package (module some changes made by Andrea Burattin for isolating the library from ProM and making it self-contained). The ProM package PetriNets is licensed as L-GPL so this distribution is as well. The original source code of the ProM PetriNets package is located at https://svn.win.tue.nl/repos/prom/Packages/PetriNets/. The ProM packages licenses are discussed in http://www.promtools.org/doku.php?id=packlicense and for general information on ProM you can visit http://www.promtools.org/.</p>"},{"location":"jbeamline/simple-pnml/#installing-the-library","title":"Installing the library","text":"<p>To use the library in your Maven project it is necessary to include, in the <code>pom.xml</code> file, the package repository: <pre><code>&lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;jitpack.io&lt;/id&gt;\n        &lt;url&gt;https://jitpack.io&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n</code></pre> Then you can include the dependency to the version you are interested, for example: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;simple-pnml&lt;/artifactId&gt;\n    &lt;version&gt;0.0.1&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See https://jitpack.io/#beamline/simple-pnml for further details (e.g., using it with Gradle).</p>"},{"location":"jbeamline/simple-pnml/#importing-a-petri-net-from-a-pnml-file","title":"Importing a Petri net from a PNML file","text":"<p>To import a Petri net from a PNML file you can use the following code:</p> <pre><code>Object[] i = PnmlImportNet.importFromStream(new FileInputStream(new File(\"file.pnml\")));\n\nPetrinet net = (Petrinet) i[0];\nMarking marking = (Marking) i[1];\n</code></pre>"},{"location":"jbeamline/simple-pnml/#importing-a-petri-net-from-a-tpn-file","title":"Importing a Petri net from a TPN file","text":"<p>To import a Petri net from a TPN file you can use the following code:</p> <pre><code>Object[] i = TpnImport.importFromStream(new FileInputStream(new File(\"file.tpn\")));\n\nPetrinet net = (Petrinet) i[0];\nMarking marking = (Marking) i[1];\n</code></pre>"},{"location":"jbeamline/simple-pnml/#exporting-a-petri-net-into-a-pnml-file","title":"Exporting a Petri net into a PNML file","text":"<p>To export a Petri net into a PNML file you can use the following code:</p> <pre><code>Petrinet net = ...;\nMarking marking = ...;\n\nPnmlExportNetToPNML.exportPetriNetToPNMLFile(net, marking, new File(\"file.pnml\"));\n</code></pre>"},{"location":"jbeamline/examples/monitoring-windows/","title":"Monitoring active windows (for Windows systems)","text":"<p>One possible usage of streaming process mining could involve the monitoring of the current system. One possible way of achieving this goal is to monitor the window currently active (i.e., with the focus) as a proxy for the application being used by the user<sup>1</sup>.</p> <p>To achieve this goal it is possible to define a new <code>XesSource</code> which observes the windows currently active and, whenever there is a new window in focus, emits an event. To accomplish this goal, in the following we make use of the JNA (Java Native Access) library which gives us access to the native shared libraries of the operating system. To have access to the library we need, first of all, to include it in our Maven dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;net.java.dev.jna&lt;/groupId&gt;\n    &lt;artifactId&gt;jna&lt;/artifactId&gt;\n    &lt;version&gt;5.10.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;net.java.dev.jna&lt;/groupId&gt;\n    &lt;artifactId&gt;jna-platform&lt;/artifactId&gt;\n    &lt;version&gt;5.10.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre></p> <p>Once the library is include we can define the method that will return the name of the currently active window on the screen (this works and has been tested on Windows 10 Enterprise):</p> <p><pre><code>class Informer {\n    public static String getWindowName() {\n        int MAX_TITLE_LENGTH = 1024;\n        char[] buffer = new char[MAX_TITLE_LENGTH * 2];\n        HWND hwnd = User32.INSTANCE.GetForegroundWindow();\n        User32.INSTANCE.GetWindowText(hwnd, buffer, MAX_TITLE_LENGTH);\n\n        IntByReference pid = new IntByReference();\n        User32.INSTANCE.GetWindowThreadProcessId(hwnd, pid);\n        HANDLE p = Kernel32.INSTANCE.OpenProcess(\n                Kernel32.PROCESS_QUERY_INFORMATION | Kernel32.PROCESS_VM_READ,\n                false,\n                pid.getValue());\n        Psapi.INSTANCE.GetModuleBaseNameW(p, null, buffer, MAX_TITLE_LENGTH);\n\n        return Native.toString(buffer);\n    }\n\n    public interface Psapi extends StdCallLibrary {\n        @SuppressWarnings(\"deprecation\")\n        Psapi INSTANCE = (Psapi) Native.loadLibrary(\"Psapi\", Psapi.class);\n        WinDef.DWORD GetModuleBaseNameW(HANDLE hProcess, HANDLE hModule, char[] lpBaseName, int nSize);\n    }\n}\n</code></pre> The documentation on the system calls used here can be found on the MSDN documentation (here, for example, the documentation for the <code>GetForegroundWindow</code> function).</p> <p>With this information it is now possible to wrap the code in a proper source: <pre><code>public class WindowsWindowMonitorSource implements BeamlineAbstractSource {\n\n   private static final int POLLING_DELAY = 100; // milliseconds between checks of the active window\n\n   @Override\n   public void run(SourceContext&lt;BEvent&gt; ctx) throws Exception {\n      Queue&lt;BEvent&gt; buffer = new LinkedList&lt;&gt;();\n\n      String caseId = UUID.randomUUID().toString();\n      new Thread(new Runnable() {\n         @Override\n         public void run() {\n            String latestProcess = \"\";\n            while(isRunning()) {\n               String currentProcess = getWindowName();\n               if (!currentProcess.isEmpty() &amp;&amp; !currentProcess.equals(latestProcess)) {\n                  latestProcess = currentProcess;\n                  try {\n                     buffer.add(BEvent.create(\"window\", caseId, currentProcess));\n                  } catch (EventException e) { }\n               }\n\n               try {\n                  Thread.sleep(POLLING_DELAY);\n               } catch (InterruptedException e) { }\n            }\n         }\n      }).start();\n\n      while(isRunning()) {\n         while (isRunning() &amp;&amp; buffer.isEmpty()) {\n            Thread.sleep(100l);\n         }\n         if (isRunning()) {\n            synchronized (ctx.getCheckpointLock()) {\n               BEvent e = buffer.poll();\n               ctx.collect(e);\n            }\n         }\n      }\n   }\n}\n</code></pre> The basic idea is to check every <code>POLLING_DELAY</code> milliseconds for the name of the window currently on focus and, if this has changed, then a new event is published.</p> <p>An example run of the application utilizing the Trivial Miner and the following code: <pre><code>public class WindowsWindowMonitor {\n   public static void main(String[] args) throws Exception {\n      StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n      env\n         .addSource(new WindowsWindowMonitorSource())\n         .keyBy(BEvent::getProcessName)\n         .flatMap(new DirectlyFollowsDependencyDiscoveryMiner().setModelRefreshRate(1).setMinDependency(0))\n         .addSink(new SinkFunction&lt;ProcessMap&gt;(){\n            public void invoke(ProcessMap value, Context context) throws Exception {\n               value.generateDot().exportToSvg(new File(\"src/main/resources/output/output.svg\"));\n            };\n         });\n      env.execute();\n   }\n}\n</code></pre></p> <p>Produces the following map:</p> G e3e9b1010-99f2-42f2-9a8b-b87c95a37494-&gt;e886f2ff8-9c79-453a-b67e-a8ab38501ee0  1.0 (1) e3e9b1010-99f2-42f2-9a8b-b87c95a37494-&gt;ef91712ff-1664-431b-9547-561693db89c9  1.0 (1) e98d60a8f-7389-47c7-aea3-7b135deb82db-&gt;e3e9b1010-99f2-42f2-9a8b-b87c95a37494  1.0 (1) e886f2ff8-9c79-453a-b67e-a8ab38501ee0-&gt;e98d60a8f-7389-47c7-aea3-7b135deb82db  1.0 (1) e3c37b245-6359-445f-b594-77d60b1ea9c8-&gt;e3e9b1010-99f2-42f2-9a8b-b87c95a37494  1.0 (1) ef91712ff-1664-431b-9547-561693db89c9-&gt;e3e9b1010-99f2-42f2-9a8b-b87c95a37494  1.0 (1) ef949dfe4-9d22-4d8e-8a7a-04df7737f67d-&gt;e3c37b245-6359-445f-b594-77d60b1ea9c8 e3e9b1010-99f2-42f2-9a8b-b87c95a37494 eclipse.exe 1.0 (3) e98d60a8f-7389-47c7-aea3-7b135deb82db OUTLOOK.EXE 0.33 (1) e886f2ff8-9c79-453a-b67e-a8ab38501ee0 explorer.exe 0.33 (1) e3c37b245-6359-445f-b594-77d60b1ea9c8 chrome.exe 0.33 (1) ef91712ff-1664-431b-9547-561693db89c9 cmd.exe 0.33 (1) ef949dfe4-9d22-4d8e-8a7a-04df7737f67d <p>The complete code of this example is available in the GitHub repository https://github.com/beamline/examples/tree/master/src/main/java/beamline/examples/windowsWindowMonitor.</p> <ol> <li> <p>It is important to emphasize that the active window might not really be the one that the user is currently using. For example, a user might be reading a webpage in a browser or a PDF document or another text document while having active another window.\u00a0\u21a9</p> </li> </ol>"},{"location":"jbeamline/examples/no-process-mining-as-input/","title":"Raw data as input (non-process mining ready)","text":"<p>Let's say we have a certain file that we want to consider for processing using Beamline but this file does not meet any of the sources already implemented. Then, this example shows how to process such a file using Beamline.</p> <p>For the sake of simplicity let's consider a file where each line refers to one event but, within the line, the first 3 characters identify the case id, while the rest is the activity name. This is an example of such a file (where <code>001</code> and <code>002</code> are the case ids, and <code>ActA</code>, <code>B</code> and <code>Act_C</code> are the activity names):</p> <pre><code>002ActA\n001ActA\n002B\n002Act_C\n001B\n001Act_C\n</code></pre> <p>To accomplish our goal, we need first to define a source capable of processing the file: <pre><code>BeamlineAbstractSource customSource = new BeamlineAbstractSource() {\n   @Override\n   public void run(SourceContext&lt;BEvent&gt; ctx) throws Exception {\n      Files.lines(Path.of(logFile)).forEach(line -&gt; {\n         String caseId = line.substring(0, 3);\n         String activityName = line.substring(3);\n\n         try {\n            ctx.collect(BEvent.create(\"my-process-name\", caseId, activityName));\n         } catch (EventException e) { }\n      });\n   }\n};\n</code></pre></p> <p>Now, a stream of <code>BEvent</code>s is available and can be processed with any miner available, for example, using the Trivial discovery miner:</p> <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n   .addSource(customSource)\n   .keyBy(BEvent::getProcessName)\n   .flatMap(new DirectlyFollowsDependencyDiscoveryMiner().setModelRefreshRate(1).setMinDependency(0.1))\n   .addSink(new SinkFunction&lt;ProcessMap&gt;() {\n      @Override\n      public void invoke(ProcessMap value, Context context) throws Exception {\n         value.generateDot().exportToSvg(new File(\"src/main/resources/output/output.svg\"));\n      };\n   });\nenv.execute();\n</code></pre> <p>In this case, we configured the miner to consume all events and, once the stream is completed (in this case we do know that the stream will terminate) we dump the result of the miner into a file <code>output.svg</code> which will contain the following model:</p> G e6def0aa8-a25c-48d9-8be2-b6873af41849-&gt;e6fd0d0c8-9bf8-41b4-b32c-27d996d529ec  1.0 (2) e6fd0d0c8-9bf8-41b4-b32c-27d996d529ec-&gt;efed7b698-4a16-44d5-99db-2afa47a4c8e4  1.0 (2) efed7b698-4a16-44d5-99db-2afa47a4c8e4-&gt;e05520936-aa17-4739-bad0-7d560003a923 ef4d5585f-76e4-451b-badf-d504407d9581-&gt;e6def0aa8-a25c-48d9-8be2-b6873af41849 e6def0aa8-a25c-48d9-8be2-b6873af41849 ActA 1.0 (2) e6fd0d0c8-9bf8-41b4-b32c-27d996d529ec B 1.0 (2) efed7b698-4a16-44d5-99db-2afa47a4c8e4 Act_C 1.0 (2) ef4d5585f-76e4-451b-badf-d504407d9581 e05520936-aa17-4739-bad0-7d560003a923 <p>The complete code of this example is available in the GitHub repository https://github.com/beamline/examples/tree/master/src/main/java/beamline/examples/rawData.</p>"},{"location":"jbeamline/examples/open-sky-monitoring/","title":"OpenSky monitoring","text":"<p>OpenSky Network is a non profit project which:</p> <p>[...] consists of a multitude of sensors connected to the Internet by volunteers, industrial supporters, and academic/governmental organizations. All collected raw data is archived in a large historical database. The database is primarily used by researchers from different areas to analyze and improve air traffic control technologies and processes.</p> <p>-- Description from https://opensky-network.org/about/about-us</p> <p>Essentially, each airplane uses a transponder to transmit data regarding their status (squawk) as well as their callsign and current position. All this information is collected by OpenSky Network and made available though their APIs.</p> <p>The underlying idea of this example is that each flight (i.e., an airplane callsign) represents the instance of a flight process. The different squawks a plane goes through indicate the activities involved in the process.</p> <p>To achieve this goal, it is necessary to write a new source which periodically queries the OpenSky Network APIs to retrieve the live status of airplanes in a certain area. First it's necessary to create the actual source and initialize the <code>OpenSkyApi</code> wrapper: <pre><code>public class OpenSkySource extends BeamlineAbstractSource {\n    private OpenSkyApi api;\n\n    @Override\n    public void open(Configuration parameters) throws Exception {\n        Properties prop = new Properties();\n        prop.load(new FileInputStream(\"./openskyCredentials.properties\"));\n        api = new OpenSkyApi(prop.getProperty(\"USERNAME\"), prop.getProperty(\"PASSWORD\"));\n    }\n</code></pre> Please note that in this case we use the Java API (imported from JitPack) and we assume the presence of a file <code>openskyCredentials.properties</code> containing username and password for accessing the APIs.</p> <p>Once the system is properly connected to the APIs, then in the <code>run</code> method it is possible to define a separate thread in charge of querying the APIs every 15 seconds and put the events into a buffer which is then used for dispatching them. In the case highlighted the APIs are queried to retrieve flights over the central Europe (lines 19-20). In addition the squawks are parsed to provide some more understandable interpretation (according to the interpretation reported here https://www.flightradars.eu/squawkcodes.html, the actual code of method <code>squawkToString</code> is omitted in this page but is available on the GitHub repository).</p> <pre><code>    @Override\n    public void run(SourceContext&lt;BEvent&gt; ctx) throws Exception {\n        Queue&lt;BEvent&gt; buffer = new LinkedList&lt;&gt;();\n\n        new Thread(() -&gt; {\n            while(isRunning()) {\n                try {\n                    OpenSkyStates os = api.getStates(0, null,\n                        new OpenSkyApi.BoundingBox(\n                            35.0518857, 62.4097744,\n                            -5.8468354, 34.3186395));\n                    if (os != null) {\n                        for (StateVector sv : os.getStates()) {\n                            try {\n                                if (!sv.getCallsign().isBlank()) {\n                                    buffer.add(\n                                        BEvent.create(\n                                            \"squawk\",\n                                            sv.getCallsign().trim(),\n                                            squawkToString(sv.getSquawk())));\n                                }\n                            } catch (EventException e) {\n                                e.printStackTrace();\n                            }\n                        }\n                    } else {\n                        System.out.println(\"No new information...\");\n                    }\n                    Thread.sleep(15000l);\n                } catch (Exception e) {\n                    // nothing to see here\n                    e.printStackTrace();\n                }\n            }\n        }).start();\n\n        while(isRunning()) {\n            while (isRunning() &amp;&amp; buffer.isEmpty()) {\n                Thread.sleep(100l);\n            }\n            if (isRunning()) {\n                synchronized (ctx.getCheckpointLock()) {\n                    BEvent e = buffer.poll();\n                    ctx.collect(e);\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>A simple consumer, in this case the Trivial discovery miner, can then be attached to the source with: <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n   .addSource(new OpenSkySource())\n   .keyBy(BEvent::getProcessName)\n   .flatMap(new DirectlyFollowsDependencyDiscoveryMiner().setModelRefreshRate(10).setMinDependency(0))\n   .addSink(new SinkFunction&lt;ProcessMap&gt;(){\n      public void invoke(ProcessMap value, Context context) throws Exception {\n         value.generateDot().exportToSvg(new File(\"src/main/resources/output/output.svg\"));\n      };\n   });\nenv.execute();\n</code></pre></p> <p>After running the system for about a few minutes, the following map was produced, where essentially only transit squawks were observed:</p> G eec7010c0-450a-418f-b0be-fa2d42391974-&gt;eec7010c0-450a-418f-b0be-fa2d42391974  1.0 (334) eec7010c0-450a-418f-b0be-fa2d42391974 Transit 1.0 (359) <p>The complete code of this example is available in the GitHub repository https://github.com/beamline/examples/tree/master/src/main/java/beamline/examples/opensky.</p>"},{"location":"jbeamline/examples/open-sky-monitoring/#scientific-literature","title":"Scientific literature","text":"<ul> <li>Bringing Up OpenSky: A Large-scale ADS-B Sensor Network for Research.  Matthias Sch\u00e4fer, Martin Strohmeier, Vincent Lenders, Ivan Martinovic and Matthias Wilhelm.  In Proceedings of the 13th IEEE/ACM International Symposium on Information Processing in Sensor Networks (IPSN), pages 83-94, April 2014.</li> </ul>"},{"location":"jbeamline/examples/speech-recognition/","title":"Speech recognition","text":"<p>In this example, we are going to explore a possible usage of streaming process mining in the context of speech recognition: each word a person is saying can be recognized as an activity and the sentences these words belong to can be the process instances. Every time a person waits a considerable amount of time between words, we can assume a new sentence is being said and thus a new case should be generated.</p> <p>To accomplish our goal we need to define a new <code>BeamlineAbstractSource</code> which can listen to the microphone, perform the speech recognition, and generate corresponding events. For the speech recognition we are going to use the Vosk speech recognition toolkit. We also going to use the <code>vosk-model-small-en-us-0.15</code> model which is available on the library website.</p> <p>First we need to setup the Maven dependencies by setting them in the <code>pom.xml</code> file: <pre><code>&lt;dependency&gt;\n   &lt;groupId&gt;com.alphacephei&lt;/groupId&gt;\n   &lt;artifactId&gt;vosk&lt;/artifactId&gt;\n   &lt;version&gt;0.3.33&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n   &lt;groupId&gt;org.json&lt;/groupId&gt;\n   &lt;artifactId&gt;json&lt;/artifactId&gt;\n   &lt;version&gt;20211205&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre></p> <p>Then, once the model folder is properly set, we can configure the source <code>SpeechRecognizerSource</code>. The main idea is to construct a new thread which remains listening for speech and translates it to a string. this has to be inserted into a (potentially never-ending) loop. Within the loop, we can extract the array of all words said until now with:</p> <pre><code>// getPartialResult returns a json object that we convert into its only string object\nString text = (String) new JSONObject(recognizer.getPartialResult()).get(\"partial\");\nif (text.isEmpty()) {\n   // if the text is empty we can skip this round\n   continue;\n}\n// split the sentence into the individual words\nString[] words = text.split(\" \");\n</code></pre> <p>After the new words being said are identified (code not reported here), it is possible to construct the event with: <pre><code>// processing new case ids\nif (lastWordMillisecs + MILLISECS_FOR_NEW_CASE &lt; System.currentTimeMillis()) {\n   caseId++;\n}\nlastWordMillisecs = System.currentTimeMillis();\n\n// prepare the actual event\nbuffer.offer(BEvent.create(\"speech\", \"case-\" + caseId, word));\n</code></pre></p> <p>Where <code>buffer</code> is a buffer used for storing events before they are dispatched to the other operators and <code>MILLISECS_FOR_NEW_CASE</code> is a <code>long</code> indicating how many milliseconds separate each sentence (and hence creates a new case identifier).</p> <p>A simple consumer, in this case the Trivial discovery miner, can then be attached to the source with: <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n   .addSource(new SpeechRecognitionSource())\n   .keyBy(BEvent::getProcessName)\n   .flatMap(new DirectlyFollowsDependencyDiscoveryMiner()\n         .setModelRefreshRate(1)\n         .setMinDependency(0))\n   .addSink(new SinkFunction&lt;ProcessMap&gt;(){\n      public void invoke(ProcessMap value, Context context) throws Exception {\n         System.out.println(value.getProcessedEvents());\n         value.generateDot().exportToSvg(new File(\"src/main/resources/output/output.svg\"));\n      };\n   });\nenv.execute();\n</code></pre></p> <p>In the following example, I tested the system saying two sentences: </p> <ul> <li>\"hello my name is peter\"</li> <li>\"good morning my name is bob\"</li> </ul> <p>The result of the processing is shown below:</p> image/svg+xml G e76ff4afd-c262-4cfe-904d-0468d17f3e76-&gt;eb7dc8274-6332-4dc7-9522-b778782e936f eb73e3c89-127b-4ee2-9704-b2c34178ec08-&gt;e7642d3c2-398a-436c-bd9a-06bd01cbe9b3  0.50 (1) e8af4e578-ab29-42d8-a4e0-ac2ca9f416b0-&gt;e889af76b-8c58-4b36-be88-97ae59fc4b1f  1.0 (2) e889af76b-8c58-4b36-be88-97ae59fc4b1f-&gt;e76ff4afd-c262-4cfe-904d-0468d17f3e76  0.50 (1) e889af76b-8c58-4b36-be88-97ae59fc4b1f-&gt;e9f0d9c0c-45bb-43f2-8fd2-1d1114895797  0.50 (1) e7585ada9-8ea0-49d2-b46a-cae864aa78ae-&gt;e7642d3c2-398a-436c-bd9a-06bd01cbe9b3  0.50 (1) e7642d3c2-398a-436c-bd9a-06bd01cbe9b3-&gt;e8af4e578-ab29-42d8-a4e0-ac2ca9f416b0  1.0 (2) e9f0d9c0c-45bb-43f2-8fd2-1d1114895797-&gt;eb7dc8274-6332-4dc7-9522-b778782e936f eafc5561b-c3c5-452e-8123-b8bfdc453ee2-&gt;eb73e3c89-127b-4ee2-9704-b2c34178ec08 eafc5561b-c3c5-452e-8123-b8bfdc453ee2-&gt;e7585ada9-8ea0-49d2-b46a-cae864aa78ae e76ff4afd-c262-4cfe-904d-0468d17f3e76 peter 0.50 (1) eb73e3c89-127b-4ee2-9704-b2c34178ec08 good morning 0.50 (1) e8af4e578-ab29-42d8-a4e0-ac2ca9f416b0 name 1.0 (2) e889af76b-8c58-4b36-be88-97ae59fc4b1f is 1.0 (2) e7585ada9-8ea0-49d2-b46a-cae864aa78ae hello 0.50 (1) e7642d3c2-398a-436c-bd9a-06bd01cbe9b3 my 1.0 (2) e9f0d9c0c-45bb-43f2-8fd2-1d1114895797 bob 0.50 (1) eafc5561b-c3c5-452e-8123-b8bfdc453ee2 eb7dc8274-6332-4dc7-9522-b778782e936f <p>The two sentences are recognized properly. It is worth noticing that on the second sentence the first 2 words (good morning) have been recognized together, probably because I've said them very quickly, one next to the other.</p> <p>The complete code of this example is available in the GitHub repository https://github.com/beamline/examples/tree/master/src/main/java/beamline/examples/speechRecognition.</p>"},{"location":"jbeamline/examples/wikipedia-edits/","title":"Wikipedia edits","text":"<p>All edits actions happening on Wikipedia are recorded and available as a stream of data (see https://wikitech.wikimedia.org/wiki/Event_Platform/EventStreams for further details). A possible way of process mine the stream of edits happening is by considering the page being edited as the instance of the editing process and the edit \"action\" as the actual activity name.</p> <p>To achieve this goal we can write a new <code>BeamlineAbstractSource</code> that consumes the stream of edits and produces a stream of <code>BEvent</code>s that can then be forwarded to one of the miners. So we can first define our source as well as the set of websites we want to filter (in this case we will focus on edits happening on the English version of Wikipedia, i.e., <code>enwiki</code>):</p> <pre><code>List&lt;String&gt; processesToStream = Arrays.asList(\"enwiki\");\n</code></pre> <p>After then we can write the code to transform the JSON produced by the Wikipedia stream into a stream of <code>XTrace</code>s. </p> <pre><code>Client client = ClientBuilder.newClient();\nWebTarget target = client.target(\"https://stream.wikimedia.org/v2/stream/recentchange\");\nSseEventSource source = SseEventSource.target(target).reconnectingEvery(5, TimeUnit.SECONDS).build();\nsource.register(new Consumer&lt;InboundSseEvent&gt;() {\n   @Override\n   public void accept(InboundSseEvent t) {\n      String data = t.readData();\n      if (data != null) {\n         JSONObject obj = new JSONObject(data);\n\n         String processName = obj.getString(\"wiki\");\n         String caseId = obj.getString(\"title\");\n         String activityName = obj.getString(\"type\");\n\n         if (processesToStream.contains(processName)) {\n            // prepare the actual event\n            try {\n               buffer.add(BEvent.create(processName, caseId, activityName));\n            } catch (EventException e) {\n               e.printStackTrace();\n            }\n         }\n      }\n   }\n});\nsource.open();\n</code></pre> <p>This code can be wrapped in a thread that executes all the time, and stores each event in a buffer for further dispatching:</p> <pre><code>public class WikipediaEditSource extends BeamlineAbstractSource {\n\n   private static final long serialVersionUID = 608025607423103621L;\n   private static List&lt;String&gt; processesToStream = Arrays.asList(\"enwiki\");\n\n   public void run(SourceContext&lt;BEvent&gt; ctx) throws Exception {\n      Queue&lt;BEvent&gt; buffer = new LinkedList&lt;&gt;();\n\n      new Thread(new Runnable() {\n         @Override\n         public void run() {\n            // code from previous listing\n            // ...\n         }\n      }).start();\n\n      while(isRunning()) {\n         while (isRunning() &amp;&amp; buffer.isEmpty()) {\n            Thread.sleep(100l);\n         }\n         if (isRunning()) {\n            synchronized (ctx.getCheckpointLock()) {\n               BEvent e = buffer.poll();\n               ctx.collect(e);\n            }\n         }\n      }\n   }\n}\n</code></pre> <p>A simple consumer, in this case the Trivial discovery miner, can then be attached to the source with: <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n   .addSource(new WikipediaEditSource())\n   .keyBy(BEvent::getProcessName)\n   .flatMap(new DirectlyFollowsDependencyDiscoveryMiner().setModelRefreshRate(10).setMinDependency(0))\n   .addSink(new SinkFunction&lt;ProcessMap&gt;(){\n      public void invoke(ProcessMap value, Context context) throws Exception {\n         value.generateDot().exportToSvg(new File(\"src/main/resources/output/output.svg\"));\n      };\n   });\nenv.execute();\n</code></pre></p> <p>After running the system for about a couple of minutes, the following map was produced:</p> G e9f086037-f263-4023-a09a-65194c88011b-&gt;e0615c600-1e15-47f0-94f6-9ce57be6cab9  0.018 (3) e9f086037-f263-4023-a09a-65194c88011b-&gt;eb542aaf4-fda2-48c0-96c2-b404ab6e59ce  0.0058 (1) ecdf5f385-1425-4bad-8feb-175f435d6826-&gt;e9f086037-f263-4023-a09a-65194c88011b  0.0058 (1) ecdf5f385-1425-4bad-8feb-175f435d6826-&gt;ecdf5f385-1425-4bad-8feb-175f435d6826  0.21 (36) ecdf5f385-1425-4bad-8feb-175f435d6826-&gt;e0615c600-1e15-47f0-94f6-9ce57be6cab9  0.099 (17) e0615c600-1e15-47f0-94f6-9ce57be6cab9-&gt;ecdf5f385-1425-4bad-8feb-175f435d6826  0.053 (9) e0615c600-1e15-47f0-94f6-9ce57be6cab9-&gt;e0615c600-1e15-47f0-94f6-9ce57be6cab9  0.87 (149) eb542aaf4-fda2-48c0-96c2-b404ab6e59ce-&gt;e9f086037-f263-4023-a09a-65194c88011b  0.0058 (1) eb542aaf4-fda2-48c0-96c2-b404ab6e59ce-&gt;e0615c600-1e15-47f0-94f6-9ce57be6cab9  0.0058 (1) eb542aaf4-fda2-48c0-96c2-b404ab6e59ce-&gt;eb542aaf4-fda2-48c0-96c2-b404ab6e59ce  1.0 (171) e5c219b19-76ba-4a89-81e8-472c2f157271-&gt;e9f086037-f263-4023-a09a-65194c88011b e5c219b19-76ba-4a89-81e8-472c2f157271-&gt;ecdf5f385-1425-4bad-8feb-175f435d6826 e5c219b19-76ba-4a89-81e8-472c2f157271-&gt;e0615c600-1e15-47f0-94f6-9ce57be6cab9 e5c219b19-76ba-4a89-81e8-472c2f157271-&gt;eb542aaf4-fda2-48c0-96c2-b404ab6e59ce e9f086037-f263-4023-a09a-65194c88011b new 0.035 (34) ecdf5f385-1425-4bad-8feb-175f435d6826 log 0.13 (121) e0615c600-1e15-47f0-94f6-9ce57be6cab9 edit 1.0 (963) eb542aaf4-fda2-48c0-96c2-b404ab6e59ce categorize 0.43 (412) e5c219b19-76ba-4a89-81e8-472c2f157271 <p>The complete code of this example is available in the GitHub repository https://github.com/beamline/examples/tree/master/src/main/java/beamline/examples/wikipedia.</p>"},{"location":"jbeamline/implemented-techniques/conformance-behavioural-patterns/","title":"Behavioral Patterns","text":""},{"location":"jbeamline/implemented-techniques/conformance-behavioural-patterns/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;conformance-behavioural-patterns&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the installation page for further instructions.</p> <p></p>"},{"location":"jbeamline/implemented-techniques/conformance-behavioural-patterns/#usage","title":"Usage","text":"<p>To use the technique you need to create the conformance checker object using:</p> <pre><code>Petrinet net = ...;\nMarking marking = ...;\nint maxCasesToStore = 1000; // max expected number of parallel process instances\n\nBehavioralConformance conformance = new BehavioralConformance(net, marking, maxCasesToStore);\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .keyBy(BEvent::getTraceName)\n    .flatMap(conformance)\n    .addSink(new SinkFunction&lt;OnlineConformanceScore&gt;(){\n        public void invoke(OnlineConformanceScore value) throws Exception {\n            System.out.println(\n                value.getConformance() + \" - \" +\n                value.getCompleteness() + \" - \" +\n                value.getConfidence());\n        };\n    });\nenv.execute();\n</code></pre> <p>It is worth highlighting that since each trace can be processed independently from the others, it is possible to increase the parallelism by keying the stream based on the case identifier (<code>BEvent::getTraceName</code>, line 9).</p> <p>In the current version, the reference model must be provided as a Petri Net.</p> <p>Importing a Petri net</p> <p>To import a Petri net it is possible to use the <code>simple-pnml</code> library: <pre><code>Object[] i = PnmlImportNet.importFromStream(new FileInputStream(new File(\"petri-net-model.pnml\")));\nPetrinet net = (Petrinet) i[0];\nMarking marking = (Marking) i[1];\n</code></pre></p>"},{"location":"jbeamline/implemented-techniques/conformance-behavioural-patterns/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Online Conformance Checking Using Behavioural Patterns A. Burattin, S. van Zelst, A. Armas-Cervantes, B. van Dongen, J. Carmona In Proceedings of BPM 2018; Sydney, Australia; September 2018.</li> </ul>"},{"location":"jbeamline/implemented-techniques/conformance-soft/","title":"Soft Conformance","text":""},{"location":"jbeamline/implemented-techniques/conformance-soft/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;soft-conformance&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the installation page for further instructions.</p> <p></p>"},{"location":"jbeamline/implemented-techniques/conformance-soft/#usage","title":"Usage","text":"<p>This conformance approach uses a descriptive model (i.e., a pattern of the observed behavior over a certain amount of time) which is not necessarily referring to the control-flow (e.g., it can be based on the social network of handover of work). To create such a model you need to specify the states and the probability of transitioning. Additionally, it is necessary to specify the likelihood of a random walk (i.e., the parameter \u03b1):</p> <p><pre><code>PDFA reference = new PDFA();\nreference.addNode(\"A\");\nreference.addNode(\"B\");\nreference.addNode(\"C\");\nreference.addEdge(\"A\", \"A\", 0.2);\nreference.addEdge(\"A\", \"B\", 0.8);\nreference.addEdge(\"B\", \"C\", 1);\n</code></pre> This model can be visualized with: <pre><code>PDFAVisualizer.getDot(reference).exportToSvg(new File(\"test.svg\"));\n</code></pre> And here is the output:</p> G e12bcafde-7737-4297-8e45-971bef8040b2 A e12bcafde-7737-4297-8e45-971bef8040b2-&gt;e12bcafde-7737-4297-8e45-971bef8040b2 0.2 e57c465e7-ec29-4da2-9d3e-e1362a897715 B e12bcafde-7737-4297-8e45-971bef8040b2-&gt;e57c465e7-ec29-4da2-9d3e-e1362a897715 0.8 e87bdcf03-5fcf-4aa6-b098-e2ab971bca74 C e57c465e7-ec29-4da2-9d3e-e1362a897715-&gt;e87bdcf03-5fcf-4aa6-b098-e2ab971bca74 1 <p>As can be seen, the model does not allow for any deviation, so it is possible to add weights for possible deviations by using: <pre><code>reference = WeightsNormalizer.normalize(reference, alpha);\n</code></pre> Which transforms the model into:</p> G edf5adbb8-1495-49f7-bf4d-dae11812ecf2 A edf5adbb8-1495-49f7-bf4d-dae11812ecf2-&gt;edf5adbb8-1495-49f7-bf4d-dae11812ecf2 0.27 eab3fce2a-df45-43e8-9b62-89ce28ff3320 B edf5adbb8-1495-49f7-bf4d-dae11812ecf2-&gt;eab3fce2a-df45-43e8-9b62-89ce28ff3320 0.57 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 C edf5adbb8-1495-49f7-bf4d-dae11812ecf2-&gt;ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 0.17 eab3fce2a-df45-43e8-9b62-89ce28ff3320-&gt;edf5adbb8-1495-49f7-bf4d-dae11812ecf2 0.17 eab3fce2a-df45-43e8-9b62-89ce28ff3320-&gt;eab3fce2a-df45-43e8-9b62-89ce28ff3320 0.17 eab3fce2a-df45-43e8-9b62-89ce28ff3320-&gt;ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 0.67 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4-&gt;edf5adbb8-1495-49f7-bf4d-dae11812ecf2 0.17 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4-&gt;eab3fce2a-df45-43e8-9b62-89ce28ff3320 0.17 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4-&gt;ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 0.17 <p>Please note that these models can also be mined. Once a model is available, it is possible to use it for conformance checking with:</p> <pre><code>PDFA reference = ...;\nint maxCasesToStore = 1000; // max expected number of parallel process instances\n\nPDFAConformance conformance = new PDFAConformance(reference, maxCasesToStore);\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .keyBy(BEvent::getTraceName)\n    .flatMap(conformance)\n    .addSink(new SinkFunction&lt;SoftConformanceReport&gt;(){\n        public void invoke(SoftConformanceReport value) throws Exception {\n            for(String caseId : value.keySet()) {\n                System.out.println(\n                    \"Case: \" + caseId + \"\\t\" +\n                    \"soft conformance: \" + value.get(caseId).getSoftConformance() + \"\\t\" +\n                    \"mean of probs: \" + value.get(caseId).getMeanProbabilities());\n            }\n        };\n    });\nenv.execute();\n</code></pre> <p>It is worth highlighting that since each trace can be processed independently from the others, it is possible to increase the parallelism by keying the stream based on the case identifier (<code>BEvent::getTraceName</code>, line 16).</p>"},{"location":"jbeamline/implemented-techniques/conformance-soft/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Online Soft Conformance Checking: Any Perspective Can Indicate Deviations A. Burattin In arXiv:2201.09222, Jan. 2022.</li> </ul>"},{"location":"jbeamline/implemented-techniques/discovery-dcr/","title":"Discovery DCR","text":""},{"location":"jbeamline/implemented-techniques/discovery-dcr/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;discovery-dcr&lt;/artifactId&gt;\n    &lt;version&gt;beamline-framework-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the installation page for further instructions.</p> <p></p>"},{"location":"jbeamline/implemented-techniques/discovery-dcr/#usage","title":"Usage","text":"<p>To construct a DCR miner it is possible to construct it with the following code:</p> <p><pre><code>Reflections reflections = new Reflections(\"beamline\");\nDFGBasedMiner miner = new DFGBasedMiner(reflections.getTypesAnnotatedWith(ExposedDcrPattern.class));\n</code></pre> In this case we use <code>Reflections</code> to identify and provide all the classes annoted with the <code>@ExposedDcrPattern</code>.</p> <p>It is possible (though not necessary) to configure the miner with the following parameters:</p> <pre><code>// configuration of the refresh rate (i.e., how many events between models update)\nmodel.setModelRefreshRate(1);\n\n// configuration of list of patters\nminer.setDcrPatternsForMining(\"Response\", \"Condition\", \"Include\", \"Exclude\");\n\n// configuration of the miner type\nminer.setStreamMinerType(new UnlimitedStreamMiner());\n//miner.setStreamMinerType(new SlidingWindowStreamMiner(15, 500));\n\n// configure which constraints to visualize\nminer.setDcrConstraintsForVisualization(RELATION.CONDITION, RELATION.RESPONSE);\n\n// configure the threshold\nminer.setRelationsThreshold(0);\n\n// configure the transitive reduction\nminer.setTransitiveReductionList(RELATION.CONDITION, RELATION.RESPONSE);\n</code></pre> <p>Once the miner is properly configured, it can be used as any other consumer. For example, using the following code: <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(new StringTestSource(\"ABCDF\", \"ABCEF\"))\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner)\n    .addSink(new SinkFunction&lt;DeclareModelView&gt;(){\n        public void invoke(DeclareModelView value, Context context) throws Exception {\n            value.generateDot().exportToSvg(new File(\"output.svg\"));\n        };\n    });\nenv.execute();\n</code></pre></p> <p>An example of the output produced is:</p> G e578f0930-aba5-467e-880d-bca6ba0b097a B e67c9c115-c541-48e8-80e5-6901bb8b4734 C e578f0930-aba5-467e-880d-bca6ba0b097a-&gt;e67c9c115-c541-48e8-80e5-6901bb8b4734 e578f0930-aba5-467e-880d-bca6ba0b097a-&gt;e67c9c115-c541-48e8-80e5-6901bb8b4734 e3677451c-681d-46aa-94c8-b6a991735be3 D e67c9c115-c541-48e8-80e5-6901bb8b4734-&gt;e3677451c-681d-46aa-94c8-b6a991735be3 e67c9c115-c541-48e8-80e5-6901bb8b4734-&gt;e3677451c-681d-46aa-94c8-b6a991735be3 ec24f6d71-e3be-4240-8cc5-18467c2ba26e K e67c9c115-c541-48e8-80e5-6901bb8b4734-&gt;ec24f6d71-e3be-4240-8cc5-18467c2ba26e e67c9c115-c541-48e8-80e5-6901bb8b4734-&gt;ec24f6d71-e3be-4240-8cc5-18467c2ba26e eba1a3825-bd6b-4990-bb2a-9995b74ff782 E e3677451c-681d-46aa-94c8-b6a991735be3-&gt;eba1a3825-bd6b-4990-bb2a-9995b74ff782 e3677451c-681d-46aa-94c8-b6a991735be3-&gt;eba1a3825-bd6b-4990-bb2a-9995b74ff782 e4b48c5a5-016c-458c-b830-243e25a8c96d A e4b48c5a5-016c-458c-b830-243e25a8c96d-&gt;e578f0930-aba5-467e-880d-bca6ba0b097a e4b48c5a5-016c-458c-b830-243e25a8c96d-&gt;e578f0930-aba5-467e-880d-bca6ba0b097a"},{"location":"jbeamline/implemented-techniques/discovery-dcr/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Uncovering Change: A Streaming Approach for Declarative Processes  A. Burattin, H. A. L\u00f3pez, L. Starklit In Proceedings of ICPM Workshop (SA4PM), 2022.</li> </ul>"},{"location":"jbeamline/implemented-techniques/discovery-declare/","title":"Discovery declare","text":""},{"location":"jbeamline/implemented-techniques/discovery-declare/#declare-miners","title":"Declare Miners","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;discovery-declare&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the installation page for further instructions.</p> <p></p>"},{"location":"jbeamline/implemented-techniques/discovery-declare/#usage","title":"Usage","text":"<p>It is possible to call the two miners <code>beamline.miners.declare.DeclareMinerLossyCounting</code> and <code>beamline.miners.declare.DeclareMinerBudgetLossyCounting</code> using the following:</p> <p><pre><code>DeclareMinerLossyCounting miner = new DeclareMinerLossyCounting(\n    0.001, // the maximal approximation error\n    10 // the number of declare constraints to show\n);\n</code></pre> <pre><code>DeclareMinerBudgetLossyCounting miner = new DeclareMinerBudgetLossyCounting(\n    1000, // the available budget\n    10 // the number of declare constraints to show\n);\n</code></pre></p> <p>After the miner is configured, both can be used to produce a CNet which can be either exported into a <code>.cnet</code> file or visualized (currently the visualization does not support the bindings):</p> <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner.setModelRefreshRate(100))\n    .addSink(new SinkFunction&lt;DeclareModelView&gt;(){\n        public void invoke(DeclareModelView value, Context context) throws Exception {\n            value.generateDot().exportToSvg(new File(\"output.svg\"));\n        };\n    });\nenv.execute();\n</code></pre>"},{"location":"jbeamline/implemented-techniques/discovery-declare/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Online Discovery of Declarative Process Models from Event Streams A. Burattin, M. Cimitile, F. Maggi, A. Sperduti In IEEE Transactions on Services Computing, vol. 8 (2015), no. 6, pp. 833-846.</li> </ul>"},{"location":"jbeamline/implemented-techniques/discovery-heuristics-miner/","title":"Heuristics Miners","text":""},{"location":"jbeamline/implemented-techniques/discovery-heuristics-miner/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;discovery-heuristics&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the installation page for further instructions.</p> <p></p>"},{"location":"jbeamline/implemented-techniques/discovery-heuristics-miner/#usage","title":"Usage","text":"<p>This miner contains two version of the streaming Heuristics miner. One is based on the Lossy Counting algorithm, the other is based on the Lossy Counting with Budget. These can be accessed with the following parameters:</p> <pre><code>HeuristicsMinerLossyCounting miner = new HeuristicsMinerLossyCounting(\n    0.0001, // the maximal approximation error\n    0.8, // the minimum dependency threshold\n    10, // the positive observation threshold\n    0.1 // the and threshold\n);\n</code></pre> <pre><code>HeuristicsMinerBudgetLossyCounting miner = new HeuristicsMinerBudgetLossyCounting(\n    100000, // the total budget available\n    0.8, // the minimum dependency threshold\n    10, // the positive observation threshold\n    0.1 // the and threshold\n);\n</code></pre> <p>After the miner is configured, both can be used to produce a CNet which can be either exported into a <code>.cnet</code> file or visualized (currently the visualization does not support the bindings):</p> <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner.setModelRefreshRate(100))\n    .addSink(new SinkFunction&lt;StreamingCNet&gt;(){\n        public void invoke(StreamingCNet value, Context context) throws Exception {\n            new CNetSimplifiedModelView(value.getCnet()).exportToSvg(new File(\"output.svg\"));\n        };\n    });\nenv.execute();\n</code></pre>"},{"location":"jbeamline/implemented-techniques/discovery-heuristics-miner/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Control-flow Discovery from Event Streams A. Burattin, A. Sperduti, W. M. P. van der Aalst In Proceedings of the Congress on Evolutionary Computation (IEEE WCCI CEC 2014); Beijing, China; July 6-11, 2014.</li> <li>Heuristics Miners for Streaming Event Data A. Burattin, A. Sperduti, W. M. P. van der Aalst In CoRR abs/1212.6383, Dec. 2012.</li> </ul>"},{"location":"jbeamline/implemented-techniques/discovery-soft/","title":"Soft Conformance Model Miner","text":""},{"location":"jbeamline/implemented-techniques/discovery-soft/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;soft-conformance&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the installation page for further instructions.</p> <p></p>"},{"location":"jbeamline/implemented-techniques/discovery-soft/#usage","title":"Usage","text":"<p>This miner can be used to extract a model to be used with the Soft Conformance technique. These models are not necessarily referring to the control-flow (e.g., they can be based on the social network of handover of work).</p> <p>This miner extracts just a dependency map leveraging the directly follows relations observed in the stream. Once a <code>XesSource</code> is available, the miner can be configured and used as follows:</p> <pre><code>PDFAMiner miner = new PDFAMiner();\nminer.setModelRefreshRate(1); // configure how ofter the mining algorithm should emit a new model\n\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(new StringTestSource(\"AABC\", \"ABC\", \"ABC\", \"ABC\"))\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner)\n    .addSink(new SinkFunction&lt;PDFA&gt;(){\n        public void invoke(PDFA value, Context context) throws Exception {\n            PDFAVisualizer.getDot(value).exportToSvg(new File(\"output.svg\"));\n        };\n    });\nenv.execute();\n</code></pre> <p>This code will produce the following model:</p> G edf5adbb8-1495-49f7-bf4d-dae11812ecf2 A edf5adbb8-1495-49f7-bf4d-dae11812ecf2-&gt;edf5adbb8-1495-49f7-bf4d-dae11812ecf2 0.27 eab3fce2a-df45-43e8-9b62-89ce28ff3320 B edf5adbb8-1495-49f7-bf4d-dae11812ecf2-&gt;eab3fce2a-df45-43e8-9b62-89ce28ff3320 0.57 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 C edf5adbb8-1495-49f7-bf4d-dae11812ecf2-&gt;ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 0.17 eab3fce2a-df45-43e8-9b62-89ce28ff3320-&gt;edf5adbb8-1495-49f7-bf4d-dae11812ecf2 0.17 eab3fce2a-df45-43e8-9b62-89ce28ff3320-&gt;eab3fce2a-df45-43e8-9b62-89ce28ff3320 0.17 eab3fce2a-df45-43e8-9b62-89ce28ff3320-&gt;ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 0.67 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4-&gt;edf5adbb8-1495-49f7-bf4d-dae11812ecf2 0.17 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4-&gt;eab3fce2a-df45-43e8-9b62-89ce28ff3320 0.17 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4-&gt;ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 0.17"},{"location":"jbeamline/implemented-techniques/discovery-soft/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Online Soft Conformance Checking: Any Perspective Can Indicate Deviations A. Burattin In arXiv:2201.09222, Jan. 2022.</li> </ul>"},{"location":"jbeamline/implemented-techniques/discovery-splitminer/","title":"Split Miner","text":""},{"location":"jbeamline/implemented-techniques/discovery-splitminer/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;discovery-splitminer&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the installation page for further instructions.</p> <p></p>"},{"location":"jbeamline/implemented-techniques/discovery-splitminer/#usage","title":"Usage","text":"<p>This miner can be used to extract a BPMN process model in a similar way as performed by the Split Miner.</p> <p>Once a <code>XesSource</code> is available, the miner can be configured and used as follows:</p> <pre><code>LossyCountingBudgetSplitMiner miner = new LossyCountingBudgetSplitMiner(\n    10, // the budget for cases\n    10, // the budget for relations\n    0.01, // concurrency threshold\n    0.01, // the frequency threshold\n    5); // the sliding window size\n\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(new StringTestSource(\"ABCDF\", \"ABCEF\"))\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner)\n    .addSink(new SinkFunction&lt;BPMNTemplateResponse&gt;() {\n        public void invoke(BPMNTemplateResponse value, Context context) throws Exception {\n            PaliaLikeBPMNDiagramGenerator.fromBPMNTemplate(\n                \"process\",\n                value.getBpmnTemplate(),\n                \"output.svg\");\n        }\n    });\nenv.execute();\n</code></pre> <p>This code will produce the following model:</p> G e53a1df30-9705-4b08-b0a8-3263f4319ccc-&gt;e19ab2931-dc04-48da-bc8b-a6445506d5c4 e19ab2931-dc04-48da-bc8b-a6445506d5c4-&gt;e808aba30-b5eb-469b-b542-d5a27f4588b7 e808aba30-b5eb-469b-b542-d5a27f4588b7-&gt;eeab80efd-180c-4fe1-8e69-9934b9ea0b09 ee7b841cb-464c-419a-8bae-3f806f9ec5c9-&gt;e6ae57bba-eded-484d-af11-a5a1989a71ee eeab80efd-180c-4fe1-8e69-9934b9ea0b09-&gt;ea1411cd2-ee63-41c7-a2dc-1c7840253baa e808e2a5f-5092-4189-90b5-8395b10cce91-&gt;ebc3567e8-38c0-4f5e-ae50-e43c49309c44 eaf32a996-30c2-4603-b9ef-ae197503fc9b-&gt;ebc3567e8-38c0-4f5e-ae50-e43c49309c44 ea1411cd2-ee63-41c7-a2dc-1c7840253baa-&gt;e808e2a5f-5092-4189-90b5-8395b10cce91 ea1411cd2-ee63-41c7-a2dc-1c7840253baa-&gt;eaf32a996-30c2-4603-b9ef-ae197503fc9b ebc3567e8-38c0-4f5e-ae50-e43c49309c44-&gt;ee7b841cb-464c-419a-8bae-3f806f9ec5c9 e53a1df30-9705-4b08-b0a8-3263f4319ccc e19ab2931-dc04-48da-bc8b-a6445506d5c4 A e808aba30-b5eb-469b-b542-d5a27f4588b7 B ee7b841cb-464c-419a-8bae-3f806f9ec5c9 F eeab80efd-180c-4fe1-8e69-9934b9ea0b09 C e808e2a5f-5092-4189-90b5-8395b10cce91 E eaf32a996-30c2-4603-b9ef-ae197503fc9b D ea1411cd2-ee63-41c7-a2dc-1c7840253baa \u00d7 ebc3567e8-38c0-4f5e-ae50-e43c49309c44 \u00d7 e6ae57bba-eded-484d-af11-a5a1989a71ee"},{"location":"jbeamline/implemented-techniques/discovery-splitminer/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Split Miner process discovery technique in streaming process mining environments A. Jarmolkowicz Master Thesis, DTU, Jun. 2023.</li> </ul> <p>The Split Miner algorithm is presented in:</p> <ul> <li>Split miner: automated discovery of accurate and simple business process models from event logs Augusto, A., Conforti, R., Dumas, M. et al.  In Knowledge and Information Systems 59, 251-284 (2019)</li> </ul>"},{"location":"jbeamline/implemented-techniques/discovery-trivial/","title":"Trivial Miner","text":""},{"location":"jbeamline/implemented-techniques/discovery-trivial/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;discovery-trivial&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the installation page for further instructions.</p> <p></p>"},{"location":"jbeamline/implemented-techniques/discovery-trivial/#usage","title":"Usage","text":"<p>This miner extracts just a dependency map leveraging the directly follows relations observed in the stream. Once a <code>XesSource</code> is available, the miner can be configured and used as follows:</p> <pre><code>DirectlyFollowsDependencyDiscoveryMiner miner = new DirectlyFollowsDependencyDiscoveryMiner();\nminer.setModelRefreshRate(1); // configure how ofter the mining algorithm should emit a new model\nminer.setMinDependency(0.8); // configure the dependency threshold\n\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(new StringTestSource(\"ABCDF\", \"ABCEF\"))\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner)\n    .addSink(new SinkFunction&lt;ProcessMap&gt;(){\n        public void invoke(ProcessMap value, Context context) throws Exception {\n            value.generateDot().exportToSvg(new File(\"output.svg\"));\n        };\n    });\nenv.execute();\n</code></pre>"},{"location":"jbeamline/implemented-techniques/discovery-trivial/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Process Mining Techniques in Business Environments A. Burattin Springer, 2015.</li> </ul>"},{"location":"jbeamline/implemented-techniques/simulation-plg/","title":"Simulation with PLG","text":""},{"location":"jbeamline/implemented-techniques/simulation-plg/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;simulation-plg&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the installation page for further instructions.</p> <p></p>"},{"location":"jbeamline/implemented-techniques/simulation-plg/#usage","title":"Usage","text":"<p>This wrapper of the PLG library allows the generation of random processes as well as their simulation. Processes can also be imported and exported. The following snipped of code generates a random process and streams it:</p> <pre><code>Process p = new Process(\"\");\nProcessGenerator.randomizeProcess(p, RandomizationConfiguration.BASIC_VALUES);\n\nLogGenerator logGenerator = new LogGenerator(p, new SimulationConfiguration(100), new ProgressAdapter());\nXLog log = logGenerator.generateLog();\n\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(new XesLogSource(log))\n    .keyBy(BEvent::getProcessName)\n    .print();\nenv.execute();\n</code></pre>"},{"location":"jbeamline/implemented-techniques/simulation-plg/#scientific-literature","title":"Scientific literature","text":"<p>The technique implemented in this package is described in:</p> <ul> <li>PLG2: Multiperspective Process Randomization with Online and Offline Simulations Andrea Burattin In Online Proceedings of the BPM Demo Track 2016; Rio de Janeiro, Brasil; September, 18 2016; CEUR-WS.org 2016.</li> </ul> <p>Other relevant publications:</p> <ul> <li>PLG: a Framework for the Generation of Business Process Models and their Execution Logs Andrea Burattin and Alessandro Sperduti In Proceedings of the 6th International Workshop on Business Process Intelligence (BPI 2010); Stevens Institute of Technology; Hoboken, New Jersey, USA; September 13, 2010. 10.1007/978-3-642-20511-8_20.</li> <li>PLG2: Multiperspective Processes Randomization and Simulation for Online and Offline Settings Andrea Burattin In CoRR abs/1506.08415, Jun. 2015.</li> </ul> <p>Further information are also availalbe at the Wiki of the PLG project.</p>"},{"location":"pybeamline/","title":"Getting Started","text":"<p>In this page pyBeamline is presented.</p>"},{"location":"pybeamline/#hello-world-with-pybeamline","title":"Hello world with pyBeamline","text":"<p>This is an example of a simple dataflow implemented in pyBeamline:</p> <pre><code>xes_log_source_from_file(\"test.xes\").pipe(\n    simple_dfg_miner(),\n    dfg_str_to_graphviz()\n).subscribe(graphviz_sink())\n</code></pre> <p>This code takes an XES log file and converts it into a stream. On this stream, a simple DFG miner is executed and it's output is converted and rendered in Graphviz (in a Jupyter Notebook).</p>"},{"location":"pybeamline/#differences-with-pm4py","title":"Differences with PM4PY","text":"<p>PM4PY has a package dedicated to streaming algorithms. This package, however, does not allow the construction of the dataflow for the processing of the events. Instead, it allows the application of a single algorithm on a defined stream. While this might be useful in certain situation, having the ability to construct the dataflow represents a fundamental architecture for stream processing.</p> What is a dataflow? <p>Here is the definition from the corresponding Wikipedia page:</p> <p>In computing, dataflow is a broad concept, which has various meanings depending on the application and context. In the context of software architecture, data flow relates to stream processing or reactive programming.</p> <p>[...]</p> <p>Dataflow computing is a software paradigm based on the idea of representing computations as a directed graph, where nodes are computations and data flow along the edges. Dataflow can also be called stream processing or reactive programming.</p> <p>There have been multiple data-flow/stream processing languages of various forms (see Stream processing). Data-flow hardware (see Dataflow architecture) is an alternative to the classic von Neumann architecture. The most obvious example of data-flow programming is the subset known as reactive programming with spreadsheets. As a user enters new values, they are instantly transmitted to the next logical \"actor\" or formula for calculation.</p> <p>Distributed data flows have also been proposed as a programming abstraction that captures the dynamics of distributed multi-protocols. The data-centric perspective characteristic of data flow programming promotes high-level functional specifications and simplifies formal reasoning about system components.</p>"},{"location":"pybeamline/basic-concepts/","title":"Basic Concepts","text":"<p>In this section the basic concepts of pyBeamline are presented.</p> <p>The main component of a pyBeamline program is its dataflow. A dataflow consists of the basic transformations applied to each event, from its origin (called source) until the end (called sink). In between, different operators can be chained together in order to transform the data according to the requirements. </p> <p>This is an example of a simple dataflow:</p> <p><pre><code>string_test_source([\"ABCD\", \"ACBD\"]).pipe(\n    simple_dfg_miner(model_update_frequency=1),\n    dfg_str_to_graphviz()\n).subscribe(graphviz_sink())\n</code></pre> </p> <p>In this dataflow, line 1 defines the source, in this case a <code>string_test_source</code> that generates a stream with 2 process instances (one with activities <code>A</code>, <code>B</code>, <code>C</code>, and <code>D</code> and the other with <code>A</code>, <code>C</code>, <code>B</code>, and <code>D</code>). Then, on this stream, a pipeline of two operators is applied: first (<code>simple_dfg_miner</code>) transforms the stream of events into a stream of DFG models (i.e., it mines the stream); and the other (<code>dfg_str_to_graphviz</code>) converts the DFG into a Graphviz string. Finally, a sink (<code>graphviz_sink</code>) is provided that will dump the DFG models into a Graphviz representation. Please note that corresponding <code>import</code> statements are omitted for simplicity.</p>"},{"location":"pybeamline/basic-concepts/#events","title":"Events","text":"<p>The pyBeamline framework comes with its own definition of event, called <code>BEvent</code> and <code>BOEvent</code>, similarly to what is defined in JBeamline. Here some of the corresponding methods are highlighted:</p>  classDiagram  class AbstractEvent {     &lt;&lt;abstract&gt;&gt;     + get_event_name() str     + get_event_time() str }  class BEvent {     + dict process_attributes     + dict trace_attributes     + dict event_attributes     + get_process_name(): str     + get_trace_name(): str }  class BOEvent {     + int event_id     + str activity_name     + time timestamp     + dict omap     + dict vmap }  AbstractEvent &lt;|-- BEvent AbstractEvent &lt;|-- BOEvent  <p>A <code>BEvent</code>, consists of 3 maps for attributes referring to the process, to the trace, and to the event itself. While it's possible to set all the attributes individually, some convenience methods are proposed as well, such as <code>getTraceName</code> which returns the name of the trace (i.e., the case id). Internally, a <code>BEvent</code> stores the basic information using as attribute names the same provided by the standard extension of OpenXES. Additionally, setters for attributes defined in the context of OpenXES are provided too, thus providing some level of interoperability between the platforms.</p> <p>A <code>BOEvent</code>, on the other hand, represents a single event, aligned with OCEL 2.0 specification. More precisely, it contains a unique event identifier (<code>ocel:eid</code>), the name of the activity (<code>ocel:activity</code>), the event timestamp (<code>ocel:timestamp</code>), a list of associated objects (<code>ocel:omap</code>) and additional event attributes (<code>ocel:vmap</code>).</p>"},{"location":"pybeamline/basic-concepts/#source-and-sink","title":"Source and Sink","text":"<p>Sources and sink are defined to extend <code>BaseSource</code> and <code>BaseSink</code> which look like this:</p>  classDiagram  class BaseSource~T~ {     &lt;&lt;abstract&gt;&gt;      + execute(): void*     + produce(item T): void     + close(): void }  class BaseSink~T~ {     &lt;&lt;abstract&gt;&gt;      + consume(item T): void*     + close(): void }  <p>Both classes have a parameter type <code>T</code> which indicates the type of events being produced and consumed. In the case of <code>BaseSource</code>, the abstract method <code>execute</code> has to be implemented and, every time an event has to be produced, method <code>produce</code> has to be called.</p> <p>For <code>BaseSink</code>, only the abstract method <code>consume</code> has to be implemented. The method receives, as parameter, the item to be consumed.</p>"},{"location":"pybeamline/basic-concepts/#operators","title":"Operators","text":"<p>In pyBeamline, the structure of operators is the following:</p>  classDiagram  class BaseOperator~T, K~ {     &lt;&lt;abstract&gt;&gt;      + apply(T): K* }  class BaseFilter~T~ {     &lt;&lt;abstract&gt;&gt;      + condition(value T): bool*     + apply(T): T }  class BaseMap~T, K~ {     &lt;&lt;abstract&gt;&gt;      + transform(value T): list[K]*     + apply(T): K }  BaseOperator &lt;|-- BaseFilter BaseOperator &lt;|-- BaseMap   <p>The difference between <code>BaseFilter</code>s and <code>BaseMap</code>s is that the first are meant just to stop some events from moving forward in the dataflow, without changing the type of the events as they continue their journey. <code>BaseMap</code>s,  on the other hand, transform the type of events. For example, a stream discovery miner will extend <code>BaseMap</code> as it is expected to transform the incoming stream of events into a stream of mined models.</p>"},{"location":"pybeamline/filters/","title":"Filters","text":"<p>The filter operator, in ReactiveX, does not change the stream, but filters the events so that only those passing a predicate test can pass. In Beamline there are some filters already implemented that can be used as follows:</p> <pre><code>from pybeamline.sources import log_source\nfrom pybeamline.filters import excludes_activity_filter, retains_activity_filter\n\nlog_source([\"ABC\", \"ACB\", \"EFG\"]).pipe(\n    excludes_activity_filter(\"A\"),\n    retains_activity_filter(\"G\")\n).subscribe(lambda x: print(str(x)))\n</code></pre> <p>Filters can operate on event attributes or trace attributes. Please note that filters can be chained together in order to achieve the desired result.</p>"},{"location":"pybeamline/filters/#retains_on_event_attribute_equal_filter","title":"<code>retains_on_event_attribute_equal_filter</code>","text":"<p>Retains events based on the equality of an event attribute. Example: <pre><code>from pybeamline.sources import log_source\nfrom pybeamline.filters import retains_on_event_attribute_equal_filter\n\nlog_source(\"test.xes\").pipe(\n    retains_on_event_attribute_equal_filter(\"event-attrib\", [\"ev\", \"ab\"]),\n).subscribe(lambda x: print(str(x)))\n</code></pre></p>"},{"location":"pybeamline/filters/#excludes_on_event_attribute_equal_filter","title":"<code>excludes_on_event_attribute_equal_filter</code>","text":"<p>Exclude events based on the equality of an event attribute. <pre><code>from pybeamline.sources import log_source\nfrom pybeamline.filters import excludes_on_event_attribute_equal_filter\n\nlog_source(\"test.xes\").pipe(\n    excludes_on_event_attribute_equal_filter(\"event-attrib\", [\"ev\", \"ab\"]),\n).subscribe(lambda x: print(str(x)))\n</code></pre></p>"},{"location":"pybeamline/filters/#retains_on_trace_attribute_equal_filter","title":"<code>retains_on_trace_attribute_equal_filter</code>","text":"<p>Retains events based on the equality of a trace attribute. <pre><code>from pybeamline.sources import log_sourcelog_source\nfrom pybeamline.filters import retains_on_trace_attribute_equal_filter\n\nlog_source(\"test.xes\").pipe(\n    retains_on_trace_attribute_equal_filter(\"trace-attrib\", [\"tv\", \"ab\"]),\n).subscribe(lambda x: print(str(x)))\n</code></pre></p>"},{"location":"pybeamline/filters/#excludes_on_trace_attribute_equal_filter","title":"<code>excludes_on_trace_attribute_equal_filter</code>","text":"<pre><code>Excludes events based on the equality of a trace attribute.\n```python\nfrom pybeamline.sources import log_source\nfrom pybeamline.filters import excludes_on_trace_attribute_equal_filter\n\nlog_source(\"test.xes\").pipe(\n    excludes_on_trace_attribute_equal_filter(\"trace-attrib\", [\"tv\", \"ab\"]),\n).subscribe(lambda x: print(str(x)))\n\n```\n</code></pre>"},{"location":"pybeamline/filters/#retains_activity_filter","title":"<code>retains_activity_filter</code>","text":"<p>Retains activities base on their name (<code>concept:name</code>). <pre><code>from pybeamline.sources import log_source\nfrom pybeamline.filters import retains_activity_filter\n\nlog_source([\"ABC\", \"ACB\", \"EFG\"]).pipe(\n    retains_activity_filter(\"G\")\n).subscribe(lambda x: print(str(x)))\n</code></pre></p>"},{"location":"pybeamline/filters/#excludes_activity_filter","title":"<code>excludes_activity_filter</code>","text":"<p>Excludes activities base on their name (<code>concept:name</code>). <pre><code>from pybeamline.sources import log_source\nfrom pybeamline.filters import excludes_activity_filter\n\nlog_source([\"ABC\", \"ACB\", \"EFG\"]).pipe(\n    excludes_activity_filter(\"A\"),\n).subscribe(lambda x: print(str(x)))\n</code></pre></p>"},{"location":"pybeamline/installation/","title":"Installation","text":"<p>pyBeamline is meant to work with Python 3.9 and above. Installation can be done via <code>pip</code>:</p> <p><pre><code>pip install pybeamline\n</code></pre> More information are available at https://pypi.org/project/pybeamline/.</p> <p></p>"},{"location":"pybeamline/integration/","title":"Integration with other Libraries","text":""},{"location":"pybeamline/integration/#river","title":"River","text":"<p>River (https://riverml.xyz/) is a library to build online machine learning models. Such models operate on data streams. River includes several online machine learning algorithms that can be used for several tasks, including classification, regression, anomaly detection, time series forecasting, etc. The ideology behind River is to be a generic machine learning which allows to perform these tasks in a streaming manner. Indeed, many batch machine learning algorithms have online equivalents. Note that River also supports some more basic tasks. For instance, you might just want to calculate a running average of a data stream.</p> <p>It is possible to integrate pyBeamline's result into River to leverage its ML capabilities. For example, let's say we want to use concept drift detection using the ADWIN algorithm. In particular, we are interested in computing if the frequency of the directly follows relation <code>BC</code> changes over time. To accomplish this task, let's first build a log where we artificially inject two of such drifts:</p> <p><pre><code>import random\n\nlog_original = [\"ABCD\"]*10000 + [\"ACBD\"]*500\nrandom.shuffle(log_original)\n\nlog_after_drift = [\"ABCD\"]*500 + [\"ACBD\"]*10000\nrandom.shuffle(log_after_drift)\n\nlog_with_drift = log_source(log_original + log_after_drift + log_original)\n</code></pre> In this case, we built two logs (<code>log_original</code> and <code>log_after_drift</code>) which include the same process variants but that differ in the number of occurrences. Finally, we construct our pyBeamline log source <code>log_with_drift</code> by concatenating <code>log_original + log_after_drift + log_original</code>.</p> <p>After that we can use the capabilities of pyBeamline and reactivex to construct a pipeline that produce a sequence of frequencies corresponding to the frequency of directly follows relation <code>BC</code> in window with length 40 (which is chosen as all our traces have length 4). Also note that we leverage the fact that in all our events when <code>B</code> and <code>C</code> appear they are always in the same trace (because of how <code>log_source</code> generates the observable). We will later define a function <code>check_for_drift</code>:</p> <pre><code>from reactivex import operators as ops\n\nlog_with_drift.pipe(\n  RxOperator(ops.buffer_with_count(40)),\n  RxOperator(ops.flat_map(lambda events: reactivex.from_iterable(events).pipe(\n      ops.pairwise(),\n      ops.filter(lambda x: x[0].get_trace_name() == x[1].get_trace_name() and x[0].get_event_name() == \"B\" and x[1].get_event_name() == \"C\"),\n      ops.count()\n      )\n  )),\n).sink(print_sink())\n</code></pre> <p>After this we can define our function for drift detection and collection of points and drift indexes using: <pre><code>import reactivex\n\nfrom pybeamline.stream.rx_operator import RxOperator\nfrom pybeamline.stream.base_sink import BaseSink\nfrom typing import Optional, List\nfrom pybeamline.stream.base_map import BaseMap\nfrom river import drift\nfrom reactivex import operators as ops\n\nclass CheckForDrift(BaseMap[int, int]):\n  def __init__(self):\n    self.drift_detector = drift.ADWIN()\n    self.drifts = []\n    self.index = 0\n\n  def transform(self, value: int) -&gt; Optional[List[int]]:\n    self.drift_detector.update(value)\n    self.index += 1\n    if self.drift_detector.drift_detected:\n      self.drifts.append(self.index)\n    return [value]\n\nclass CollectSink(BaseSink[int]):\n  def __init__(self):\n    self.data = []\n\n  def consume(self, item: int) -&gt; None:\n    self.data.append(item)\n\n\ndrift_detector = CheckForDrift()\ncollector = CollectSink()\n\nlog_with_drift.pipe(RxOperator(ops.buffer_with_count(40)),\n  RxOperator(ops.flat_map(lambda events: reactivex.from_iterable(events).pipe(\n      ops.pairwise(),\n      ops.filter(lambda x: x[0].get_trace_name() == x[1].get_trace_name() and x[0].get_event_name() == \"B\" and x[1].get_event_name() == \"C\"),\n      ops.count()\n      )\n  )),\n  drift_detector\n).sink(collector)\n</code></pre> With this class available, <code>CheckForDrift</code> can now be piped to the previous computation. Plotting the frequencies and the concept drifts will result in the following:</p> <p></p> <p>For a complete working example, see https://github.com/beamline/pybeamline/blob/master/tutorial.ipynb.</p>"},{"location":"pybeamline/pybeamline-designer/","title":"pyBeamline Designer","text":"<p>To help getting started, you can try the pyBeamline Designer, available at https://beamline.github.io/pybeamline-designer/:</p> <p> </p> https://beamline.github.io/pybeamline-designer/ <p>pyBeamline Designer aims to make your process mining analytics as easy as possible. Here you will be able to create diagrams resembling your own system.</p>"},{"location":"pybeamline/conformance/behavioral_conformance/","title":"behavioral_conformance","text":"<p>An algorithm to compute the conformance using behavioral patterns.</p>"},{"location":"pybeamline/conformance/behavioral_conformance/#parameters","title":"Parameters","text":"<ul> <li>model: <code>tuple</code>   The reference behavioral model.</li> </ul>"},{"location":"pybeamline/conformance/behavioral_conformance/#returned-type","title":"Returned type","text":"<p>The returned output has type <code>(float, float, float, int)</code> with: conformance, confidence, completeness, and number of observed events.</p>"},{"location":"pybeamline/conformance/behavioral_conformance/#example","title":"Example","text":"<p>In this example, the reference model is extracted by a (finite) stream:</p> <pre><code>from pybeamline.algorithms.conformance import mine_behavioral_model_from_stream, behavioral_conformance\nfrom pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.sources import log_source\n\nsource = log_source([\"ABCD\", \"ABCD\"])\nreference_model = mine_behavioral_model_from_stream(source)\n\nlog_source([\"ABCD\", \"ABEFG\"]).pipe(\n    behavioral_conformance(reference_model)\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>(1.0, 0.0, 1, 2)\n(1.0, 0.5, 1, 3)\n(1.0, 1.0, 1, 4)\n(1.0, 0.0, 1, 6)\n(0.5, -1, -1, 7)\n(0.3333333333333333, -1, -1, 8)\n(0.25, -1, -1, 9)\n</code></pre> <p>The reference model can also be obtained converting a Petri net (from PM4PY) into a behavioral model:</p> <pre><code>from pm4py.objects.petri_net.obj import PetriNet, Marking\nfrom pm4py.objects.petri_net.utils.petri_utils import add_arc_from_to\n\nfrom pybeamline.algorithms.conformance import behavioral_conformance\nfrom pybeamline.algorithms.conformance.behavioral.behavioral_conformance import petri_net_2_behavioral_model\nfrom pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.sources import log_source\n\n# code definition of the petri net. it is also possible to import it\np0 = PetriNet.Place(\"p0\")\np1 = PetriNet.Place(\"p1\")\np2 = PetriNet.Place(\"p2\")\np3 = PetriNet.Place(\"p3\")\np4 = PetriNet.Place(\"p4\")\ntA = PetriNet.Transition(\"tA\", \"A\")\ntB = PetriNet.Transition(\"tB\", \"B\")\ntC = PetriNet.Transition(\"tC\", \"C\")\ntD = PetriNet.Transition(\"tD\", \"D\")\nnet = PetriNet(\"seq_net\")\nnet.places.update({p0, p1, p2, p3, p4})\nnet.transitions.update({tA, tB, tC, tD})\nadd_arc_from_to(p0, tA, net)\nadd_arc_from_to(tA, p1, net)\nadd_arc_from_to(p1, tB, net)\nadd_arc_from_to(tB, p2, net)\nadd_arc_from_to(p2, tC, net)\nadd_arc_from_to(tC, p3, net)\nadd_arc_from_to(p3, tD, net)\nadd_arc_from_to(tD, p4, net)\nim = Marking({p0: 1})\nfm = Marking({p4: 0})\n\n# conversion of the reference petri net into behavioral model\nreference_model = petri_net_2_behavioral_model(net, im, fm)\n\nlog_source([\"ABCD\", \"ABEFG\"]).pipe(\n    behavioral_conformance(reference_model)\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>(1.0, 0.0, 1, 2)\n(1.0, 0.5, 1, 3)\n(1.0, 1.0, 1, 4)\n(1.0, 0.0, 1, 6)\n(0.5, -1, -1, 7)\n(0.3333333333333333, -1, -1, 8)\n(0.25, -1, -1, 9)\n</code></pre>"},{"location":"pybeamline/conformance/behavioral_conformance/#references","title":"References","text":"<p>The algorithm is described in:</p> <ul> <li>Online Conformance Checking Using Behavioural Patterns   A. Burattin, S. van Zelst, A. Armas-Cervantes, B. van Dongen, J. Carmona   In Proceedings of BPM 2018; Sydney, Australia; September 2018.</li> </ul>"},{"location":"pybeamline/conformance/soft_conformance/","title":"soft_conformance","text":"<p>This conformance approach uses a descriptive model (i.e., a pattern of the observed behavior over a certain amount of time) which is not necessarily referring to the control-flow (e.g., it can be based on the social network of handover of work). To create such a model you need to specify the states and the probability of transitioning.</p>"},{"location":"pybeamline/conformance/soft_conformance/#parameters","title":"Parameters","text":"<ul> <li> <p>model: <code>Pdfa</code>   The reference PDFA model.</p> </li> <li> <p>alpha: <code>float</code>   Likelihood of a random walk (i.e., the parameter \u03b1).</p> </li> <li> <p>max_cases_to_store: <code>int</code> default <code>1000</code>   Maximum number of cases to store.</p> </li> <li> <p>result_refresh_rate: <code>int</code> default <code>10</code>   How often the results should be propagated.</p> </li> </ul>"},{"location":"pybeamline/conformance/soft_conformance/#returned-type","title":"Returned type","text":"<p>The returned output has type <code>SoftConformanceReport</code> which is <code>Dict[str, SoftConformanceStatus]</code>, where the key is the case id and the <code>SoftConformanceStatus</code> has the following methods:</p> <ul> <li><code>get_last_probability()</code></li> <li><code>get_sequence_probability()</code></li> <li><code>get_sequence_log_probability()</code></li> <li><code>get_mean_probabilities()</code></li> <li><code>get_soft_conformance()</code></li> <li><code>get_last_update()</code></li> </ul>"},{"location":"pybeamline/conformance/soft_conformance/#example","title":"Example","text":"<pre><code>from pybeamline.algorithms.conformance.soft.pdfa_conformance import soft_conformance\nfrom pybeamline.algorithms.lambda_operator import lambda_operator\nfrom pybeamline.models.pdfa.pdfa import Pdfa\nfrom pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.sources import log_source\n\npdfa = Pdfa()\npdfa.add_node(\"A\")\npdfa.add_node(\"B\")\npdfa.add_node(\"C\")\npdfa.add_edge(\"A\", \"A\", 0.2)\npdfa.add_edge(\"A\", \"B\", 0.8)\npdfa.add_edge(\"B\", \"C\", 1.0)\n\nlog_source([\"ABC\", \"ACBDE\"]).pipe(\n    soft_conformance(pdfa, 0.5, 100, 1),\n    lambda_operator(lambda x: sum(c.get_soft_conformance() for c in x.values()) / len(x))\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>0.0\n0.85\n0.925\n0.4625\n0.5875\n0.5875\n0.5458333333333334\n0.525\n</code></pre>"},{"location":"pybeamline/conformance/soft_conformance/#references","title":"References","text":"<p>The algorithm is described in:</p> <ul> <li>Online Soft Conformance Checking: Any Perspective Can Indicate Deviations   A. Burattin   In arXiv:2201.09222, Jan. 2022.</li> </ul>"},{"location":"pybeamline/conformance/temporal_profile_conformance/","title":"temporal_profile_conformance","text":"<p>An algorithm to compute the temporal profile conformance.</p>"},{"location":"pybeamline/conformance/temporal_profile_conformance/#parameters","title":"Parameters","text":"<ul> <li> <p>temporal_profile: <code>TemporalProfile</code>   The reference temporal profile for the conformance. See <code>temporal_profile_discovery_mapper</code>.</p> </li> <li> <p>parameters: <code>Dict</code> default: <code>None</code>   Set of additional parameters as specified in <code>pm4py.streaming.algo.conformance.temporal.variants.classic.TemporalProfileStreamingConformance</code>.</p> </li> </ul>"},{"location":"pybeamline/conformance/temporal_profile_conformance/#returned-type","title":"Returned type","text":"<p>The returned output has type <code>pm4py.util.typing.TemporalProfileStreamingConfResults</code>.</p>"},{"location":"pybeamline/conformance/temporal_profile_conformance/#example","title":"Example","text":"<pre><code>from pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.sources import log_source\nfrom pybeamline.stream.base_sink import BaseSink\nfrom pybeamline.algorithms.discovery.temporal_profile import temporal_profile_discovery_mapper\nfrom pybeamline.algorithms.conformance.temporal_profile.temporal_profile_conformance import temporal_profile_conformance\n\nstream_for_learning = [\"ABC\",\"ABC\",\"DEF\"]\nstream_for_conformance = [\"ABC\",\"ABC\",\"DEF\"]\n\n# construction of the temporal profile\nclass model_store(BaseSink):\n    model = None\n    def consume(self, item):\n        self.model = item\n\nsink = model_store()\n\nlog_source().pipe(\n    temporal_profile_discovery_mapper()\n).subscribe(sink)\n\n# conformance with the constructed temporal profile\nlog_source(stream_for_conformance).pipe(\n    temporal_profile_conformance(temporal_profile=sink.model)\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>{}\n{}\n{'case_1': [['case_1', 'A', 'C', 0.0, 10.772515040758183], ['case_1', 'B', 'C', 0.0, 19.209437368002256]]}\n{'case_1': [['case_1', 'A', 'C', 0.0, 10.772515040758183], ['case_1', 'B', 'C', 0.0, 19.209437368002256]]}\n{'case_1': [['case_1', 'A', 'C', 0.0, 10.772515040758183], ['case_1', 'B', 'C', 0.0, 19.209437368002256]]}\n{'case_1': [['case_1', 'A', 'C', 0.0, 10.772515040758183], ['case_1', 'B', 'C', 0.0, 19.209437368002256]], 'case_2': [['case_2', 'A', 'C', 0.0, 10.772515040758183], ['case_2', 'B', 'C', 0.0, 19.209437368002256]]}\n{'case_1': [['case_1', 'A', 'C', 0.0, 10.772515040758183], ['case_1', 'B', 'C', 0.0, 19.209437368002256]], 'case_2': [['case_2', 'A', 'C', 0.0, 10.772515040758183], ['case_2', 'B', 'C', 0.0, 19.209437368002256]]}\n{'case_1': [['case_1', 'A', 'C', 0.0, 10.772515040758183], ['case_1', 'B', 'C', 0.0, 19.209437368002256]], 'case_2': [['case_2', 'A', 'C', 0.0, 10.772515040758183], ['case_2', 'B', 'C', 0.0, 19.209437368002256]], 'case_3': [['case_3', 'D', 'E', 0.0, 9223372036854775807]]}\n{'case_1': [['case_1', 'A', 'C', 0.0, 10.772515040758183], ['case_1', 'B', 'C', 0.0, 19.209437368002256]], 'case_2': [['case_2', 'A', 'C', 0.0, 10.772515040758183], ['case_2', 'B', 'C', 0.0, 19.209437368002256]], 'case_3': [['case_3', 'D', 'E', 0.0, 9223372036854775807], ['case_3', 'D', 'F', 0.0, 9223372036854775807], ['case_3', 'E', 'F', 0.0, 9223372036854775807]]}\n</code></pre>"},{"location":"pybeamline/conformance/temporal_profile_conformance/#references","title":"References","text":"<p>The algorithm is described in publications:</p> <ul> <li>Temporal Conformance Checking at Runtime Based on Time-infused Process Models   F. Stertz, J/ Mangler, and S. Rinderle-Ma   In arXiv preprint arXiv:2008.07262 (2020).</li> </ul>"},{"location":"pybeamline/discovery/heuristics_miner_lossy_counting/","title":"heuristics_miner_lossy_counting","text":"<p>An algorithm to mine a Heuristics Net using the Lossy Counting algorithm.</p>"},{"location":"pybeamline/discovery/heuristics_miner_lossy_counting/#parameters","title":"Parameters","text":"<ul> <li> <p>model_update_frequency: <code>int</code> default: <code>10</code>   How often (in number of events) the model should be returned.</p> </li> <li> <p>max_approx_error: <code>Float</code> default: <code>0.001</code>   The maximum approximation error in the Lossy Counting of the ferquencies.</p> </li> <li> <p>dependency_threshold: <code>Float</code> default: <code>0.5</code>   The Heuristics Miner's dependency threshold.</p> </li> <li> <p>and_threshold: <code>Float</code> default: <code>0.8</code>   The Heuristics Miner's AND threshold.</p> </li> </ul>"},{"location":"pybeamline/discovery/heuristics_miner_lossy_counting/#returned-type","title":"Returned type","text":"<p>The returned output has type <code>pm4py.objects.heuristics_net.obj.HeuristicsNet</code>. See https://processintelligence.solutions/pm4py/api?page=pm4py.objects.heuristics_net.html%23pm4py.objects.heuristics_net.obj.HeuristicsNet.</p>"},{"location":"pybeamline/discovery/heuristics_miner_lossy_counting/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.algorithms.discovery.heuristics_miner_lossy_counting import heuristics_miner_lossy_counting\nfrom pybeamline.sinks.print_sink import print_sink\n\nlog_source([\"ABC\",\"ABC\",\"DEF\"]).pipe(\n    heuristics_miner_lossy_counting(model_update_frequency=4)\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>{'A': (node:A connections:{B:[0.5]}), 'B': (node:B connections:{C:[0.5]}), 'C': (node:C connections:{})}\n{'A': (node:A connections:{B:[0.6666666666666666]}), 'B': (node:B connections:{C:[0.6666666666666666]}), 'C': (node:C connections:{})}\n</code></pre>"},{"location":"pybeamline/discovery/heuristics_miner_lossy_counting/#references","title":"References","text":"<p>The algorithm is described in publications:</p> <ul> <li>Control-flow Discovery from Event Streams   A. Burattin, A. Sperduti, W. M. P. van der Aalst   In Proceedings of the Congress on Evolutionary Computation (IEEE WCCI CEC 2014); Beijing, China; July 6-11, 2014.</li> <li>Heuristics Miners for Streaming Event Data   A. Burattin, A. Sperduti, W. M. P. van der Aalst   In CoRR abs/1212.6383, Dec. 2012.</li> </ul>"},{"location":"pybeamline/discovery/heuristics_miner_lossy_counting_budget/","title":"heuristics_miner_lossy_counting_budget","text":"<p>An algorithm to mine a Heuristics Net using the Lossy Counting with Budget algorithm.</p>"},{"location":"pybeamline/discovery/heuristics_miner_lossy_counting_budget/#parameters","title":"Parameters","text":"<ul> <li> <p>model_update_frequency: <code>int</code> default: <code>10</code>   How often (in number of events) the model should be returned.</p> </li> <li> <p>budget: <code>int</code> default: <code>100</code>   The maximum budget available to the algorithm.</p> </li> <li> <p>dependency_threshold: <code>Float</code> default: <code>0.5</code>   The Heuristics Miner's dependency threshold.</p> </li> <li> <p>and_threshold: <code>Float</code> default: <code>0.8</code>   The Heuristics Miner's AND threshold.</p> </li> </ul>"},{"location":"pybeamline/discovery/heuristics_miner_lossy_counting_budget/#returned-type","title":"Returned type","text":"<p>The returned output has type <code>pm4py.objects.heuristics_net.obj.HeuristicsNet</code>. See https://processintelligence.solutions/pm4py/api?page=pm4py.objects.heuristics_net.html%23pm4py.objects.heuristics_net.obj.HeuristicsNet.</p>"},{"location":"pybeamline/discovery/heuristics_miner_lossy_counting_budget/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.algorithms.discovery.heuristics_miner_lossy_counting_budget import heuristics_miner_lossy_counting_budget\nfrom pybeamline.sinks.print_sink import print_sink\n\nlog_source([\"ABC\",\"ABC\",\"DEF\"]).pipe(\n    heuristics_miner_lossy_counting_budget(model_update_frequency=3, budget=4)\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>{'A': (node:A connections:{B:[0.5]}), 'B': (node:B connections:{C:[0.5]}), 'C': (node:C connections:{})}\n{'A': (node:A connections:{B:[0.6666666666666666]}), 'B': (node:B connections:{C:[0.6666666666666666]}), 'C': (node:C connections:{})}\n{'E': (node:E connections:{F:[0.5]}), 'F': (node:F connections:{})}\n</code></pre>"},{"location":"pybeamline/discovery/heuristics_miner_lossy_counting_budget/#references","title":"References","text":"<p>The algorithm is described in publications:</p> <ul> <li>Control-flow Discovery from Event Streams   A. Burattin, A. Sperduti, W. M. P. van der Aalst   In Proceedings of the Congress on Evolutionary Computation (IEEE WCCI CEC 2014); Beijing, China; July 6-11, 2014.</li> <li>Heuristics Miners for Streaming Event Data   A. Burattin, A. Sperduti, W. M. P. van der Aalst   In CoRR abs/1212.6383, Dec. 2012.</li> </ul>"},{"location":"pybeamline/discovery/oc_merge/","title":"oc_merge","text":"<p>Operator that sits downstream of the <code>oc_operator</code> in the streaming pipeline. It merges the output from multiple miners -- per-object-type control-flow models (DFGs), activity-object relations (AERs), and inclusion commands -- into a synchronized and semantically coherent object-centric process model.</p> <p>See also <code>oc_operator</code> and <code>oc_visualizer_sink</code>.</p>"},{"location":"pybeamline/discovery/oc_merge/#parameters","title":"Parameters","text":"<ul> <li>None</li> </ul>"},{"location":"pybeamline/discovery/oc_merge/#returned-type","title":"Returned type","text":"<p>A stream of synchronized models in the following format:</p> <pre><code>{\n  \"ocdfg\": OCDFG(...),\n  \"aer\": AER(...)\n}\n</code></pre> <p>These models represent a current snapshot of the object-centric behavior in the system, respecting only the currently active object types.</p>"},{"location":"pybeamline/discovery/oc_merge/#example","title":"Example","text":"<pre><code>from pybeamline.algorithms.oc.oc_merge_operator import oc_merge_operator\nfrom pybeamline.algorithms.oc.oc_operator import oc_operator\nfrom pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.sources.dict_ocel_test_source import dict_test_ocel_source\n\ntrace_1 = [\n    {\"activity\": \"Register Customer\", \"objects\": {\"Customer\": [\"c1\"]}},\n    {\"activity\": \"Create Order\", \"objects\": {\"Customer\": [\"c1\"], \"Order\": [\"o1\"]}},\n    {\"activity\": \"Add Item\", \"objects\": {\"Order\": [\"o1\"], \"Item\": [\"i1\"]}},\n    {\"activity\": \"Add Item\", \"objects\": {\"Order\": [\"o1\"], \"Item\": [\"i2\"]}},\n    {\"activity\": \"Ship Order\", \"objects\": {\"Item\": [\"i1\", \"i2\"], \"Order\": [\"o1\"]}}\n]\n\ntest_source = dict_test_ocel_source([(trace_1, 10)]).pipe(\n    oc_operator(),\n    oc_merge_operator(),\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>{'ocdfg': OCDFG(activities=['Add Item', 'Create Order', 'Ship Order'], object_types=['Order'], edges={'Order': {('Add Item', 'Ship Order'): 4, ('Create Order', 'Add Item'): 5, ('Add Item', 'Add Item'): 5}}, start_activities={'Order': {'Create Order'}}, end_activities={'Order': {'Ship Order'}}), 'aer': ActivityER(activities=[], object_types={}, relations={})}\n{'ocdfg': OCDFG(activities=['Add Item', 'Create Order', 'Ship Order'], object_types=['Item', 'Order'], edges={'Order': {('Add Item', 'Ship Order'): 4, ('Create Order', 'Add Item'): 5, ('Add Item', 'Add Item'): 5}, 'Item': {('Add Item', 'Ship Order'): 9}}, start_activities={'Order': {'Create Order'}, 'Item': {'Add Item'}}, end_activities={'Order': {'Ship Order'}, 'Item': {'Ship Order'}}), 'aer': ActivityER(activities=[], object_types={}, relations={})}\n{'ocdfg': OCDFG(activities=['Add Item', 'Create Order', 'Ship Order'], object_types=['Item', 'Order'], edges={'Order': {('Add Item', 'Ship Order'): 4, ('Create Order', 'Add Item'): 5, ('Add Item', 'Add Item'): 5}, 'Item': {('Add Item', 'Ship Order'): 9}}, start_activities={'Order': {'Create Order'}, 'Item': {'Add Item'}}, end_activities={'Order': {'Ship Order'}, 'Item': {'Ship Order'}}), 'aer': ActivityER(activities=['Add Item', 'Create Order', 'Ship Order'], object_types={'Create Order': {'Order'}, 'Add Item': {'Item', 'Order'}, 'Ship Order': {'Item', 'Order'}}, relations={'Add Item': {('Item', 'Order'): &lt;Cardinality.ONE_TO_ONE: '1..1'&gt;}, 'Ship Order': {('Item', 'Order'): &lt;Cardinality.MANY_TO_ONE: 'N..1'&gt;}})}\n{'ocdfg': OCDFG(activities=['Add Item', 'Create Order', 'Ship Order'], object_types=['Item', 'Order'], edges={'Order': {('Add Item', 'Ship Order'): 4, ('Create Order', 'Add Item'): 5, ('Add Item', 'Add Item'): 5}, 'Item': {('Add Item', 'Ship Order'): 9}}, start_activities={'Order': {'Create Order'}, 'Item': {'Add Item'}}, end_activities={'Order': {'Ship Order'}, 'Item': {'Ship Order'}}), 'aer': ActivityER(activities=['Add Item', 'Create Order', 'Ship Order'], object_types={'Create Order': {'Order'}, 'Add Item': {'Item', 'Order'}, 'Ship Order': {'Item', 'Order'}}, relations={'Add Item': {('Item', 'Order'): &lt;Cardinality.ONE_TO_ONE: '1..1'&gt;}, 'Ship Order': {('Item', 'Order'): &lt;Cardinality.MANY_TO_ONE: 'N..1'&gt;}})}\n{'ocdfg': OCDFG(activities=['Add Item', 'Create Order', 'Ship Order'], object_types=['Item', 'Order'], edges={'Order': {('Add Item', 'Ship Order'): 4, ('Create Order', 'Add Item'): 5, ('Add Item', 'Add Item'): 5}, 'Item': {('Add Item', 'Ship Order'): 9}}, start_activities={'Order': {'Create Order'}, 'Item': {'Add Item'}}, end_activities={'Order': {'Ship Order'}, 'Item': {'Ship Order'}}), 'aer': ActivityER(activities=['Add Item', 'Create Order', 'Ship Order'], object_types={'Create Order': {'Order'}, 'Add Item': {'Item', 'Order'}, 'Ship Order': {'Item', 'Order'}}, relations={'Add Item': {('Item', 'Order'): &lt;Cardinality.ONE_TO_ONE: '1..1'&gt;}, 'Ship Order': {('Item', 'Order'): &lt;Cardinality.MANY_TO_ONE: 'N..1'&gt;}})}\n{'ocdfg': OCDFG(activities=['Add Item', 'Create Order', 'Register Customer', 'Ship Order'], object_types=['Customer', 'Item', 'Order'], edges={'Order': {('Add Item', 'Ship Order'): 4, ('Create Order', 'Add Item'): 5, ('Add Item', 'Add Item'): 5}, 'Item': {('Add Item', 'Ship Order'): 9}, 'Customer': {('Register Customer', 'Create Order'): 9}}, start_activities={'Order': {'Create Order'}, 'Item': {'Add Item'}, 'Customer': {'Register Customer'}}, end_activities={'Order': {'Ship Order'}, 'Item': {'Ship Order'}, 'Customer': {'Create Order'}}), 'aer': ActivityER(activities=['Add Item', 'Create Order', 'Register Customer', 'Ship Order'], object_types={'Register Customer': {'Customer'}, 'Create Order': {'Customer', 'Order'}, 'Add Item': {'Item', 'Order'}, 'Ship Order': {'Item', 'Order'}}, relations={'Create Order': {('Customer', 'Order'): &lt;Cardinality.ONE_TO_ONE: '1..1'&gt;}, 'Add Item': {('Item', 'Order'): &lt;Cardinality.ONE_TO_ONE: '1..1'&gt;}, 'Ship Order': {('Item', 'Order'): &lt;Cardinality.MANY_TO_ONE: 'N..1'&gt;}})}\n{'ocdfg': OCDFG(activities=['Add Item', 'Create Order', 'Register Customer', 'Ship Order'], object_types=['Customer', 'Item', 'Order'], edges={'Order': {('Add Item', 'Ship Order'): 9, ('Create Order', 'Add Item'): 10, ('Add Item', 'Add Item'): 10}, 'Item': {('Add Item', 'Ship Order'): 9}, 'Customer': {('Register Customer', 'Create Order'): 9}}, start_activities={'Order': {'Create Order'}, 'Item': {'Add Item'}, 'Customer': {'Register Customer'}}, end_activities={'Order': {'Ship Order'}, 'Item': {'Ship Order'}, 'Customer': {'Create Order'}}), 'aer': ActivityER(activities=['Add Item', 'Create Order', 'Register Customer', 'Ship Order'], object_types={'Register Customer': {'Customer'}, 'Create Order': {'Customer', 'Order'}, 'Add Item': {'Item', 'Order'}, 'Ship Order': {'Item', 'Order'}}, relations={'Create Order': {('Customer', 'Order'): &lt;Cardinality.ONE_TO_ONE: '1..1'&gt;}, 'Add Item': {('Item', 'Order'): &lt;Cardinality.ONE_TO_ONE: '1..1'&gt;}, 'Ship Order': {('Item', 'Order'): &lt;Cardinality.MANY_TO_ONE: 'N..1'&gt;}})}\n{'ocdfg': OCDFG(activities=['Add Item', 'Create Order', 'Register Customer', 'Ship Order'], object_types=['Customer', 'Item', 'Order'], edges={'Order': {('Add Item', 'Ship Order'): 9, ('Create Order', 'Add Item'): 10, ('Add Item', 'Add Item'): 10}, 'Item': {('Add Item', 'Ship Order'): 19}, 'Customer': {('Register Customer', 'Create Order'): 9}}, start_activities={'Order': {'Create Order'}, 'Item': {'Add Item'}, 'Customer': {'Register Customer'}}, end_activities={'Order': {'Ship Order'}, 'Item': {'Ship Order'}, 'Customer': {'Create Order'}}), 'aer': ActivityER(activities=['Add Item', 'Create Order', 'Register Customer', 'Ship Order'], object_types={'Register Customer': {'Customer'}, 'Create Order': {'Customer', 'Order'}, 'Add Item': {'Item', 'Order'}, 'Ship Order': {'Item', 'Order'}}, relations={'Create Order': {('Customer', 'Order'): &lt;Cardinality.ONE_TO_ONE: '1..1'&gt;}, 'Add Item': {('Item', 'Order'): &lt;Cardinality.ONE_TO_ONE: '1..1'&gt;}, 'Ship Order': {('Item', 'Order'): &lt;Cardinality.MANY_TO_ONE: 'N..1'&gt;}})}\n</code></pre>"},{"location":"pybeamline/discovery/oc_merge/#references","title":"References","text":"<p>The algorithm is described in publication:</p> <ul> <li>Push your objects into streams! Streaming OCPM, Take 1   J.M. Mikkelsen, A. Rivkin and A. Burattin   In Proceedings of the Stream Management &amp; Analytics for Process Mining ICPM Workshop (SMA4PM 2025); Montevideo, Uruguay; October 20, 2025.</li> </ul>"},{"location":"pybeamline/discovery/oc_operator/","title":"oc_operator","text":"<p>Configures and returns a reactive operator that enables real-time discovery of object-centric process models and activity-entity relationship (AER) diagrams from a stream of <code>BOEvent</code> events.</p> <p>See also <code>oc_merge</code> and <code>oc_visualizer_sink</code>.</p>"},{"location":"pybeamline/discovery/oc_operator/#parameters","title":"Parameters","text":"<ul> <li> <p>inclusion_strategy: <code>InclusionStrategy</code> default: <code>None</code>   Determines when object types are considered active/inactive (e.g., based on relative frequency or lossy counting).</p> </li> <li> <p>control_flow: <code>Dict[str, Callable[[], StreamMiner]]</code> default: <code>None</code>   Predefined miners for each object type (static mode).</p> </li> <li> <p>aer_model_update_frequency: <code>int</code> default: <code>30</code>   Frequency (in #events) for emitting AER model updates.</p> </li> <li> <p>aer_model_max_approx_error: <code>Float</code> default: <code>0.01</code>   Maximum error tolerance for lossy counting in AER miner (lower = more accurate but higher memory).</p> </li> <li> <p>default_miner: <code>Callable[[], StreamMiner]</code> default: <code>None</code>   Miner to use in dynamic mode for unseen object types.</p> </li> </ul> <p>Modes of Operation:</p> <ul> <li>Static Mode: You provide a <code>control_flow</code> dictionary that maps object types to specific miners. Thereby only selected object types are processed, and miners are created based on the provided functions.</li> <li>Dynamic Mode: If <code>control_flow</code> is not provided, miners are created on-the-fly using <code>default_miner</code>.</li> </ul>"},{"location":"pybeamline/discovery/oc_operator/#returned-type","title":"Returned type","text":"<p>A stream where each message is of one of the following types:</p> <ul> <li> <p><code>{\"type\": \"dfg\", \"object_type\": ..., \"model\": ...}</code>   Object-type-specific control-flow models (e.g., Heuristics Net / DFG)</p> </li> <li> <p><code>{\"type\": \"aer\", \"model\": ...}</code>   Activity-Entity Relationship diagrams across all object types</p> </li> <li> <p><code>{\"type\": \"command\", \"command\": ACTIVE/INACTIVE, \"object_type\": ...}</code>   Inclusion/exclusion signals for adaptive concept drift handling</p> </li> </ul>"},{"location":"pybeamline/discovery/oc_operator/#example","title":"Example","text":"<pre><code>from pybeamline.algorithms.discovery import heuristics_miner_lossy_counting, heuristics_miner_lossy_counting_budget\nfrom pybeamline.algorithms.oc.oc_operator import oc_operator\nfrom pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.sources.dict_ocel_test_source import dict_test_ocel_source\n\ntrace_1 = [\n    {\"activity\": \"Register Customer\", \"objects\": {\"Customer\": [\"c1\"]}},\n    {\"activity\": \"Create Order\", \"objects\": {\"Customer\": [\"c1\"], \"Order\": [\"o1\"]}},\n    {\"activity\": \"Add Item\", \"objects\": {\"Order\": [\"o1\"], \"Item\": [\"i1\"]}},\n    {\"activity\": \"Add Item\", \"objects\": {\"Order\": [\"o1\"], \"Item\": [\"i2\"]}},\n    {\"activity\": \"Ship Order\", \"objects\": {\"Item\": [\"i1\", \"i2\"], \"Order\": [\"o1\"]}}\n]\ntrace_2 = [\n    {\"activity\": \"Register Guest\", \"objects\": {\"Guest\": [\"g1\"]}},\n    {\"activity\": \"Create Booking\", \"objects\": {\"Guest\": [\"g1\"], \"Booking\": [\"b1\"]}},\n    {\"activity\": \"Reserve Room\", \"objects\": {\"Booking\": [\"b1\"]}},\n    {\"activity\": \"Check In\", \"objects\": {\"Guest\": [\"g1\"], \"Booking\": [\"b1\"]}},\n    {\"activity\": \"Check Out\", \"objects\": {\"Guest\": [\"g1\"], \"Booking\": [\"b1\"]}}\n]\n\ncontrol_flow = {\n    \"Customer\": lambda : heuristics_miner_lossy_counting(\n        model_update_frequency=5,\n        max_approx_error=0.2\n    ),\n    \"Order\": lambda : heuristics_miner_lossy_counting_budget( # Individual tuning for Order\n        model_update_frequency=4,\n    ),\n    \"Item\": lambda : heuristics_miner_lossy_counting(\n        model_update_frequency=4,\n        max_approx_error=0.1\n    )\n}\n\ntest_source = dict_test_ocel_source([(trace_1, 2), (trace_2, 3)]).pipe(\n    oc_operator(control_flow=control_flow),\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>{'type': 'command', 'command': &lt;Command.ACTIVE: 'active'&gt;, 'object_type': 'Item'}\n{'type': 'dfg', 'object_type': 'Item', 'model': {'Add Item': (node:Add Item connections:{Ship Order:[0.5]}), 'Ship Order': (node:Ship Order connections:{})}}\n{'type': 'command', 'command': &lt;Command.ACTIVE: 'active'&gt;, 'object_type': 'Order'}\n{'type': 'dfg', 'object_type': 'Order', 'model': {'Create Order': (node:Create Order connections:{Add Item:[0.5]}), 'Add Item': (node:Add Item connections:{Add Item:[0.5], Ship Order:[0.5]}), 'Ship Order': (node:Ship Order connections:{})}}\n{'type': 'command', 'command': &lt;Command.ACTIVE: 'active'&gt;, 'object_type': 'Customer'}\n{'type': 'dfg', 'object_type': 'Customer', 'model': {'Register Customer': (node:Register Customer connections:{Create Order:[0.6666666666666666]}), 'Create Order': (node:Create Order connections:{})}}\n{'type': 'dfg', 'object_type': 'Item', 'model': {'Add Item': (node:Add Item connections:{Ship Order:[0.75]}), 'Ship Order': (node:Ship Order connections:{})}}\n{'type': 'dfg', 'object_type': 'Order', 'model': {'Create Order': (node:Create Order connections:{Add Item:[0.6666666666666666]}), 'Add Item': (node:Add Item connections:{Add Item:[0.6666666666666666], Ship Order:[0.6666666666666666]}), 'Ship Order': (node:Ship Order connections:{})}}\n</code></pre>"},{"location":"pybeamline/discovery/oc_operator/#references","title":"References","text":"<p>The algorithm is described in publication:</p> <ul> <li>Push your objects into streams! Streaming OCPM, Take 1   J.M. Mikkelsen, A. Rivkin and A. Burattin   In Proceedings of the Stream Management &amp; Analytics for Process Mining ICPM Workshop (SMA4PM 2025); Montevideo, Uruguay; October 20, 2025.</li> </ul>"},{"location":"pybeamline/discovery/simple_dfg_miner/","title":"simple_dfg_miner","text":"<p>An algorithm that simply constructs the DFG considering infinite amount of memory available.</p>"},{"location":"pybeamline/discovery/simple_dfg_miner/#parameters","title":"Parameters","text":"<ul> <li> <p>model_update_frequency: <code>int</code> default: <code>10</code>   How often (in number of events) the model should be returned.</p> </li> <li> <p>min_relative_frequency: <code>Float</code> default: <code>0.75</code>    Minimum relative frequency that a directly follow relations should have to be generated.</p> </li> </ul>"},{"location":"pybeamline/discovery/simple_dfg_miner/#returned-type","title":"Returned type","text":"<p>The returned output has type <code>Tuple[int, Dict]]</code>. The first component is the number of observed events, the second is a dictionary where the key is the directly follow relation, the value is the frequency of such relation.</p>"},{"location":"pybeamline/discovery/simple_dfg_miner/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.sources import log_source\nfrom pybeamline.algorithms.discovery.dfg_miner import simple_dfg_miner\nfrom pybeamline.sinks.print_sink import print_sink\n\nlog_source([\"ABC\",\"ABC\",\"DEF\"]).pipe(\n    simple_dfg_miner(model_update_frequency=3, min_relative_frequency=0.4)\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>(3, {('A', 'B'): 1.0, ('B', 'C'): 1.0})\n(6, {('A', 'B'): 1.0, ('B', 'C'): 1.0})\n(9, {('A', 'B'): 1.0, ('B', 'C'): 1.0, ('D', 'E'): 0.5, ('E', 'F'): 0.5})\n</code></pre>"},{"location":"pybeamline/discovery/temporal_profile_discovery_mapper/","title":"temporal_profile_discovery_mapper","text":"<p>An algorithm to extract a temporal profile.</p>"},{"location":"pybeamline/discovery/temporal_profile_discovery_mapper/#parameters","title":"Parameters","text":"<ul> <li>None</li> </ul>"},{"location":"pybeamline/discovery/temporal_profile_discovery_mapper/#returned-type","title":"Returned type","text":"<p>The returned output has type <code>pm4py.util.typing.TemporalProfile</code>. See <code>temporal_profile_conformance</code>.</p>"},{"location":"pybeamline/discovery/temporal_profile_discovery_mapper/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.algorithms.discovery.temporal_profile import temporal_profile_discovery_mapper\nfrom pybeamline.sinks.print_sink import print_sink\n\nlog_source([\"ABC\",\"ABC\",\"DEF\"]).pipe(\n    temporal_profile_discovery_mapper()\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>{}\n{('A', 'B'): (0.088598, 0.0)}\n{('A', 'B'): (0.088598, 0.0), ('A', 'C'): (0.14812, 0.0), ('B', 'C'): (0.059522, 0.0)}\n{('A', 'B'): (0.088598, 0.0), ('A', 'C'): (0.14812, 0.0), ('B', 'C'): (0.059522, 0.0)}\n{('A', 'B'): (0.061631, 0.03813709713651525), ('A', 'C'): (0.14812, 0.0), ('B', 'C'): (0.059522, 0.0)}\n{('A', 'B'): (0.061631, 0.03813709713651525), ('A', 'C'): (0.1078875, 0.05689734714817555), ('B', 'C'): (0.0462565, 0.018760250011660293)}\n{('A', 'B'): (0.061631, 0.03813709713651525), ('A', 'C'): (0.1078875, 0.05689734714817555), ('B', 'C'): (0.0462565, 0.018760250011660293)}\n{('A', 'B'): (0.061631, 0.03813709713651525), ('A', 'C'): (0.1078875, 0.05689734714817555), ('B', 'C'): (0.0462565, 0.018760250011660293), ('D', 'E'): (0.029873, 0.0)}\n{('A', 'B'): (0.061631, 0.03813709713651525), ('A', 'C'): (0.1078875, 0.05689734714817555), ('B', 'C'): (0.0462565, 0.018760250011660293), ('D', 'E'): (0.029873, 0.0), ('D', 'F'): (0.060462999999999996, 0.0), ('E', 'F'): (0.03059, 0.0)}\n</code></pre>"},{"location":"pybeamline/discovery/temporal_profile_discovery_mapper/#references","title":"References","text":"<p>The algorithm is described in publications:</p> <ul> <li>Temporal Conformance Checking at Runtime Based on Time-infused Process Models   F. Stertz, J/ Mangler, and S. Rinderle-Ma   In arXiv preprint arXiv:2008.07262 (2020).</li> </ul>"},{"location":"pybeamline/examples/full-cycle/","title":"Full cycle","text":"<p>In this example we are going to see how to use <code>pyBeamline</code> to go all the way from the simulation of an MQTT-XES stream to its mining and the visualization of the results as a Petri net that changes over time.</p> <p>The picture below depicts the architecture of the example.</p>  sequenceDiagram     Emitter -&gt;&gt; MQTT Broker: new event     MQTT Broker -&gt;&gt; Miner: notifies event     activate Miner     Miner --&gt;&gt; MQTT Broker: new model     deactivate Miner     MQTT Broker -&gt;&gt; Results Visualizer: notifies new model  <p>There is an MQTT Broker at the center. The <code>Emitter</code> is in charge of generating the events as MQTT-XES. The <code>Miner</code>, which is subscribed to the MQTT-XES, consumes the events and performs the discovery. It also publishes the models (as Graphviz DOR render of a Petri net) back into the MQTT broker. The <code>ResultVisualizer</code> is a static webpage that connects to the MQTT Broker and subscribes to the models which are rendered and presented as output.</p> <p>All these components can be tested without the need to install anything: it is possible to use a public MQTT broker, the <code>Emitter</code> and the <code>Miner</code> can be hosted on Google Colab (see links below in each section), and a deployment of <code>ResultVisualizer</code> is also available (see link below).</p>"},{"location":"pybeamline/examples/full-cycle/#the-emitter-component","title":"The <code>Emitter</code> component","text":"<p>The <code>Emitter</code> first defines the destination of the MQTT messages, after that a list of all possible traces (referring to a process that contains a sequence, a parallel split/join and an XOR split/join) is reported and finally the system connects to the MQTT broker and starts an infinite loop that publishes one event after the other according to the MQTT-XES specification.</p> <p>Here is the complete code of the <code>Emitter</code>:</p> <pre><code>import paho.mqtt.client as mqtt\nimport time\n\nmqtt_source = {\n    \"broker\": 'broker.emqx.io',\n    \"port\": 1883,\n    \"topic\": 'pybeamline/source'\n}\n\ntraces = []\ntraces.append([\"A\", \"B\", \"C\"])\ntraces.append([\"A\", \"C\", \"B\"])\ntraces.append([\"A\", \"B\", \"C\", \"F\", \"D\"])\ntraces.append([\"A\", \"C\", \"B\", \"F\", \"E\"])\ntraces.append([\"A\", \"B\", \"C\", \"F\", \"E\", \"G\", \"I\"])\ntraces.append([\"A\", \"C\", \"B\", \"F\", \"D\", \"H\", \"I\"])\n\nc = mqtt.Client()\nc.connect(mqtt_source[\"broker\"], mqtt_source[\"port\"], 60)\n\nprocess_name = \"test\"\ntrace_id = 0\nwhile True:\n    for trace in traces:\n        trace_id += 1\n        for activity in trace:\n            c.publish(mqtt_source[\"topic\"] + \"/\" + process_name + \"/C\" + str(trace_id) + \"/\" + activity, \"{}\")\n            time.sleep(0.5)\n</code></pre> <p>Currently, between each event, the scripts waits for 0.5 seconds.</p> <p>Please note that this code is not terminating on purpose: the goal is that events are continuously generated and the generation stops when the script is forced to terminate.</p>"},{"location":"pybeamline/examples/full-cycle/#the-miner-component","title":"The <code>Miner</code> component","text":"<p>In order to configure the <code>Miner</code> component it is necessary to specify the two MQTT endpoints referring to where the event messages are sent and where the model updates should be published.</p> <pre><code>mqtt_source = {\n    \"broker\": 'broker.emqx.io',\n    \"port\": 1883,\n    \"topic\": 'pybeamline/source'\n}\n\nmqtt_target = {\n    \"broker\": 'broker.emqx.io',\n    \"port\": 1883,\n    \"topic\": 'pybeamline/output'\n}\n</code></pre> <p>The script ensures a connection to the MQTT endpoint, then it defines a function to transform the Heuristics Net (produced by <code>heuristics_miner_lossy_counting_budget</code> into the Graphviz DOT representation of the translated Petri net) leveraging the PM4PY functions. At the very end, the <code>pyBeamline</code> pipeline is defined: it connects to the <code>mqttxes_source</code> and defines a pipeline that only contains <code>heuristics_miner_lossy_counting_budget</code>. The results are then processes in a <code>lambda</code> function that converts it to Petri net and publishes them to the MQTT broker.</p> <p>Here is the complete code of the <code>Miner</code>:</p> <pre><code>from pybeamline.sources import mqttxes_source\nfrom pybeamline.algorithms.discovery import heuristics_miner_lossy_counting_budget\nfrom pm4py.objects.conversion.heuristics_net import converter as conversion_factory\nfrom pm4py.visualization.petri_net import visualizer as petri_net_visualizer\nimport paho.mqtt.client as mqtt\n\nclient = mqtt.Client()\nclient.connect(mqtt_target[\"broker\"], mqtt_target[\"port\"], 60)\nclient.loop_start()\n\ndef conversion_from_HN_to_Graphviz(heuristics_net):\n  petri_net, initial_marking, final_marking = conversion_factory.apply(heuristics_net)\n  gviz = petri_net_visualizer.apply(petri_net, initial_marking, final_marking)\n  return str(gviz)\n\nmqttxes_source(mqtt_source[\"broker\"], mqtt_source[\"port\"], mqtt_source[\"topic\"]).pipe(\n    heuristics_miner_lossy_counting_budget(model_update_frequency=4, budget=1000, dependency_threshold=0.75)\n).subscribe(lambda x: client.publish(mqtt_target[\"topic\"], conversion_from_HN_to_Graphviz(x)))\n\ninput()\n</code></pre> <p>Please note that the <code>input()</code> at the very end ensures that the script does not terminate.</p>"},{"location":"pybeamline/examples/full-cycle/#the-result-visualizer-component","title":"The <code>Result Visualizer</code> component","text":"<p>This component is just a static HTML page that connects to the MQTT broker (via web sockets, which must be enabled on the MQTT broker) and subscribes to messages on a certain topics. The payload of the message is assumed to be a Graphviz DOT string (as produced by the <code>Miner</code>) and is then converted into and SVG picture which is displayed and updated with each message.</p> <p>A deployment of such component is available at https://people.compute.dtu.dk/andbur/mqtt-graphviz/ and source code is available at https://github.com/beamline/examples-pybeamline/blob/main/full-cycle-example/mqtt-graphviz-visualizer.html. A screenshot of such page is below:</p> <p></p> <p>The complete code of this example is available in the GitHub repository https://github.com/beamline/examples-pybeamline/tree/main/full-cycle-example.</p>"},{"location":"pybeamline/filters/excludes_activity_filter/","title":"excludes_activity_filter","text":"<p>Excludes activities base on their name (<code>concept:name</code>).</p>"},{"location":"pybeamline/filters/excludes_activity_filter/#parameters","title":"Parameters","text":"<ul> <li>activity_names: <code>Iterable[str]</code>   Activity names to filter.</li> </ul>"},{"location":"pybeamline/filters/excludes_activity_filter/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.filters import excludes_activity_filter\n\nlog_source([\"ABC\", \"ACB\", \"EFG\"]).pipe(\n    excludes_activity_filter(\"A\"),\n).subscribe(print_sink())\n</code></pre>"},{"location":"pybeamline/filters/excludes_on_event_attribute_equal_filter/","title":"excludes_on_event_attribute_equal_filter","text":"<p>Excludes events based on the equality of an event attribute.</p>"},{"location":"pybeamline/filters/excludes_on_event_attribute_equal_filter/#parameters","title":"Parameters","text":"<ul> <li> <p>attribute_name: <code>str</code>   Name of the event attribute to filter.</p> </li> <li> <p>attribute_values: <code>Iterable</code>    Values to look for in the attribute.</p> </li> </ul>"},{"location":"pybeamline/filters/excludes_on_event_attribute_equal_filter/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.filters import excludes_on_event_attribute_equal_filter\n\nlog_source(\"test.xes\").pipe(\n    excludes_on_event_attribute_equal_filter(\"event-attrib\", [\"ev\", \"ab\"]),\n).subscribe(print_sink())\n</code></pre>"},{"location":"pybeamline/filters/excludes_on_trace_attribute_equal_filter/","title":"excludes_on_trace_attribute_equal_filter","text":"<p>Excludes events based on the equality of a trace-level attribute.</p>"},{"location":"pybeamline/filters/excludes_on_trace_attribute_equal_filter/#parameters","title":"Parameters","text":"<ul> <li> <p>attribute_name: <code>str</code>   Name of the trace attribute to filter.</p> </li> <li> <p>attribute_values: <code>Iterable</code>    Values to look for in the attribute.</p> </li> </ul>"},{"location":"pybeamline/filters/excludes_on_trace_attribute_equal_filter/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.filters import excludes_on_trace_attribute_equal_filter\n\nlog_source(\"test.xes\").pipe(\n    excludes_on_trace_attribute_equal_filter(\"event-attrib\", [\"ev\", \"ab\"]),\n).subscribe(print_sink())\n</code></pre>"},{"location":"pybeamline/filters/retains_activity_filter/","title":"retains_activity_filter","text":"<p>Retains activities base on their name (<code>concept:name</code>).</p>"},{"location":"pybeamline/filters/retains_activity_filter/#parameters","title":"Parameters","text":"<ul> <li>activity_names: <code>Iterable[str]</code>   Activity names to filter.</li> </ul>"},{"location":"pybeamline/filters/retains_activity_filter/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.filters import retains_activity_filter\n\nlog_source([\"ABC\", \"ACB\", \"EFG\"]).pipe(\n    retains_activity_filter(\"G\")\n).subscribe(print_sink())\n</code></pre>"},{"location":"pybeamline/filters/retains_on_event_attribute_equal_filter/","title":"retains_on_event_attribute_equal_filter","text":"<p>Retains events based on the equality of an event attribute.</p>"},{"location":"pybeamline/filters/retains_on_event_attribute_equal_filter/#parameters","title":"Parameters","text":"<ul> <li> <p>attribute_name: <code>str</code>   Name of the event attribute to filter.</p> </li> <li> <p>attribute_values: <code>Iterable</code>    Values to look for in the attribute.</p> </li> </ul>"},{"location":"pybeamline/filters/retains_on_event_attribute_equal_filter/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.filters import retains_on_event_attribute_equal_filter\n\nlog_source(\"test.xes\").pipe(\n    retains_on_event_attribute_equal_filter(\"event-attrib\", [\"ev\", \"ab\"]),\n).subscribe(print_sink())\n</code></pre>"},{"location":"pybeamline/filters/retains_on_trace_attribute_equal_filter/","title":"retains_on_trace_attribute_equal_filter","text":"<p>Retains events based on the equality of a trace-level attribute.</p>"},{"location":"pybeamline/filters/retains_on_trace_attribute_equal_filter/#parameters","title":"Parameters","text":"<ul> <li> <p>attribute_name: <code>str</code>   Name of the trace attribute to filter.</p> </li> <li> <p>attribute_values: <code>Iterable</code>    Values to look for in the attribute.</p> </li> </ul>"},{"location":"pybeamline/filters/retains_on_trace_attribute_equal_filter/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.filters import retains_on_trace_attribute_equal_filter\n\nlog_source(\"test.xes\").pipe(\n    retains_on_trace_attribute_equal_filter(\"event-attrib\", [\"ev\", \"ab\"]),\n).subscribe(print_sink())\n</code></pre>"},{"location":"pybeamline/mappers/dfg_str_to_graphviz/","title":"dfg_str_to_graphviz","text":"<p>Converts a DFG into a Graphviz string.</p>"},{"location":"pybeamline/mappers/dfg_str_to_graphviz/#parameters","title":"Parameters","text":"<ul> <li>None</li> </ul>"},{"location":"pybeamline/mappers/dfg_str_to_graphviz/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.algorithms.discovery import simple_dfg_miner\nfrom pybeamline.mappers.dfg_str_to_graphviz import dfg_str_to_graphviz\nfrom pybeamline.sinks.print_sink import print_sink\n\nlog_source([\"ABCD\", \"ABCD\"]).pipe(\n    simple_dfg_miner(model_update_frequency=8),\n    dfg_str_to_graphviz()\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>digraph G {\n\n    ranksep = 0.5\n    fontsize = 9\n    remincross = true\n    margin = \"0.0,0.0\"\n    outputorder = \"edgesfirst\"\n\n    node[\n        shape = box\n        height = 0.23\n        width = 1.2\n        style = \"rounded,filled\"\n        fontname = \"Arial\"\n    ]\n    edge[\n        decorate = false\n        fontsize = 8\n        arrowsize = 0.5\n        fontname = Arial\n        tailclip = false\n    ]\n\n    start [\n        shape = circle\n        style = filled\n        fillcolor = \"#CED6BD\"\n        gradientangle = 270\n        color = \"#595F45\"\n        height = 0.13\n        width = 0.13\n        label = \"\"\n    ]\n    end [\n        shape = circle\n        style = filled\n        fillcolor = \"#D8BBB9\"\n        gradientangle = 270\n        color = \"#614847\"\n        height = 0.13\n        width = 0.13\n        label = \"\"\n    ]\n    \"A\" -&gt; \"B\" [penwidth=5.0,label=\"1.0\"];\n    \"B\" -&gt; \"C\" [penwidth=5.0,label=\"1.0\"];\n    \"C\" -&gt; \"D\" [penwidth=5.0,label=\"1.0\"];\n    start -&gt; \"A\" [penwidth = 2, style = dashed, color = \"#ACB89C\"];\n    \"D\" -&gt; end [penwidth = 2, style = dashed, color = \"#C2B0AB\"];\n}\n</code></pre>"},{"location":"pybeamline/mappers/infinite_size_directly_follows_mapper/","title":"infinite_size_directly_follows_mapper","text":"<p>Transforms each pair of consequent event appearing in the same case as a directly follows relation (generating a tuple with the two event names). This mapper is called infinite because it's memory footprint will grow as the case ids grow.</p>"},{"location":"pybeamline/mappers/infinite_size_directly_follows_mapper/#parameters","title":"Parameters","text":"<ul> <li>None</li> </ul>"},{"location":"pybeamline/mappers/infinite_size_directly_follows_mapper/#returned-type","title":"Returned type","text":"<p>The returned output has type <code>(str, str)</code>. The first component is the source activity, the second is the target activity.</p>"},{"location":"pybeamline/mappers/infinite_size_directly_follows_mapper/#example","title":"Example","text":"<pre><code>from pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.sources import log_source\nfrom pybeamline.mappers import infinite_size_directly_follows_mapper\n\nlog_source([\"ABC\", \"ACB\"]).pipe(\n    infinite_size_directly_follows_mapper()\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>('A', 'B')\n('B', 'C')\n('A', 'C')\n('C', 'B')\n</code></pre>"},{"location":"pybeamline/mappers/sliding_window_to_log/","title":"sliding_window_to_log","text":"<p>Converts a list of events into a <code>DataFrame</code> suitable to be mined using PM4PY.</p>"},{"location":"pybeamline/mappers/sliding_window_to_log/#parameters","title":"Parameters","text":"<ul> <li>None</li> </ul>"},{"location":"pybeamline/mappers/sliding_window_to_log/#example","title":"Example","text":"<pre><code>from pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.sources import log_source\nfrom pybeamline.mappers import sliding_window_to_log\nfrom pybeamline.stream.base_map import BaseMap\nfrom pybeamline.stream.rx_operator import RxOperator\nfrom reactivex.operators import window_with_count\nimport pm4py\n\n# class to run the offline mining algorithm\nclass mine_using_offline_pm4py(BaseMap):\n    def transform(self, log):\n        try:\n            return [pm4py.discover_dfg_typed(log)]\n        except:\n            return None\n\nlog_source([\"ABC\", \"ABD\"]).pipe(\n    RxOperator(window_with_count(3)),\n    sliding_window_to_log(),\n    mine_using_offline_pm4py()\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>Counter({('A', 'B'): 1, ('B', 'C'): 1})\nCounter({('A', 'B'): 1, ('B', 'D'): 1})\n</code></pre> <p>As can be seen the 2 DFGs are mined from the 2 traces separately (as the tumbling window has size 3, which corresponds to the size of each trace). Using a tumbling window of size 6 (i.e., <code>window_with_count(6)</code>) will produce the following:</p> <pre><code>Counter({('A', 'B'): 2, ('B', 'C'): 1, ('B', 'D'): 1})\n</code></pre> <p>In this case, the only model extracted embeds both traces inside.</p>"},{"location":"pybeamline/sinks/dotted_chart_sink/","title":"dotted_chart_sink","text":"<p>Outputs the events as a dotted chart graph.</p>"},{"location":"pybeamline/sinks/dotted_chart_sink/#parameters","title":"Parameters","text":"<ul> <li>title: <code>str</code> default: <code>Dotted chart of events</code>   The title of the dotted chart.</li> <li>max_events: <code>int</code> default: <code>None</code>   Max number of events to show.</li> <li>time_window_seconds: <code>int</code> default: <code>None</code>   Max time window of events to show.</li> <li>point_size: <code>int</code> default: <code>100</code>   The size of each event point.</li> <li>show_legend: <code>boolean</code> default: <code>False</code>   Whether the legend should be shown.</li> <li>gif_path: <code>str</code> default: <code>None</code>   The path where the gif of the stream should be stored. If <code>None</code> is specified, then the output is rendered on the notebook directly.</li> <li>fps: <code>int</code> default: <code>5</code>   The number of frame per seconds, in case the output is stored as a GIF.</li> </ul>"},{"location":"pybeamline/sinks/dotted_chart_sink/#example","title":"Example","text":"<pre><code>from pybeamline.sources import string_test_source\nfrom pybeamline.sinks.dotted_chart_sink import dotted_chart_sink\n\nlog_original = [\"ABCD\"]*5 + [\"ACBD\"]*5\nlog_after_drift = [\"AEFG\"]*5 + [\"AFEG\"]*5\n\nstring_test_source(log_original + log_after_drift).pipe(\n\n).sink(dotted_chart_sink(max_events=25, gif_path=\"test_dotted_chart_sink.gif\"))\n</code></pre> <p>Output:</p> <p></p>"},{"location":"pybeamline/sinks/graphviz_sink/","title":"graphviz_sink","text":"<p>Outputs the events considering it as a Graphviz graph.</p>"},{"location":"pybeamline/sinks/graphviz_sink/#parameters","title":"Parameters","text":"<ul> <li>gif_path: <code>str</code> default: <code>None</code>   The path where the gif of the stream should be stored. If <code>None</code> is specified, then the output is rendered on the notebook directly.</li> <li>fps: <code>int</code> default: <code>5</code>   The number of frame per seconds, in case the output is stored as a GIF.</li> <li>mode: <code>str</code> default <code>RGB</code>   The GIF color mode.</li> <li>bg_color: <code>tuple</code> default: <code>(255, 255, 255)</code>   The background color of the GIF.</li> <li>center: <code>boolean</code> default: <code>True</code>   Whether the content should be centered.</li> </ul>"},{"location":"pybeamline/sinks/graphviz_sink/#example","title":"Example","text":"<pre><code>from pybeamline.sources import string_test_source\nfrom pybeamline.algorithms.discovery.dfg_miner import simple_dfg_miner\nfrom pybeamline.mappers.dfg_str_to_graphviz import dfg_str_to_graphviz\nfrom pybeamline.sinks.graphviz_sink import graphviz_sink\n\nlog_original = [\"ABCD\"]*50 + [\"ACBD\"]*50\nlog_after_drift = [\"AEFG\"]*50 + [\"AFEG\"]*50\n\nstring_test_source(log_original + log_after_drift).pipe(\n    simple_dfg_miner(model_update_frequency=50, min_relative_frequency=0.2),\n    dfg_str_to_graphviz(),\n).sink(graphviz_sink(gif_path='test_graphviz_sink.gif', fps=1))\n</code></pre> <p>Output:</p> <p></p>"},{"location":"pybeamline/sinks/heatmap_sink/","title":"heatmap_sink","text":"<p>Outputs the events as a heatmap graph. Each element of the stream to be presented should have the following shape: <code>((a, b), freq)</code>.</p>"},{"location":"pybeamline/sinks/heatmap_sink/#parameters","title":"Parameters","text":"<ul> <li>title: <code>str</code> default: <code>Distribution</code>   The title of the heatmap.</li> <li>value_label: <code>str</code> default: <code>frequency</code>   The label of the value of the heatmap.</li> <li>gif_path: <code>str</code> default: <code>None</code>   The path where the gif of the stream should be stored. If <code>None</code> is specified, then the output is rendered on the notebook directly.</li> <li>fps: <code>int</code> default: <code>5</code>   The number of frame per seconds, in case the output is stored as a GIF.</li> </ul>"},{"location":"pybeamline/sinks/heatmap_sink/#example","title":"Example","text":"<pre><code>from pybeamline.sources import string_test_source\nfrom pybeamline.mappers.to_directly_follow_relations import to_directly_follow_relations\nfrom pybeamline.utils.skip_events import skip_events\nfrom pybeamline.sinks.heatmap_sink import heatmap_sink\n\nclass count_latest(BaseMap):\n    def __init__(self, window_size=5):\n        self.observations = dict()\n        self.window_size = window_size\n        self.window = list()\n\n    def transform(self, value):\n        if value not in self.observations.keys():\n            self.observations[value] = 0\n        self.observations[value] += 1\n        self.window.append(value)\n        if len(self.window) &gt; self.window_size:\n            removed = self.window.pop(0)\n            self.observations[removed] -= 1\n            if self.observations[removed] == 0:\n                del self.observations[removed]\n        return [dict(self.observations)]\n\nlog_original = [\"ABCD\"]*50 + [\"ACBD\"]*50\nlog_after_drift = [\"ABCE\"]*100 + [\"ACBF\"]*100\nstring_test_source(log_original + log_after_drift).pipe(\n  to_directly_follow_relations(),\n    count_latest(window_size=200),\n    skip_events(events_to_skip=20)\n).sink(heatmap_sink(title=\"Directly-follows relation distribution\", gif_path='test_heatmap_sink.gif', fps=3))\n</code></pre> <p>Output:</p> <p></p>"},{"location":"pybeamline/sinks/oc_visualizer_sink/","title":"oc_visualizer_sink","text":"<p>Outputs the events from <code>oc_merge</code> as a graph.</p> <p>See also <code>oc_merge</code> and <code>oc_operator</code>.</p>"},{"location":"pybeamline/sinks/oc_visualizer_sink/#parameters","title":"Parameters","text":"<ul> <li>gif_path: <code>str</code> default: <code>None</code>   The path where the gif of the stream should be stored. If <code>None</code> is specified, then the output is rendered on the notebook directly.</li> <li>fps: <code>int</code> default: <code>5</code>   The number of frame per seconds, in case the output is stored as a GIF.</li> <li>mode: <code>str</code> default <code>RGB</code>   The GIF color mode.</li> <li>bg_color: <code>tuple</code> default: <code>(255, 255, 255)</code>   The background color of the GIF.</li> <li>center: <code>boolean</code> default: <code>True</code>   Whether the content should be centered.</li> <li>display_in_notebook: <code>boolean</code> default: <code>True</code>   Whether the result should be shown on the notebook.</li> </ul>"},{"location":"pybeamline/sinks/oc_visualizer_sink/#example","title":"Example","text":"<pre><code>from pybeamline.algorithms.oc.oc_merge_operator import oc_merge_operator\nfrom pybeamline.algorithms.oc.oc_operator import oc_operator\nfrom pybeamline.sinks.oc_visualizer_sink import oc_visualizer_sink\nfrom pybeamline.sources.dict_ocel_test_source import dict_test_ocel_source\n\ntrace_1 = [\n    {\"activity\": \"Register Customer\", \"objects\": {\"Customer\": [\"c1\"]}},\n    {\"activity\": \"Create Order\", \"objects\": {\"Customer\": [\"c1\"], \"Order\": [\"o1\"]}},\n    {\"activity\": \"Add Item\", \"objects\": {\"Order\": [\"o1\"], \"Item\": [\"i1\"]}},\n    {\"activity\": \"Add Item\", \"objects\": {\"Order\": [\"o1\"], \"Item\": [\"i2\"]}},\n    {\"activity\": \"Ship Order\", \"objects\": {\"Item\": [\"i1\", \"i2\"], \"Order\": [\"o1\"]}}\n]\n\ntest_source = dict_test_ocel_source([(trace_1, 10)]).pipe(\n    oc_operator(),\n    oc_merge_operator(),\n).subscribe(oc_visualizer_sink(gif_path='test_oc_visualizer_sink.gif', fps=1))\n</code></pre> <p>Output:</p> <p></p>"},{"location":"pybeamline/sinks/print_sink/","title":"print_sink","text":"<p>Converts the items into a string and prints them.</p>"},{"location":"pybeamline/sinks/print_sink/#parameters","title":"Parameters","text":"<ul> <li>None</li> </ul>"},{"location":"pybeamline/sinks/print_sink/#example","title":"Example","text":"<pre><code>from pybeamline.sources import string_test_source\nfrom pybeamline.sinks.print_sink import print_sink\n\nstring_test_source([\"ABC\", \"ACB\"]).pipe().subscribe(print_sink())\n</code></pre> <p>Output: <pre><code>(A, case_1, Process, 2020-00-00 13:31:56.857558 - {} - {} - {})\n(B, case_1, Process, 2020-00-00 13:31:56.857558 - {} - {} - {})\n(C, case_1, Process, 2020-00-00 13:31:56.857558 - {} - {} - {})\n(A, case_2, Process, 2020-00-00 13:31:56.857558 - {} - {} - {})\n(C, case_2, Process, 2020-00-00 13:31:56.858537 - {} - {} - {})\n(B, case_2, Process, 2020-00-00 13:31:56.858537 - {} - {} - {})\n</code></pre></p>"},{"location":"pybeamline/sources/combining-sources/","title":"Combining sources","text":"<p>In order to build tests where drifts occur in a controlled setting, it is possible to concatenate different sources together. See the example below:</p> <pre><code>from pybeamline.sources import xes_log_source_from_file, log_source\nfrom pybeamline.sinks.print_sink import print_sink\n\nsrc1 = xes_log_source_from_file(\"tests/log.xes\")\nsrc2 = log_source([\"ABCD\", \"ABCD\"])\nsrc3 = xes_log_source_from_file(\"tests/log.xes\")\n\nconcat = src1.concat(src2).concat(src3)\nconcat.subscribe(print_sink())\n</code></pre>"},{"location":"pybeamline/sources/dict_test_ocel_source/","title":"dict_test_ocel_source","text":"<p>Loads an OCEL 2.0 log from a file path and returns it as a stream of <code>BOEvent</code>s.</p>"},{"location":"pybeamline/sources/dict_test_ocel_source/#parameters","title":"Parameters","text":"<ul> <li>flows: <code>List[Tuple[List[dict], int]]</code>   A list of tuples, where each tuple is of the form <code>(flow_template, repetitions)</code> where <code>flow_template</code> is a list of event dictionaries with keys \"<code>activity</code>\" and \"<code>objects</code>\" and <code>repetitions</code> is the number of traces to generate from that template.   Example:   <pre><code>[\n  (\n    [\n      {\"activity\": \"Register Customer\", \"objects\": {\"Customer\": [\"c1\"]}},\n      {\"activity\": \"Create Order\", \"objects\": {\"Customer\": [\"c1\"], \"Order\": [\"o1\"]}}\n    ],\n    20\n  )\n]\n</code></pre>   This means: generate 20 traces with those two events.</li> <li>shuffle: <code>bool</code> default: <code>False</code>   Whether to shuffle the events from different traces in the final output.</li> <li>scheduler: <code>Optional[abc.SchedulerBase]</code> default: <code>None</code>   A ReactiveX scheduler to control event emission timing.</li> </ul>"},{"location":"pybeamline/sources/dict_test_ocel_source/#example","title":"Example","text":"<pre><code>from pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.sources.dict_ocel_test_source import dict_test_ocel_source\n\ntrace_1 = [\n      {\"activity\": \"Register Customer\", \"objects\": {\"Customer\": [\"c1\"]}},\n      {\"activity\": \"Create Order\", \"objects\": {\"Customer\": [\"c1\"], \"Order\": [\"o1\"]}},\n      {\"activity\": \"Add Item\", \"objects\": {\"Order\": [\"o1\"], \"Item\": [\"i1\"]}},\n      {\"activity\": \"Add Item\", \"objects\": {\"Order\": [\"o1\"], \"Item\": [\"i2\"]}},\n      {\"activity\": \"Ship Order\", \"objects\": {\"Item\": [\"i1\", \"i2\"], \"Order\": [\"o1\"]}}\n  ]\ntrace_2 = [\n      {\"activity\": \"Register Guest\", \"objects\": {\"Guest\": [\"g1\"]}},\n      {\"activity\": \"Create Booking\", \"objects\": {\"Guest\": [\"g1\"], \"Booking\": [\"b1\"]}},\n      {\"activity\": \"Reserve Room\", \"objects\": {\"Booking\": [\"b1\"]}},\n      {\"activity\": \"Check In\", \"objects\": {\"Guest\": [\"g1\"], \"Booking\": [\"b1\"]}},\n      {\"activity\": \"Check Out\", \"objects\": {\"Guest\": [\"g1\"], \"Booking\": [\"b1\"]}}\n  ]\n\ntest_source = dict_test_ocel_source(\n    [\n        (trace_1, 2),  # Repeat trace_1 twice\n        (trace_2, 3)   # Repeat trace_2 three times\n    ]\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>{'ocel:eid': 'e0', 'ocel:activity': 'Register Customer', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 490891), 'ocel:omap': {'Customer': {'c1_0'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e1', 'ocel:activity': 'Create Order', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Customer': {'c1_0'}, 'Order': {'o1_0'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e2', 'ocel:activity': 'Add Item', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Order': {'o1_0'}, 'Item': {'i1_0'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e3', 'ocel:activity': 'Add Item', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Order': {'o1_0'}, 'Item': {'i2_0'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e4', 'ocel:activity': 'Ship Order', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Item': {'i1_0', 'i2_0'}, 'Order': {'o1_0'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e5', 'ocel:activity': 'Register Customer', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Customer': {'c1_1'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e6', 'ocel:activity': 'Create Order', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Customer': {'c1_1'}, 'Order': {'o1_1'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e7', 'ocel:activity': 'Add Item', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Order': {'o1_1'}, 'Item': {'i1_1'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e8', 'ocel:activity': 'Add Item', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Order': {'o1_1'}, 'Item': {'i2_1'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e9', 'ocel:activity': 'Ship Order', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Item': {'i1_1', 'i2_1'}, 'Order': {'o1_1'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e10', 'ocel:activity': 'Register Guest', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Guest': {'g1_2'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e11', 'ocel:activity': 'Create Booking', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Guest': {'g1_2'}, 'Booking': {'b1_2'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e12', 'ocel:activity': 'Reserve Room', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Booking': {'b1_2'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e13', 'ocel:activity': 'Check In', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Guest': {'g1_2'}, 'Booking': {'b1_2'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e14', 'ocel:activity': 'Check Out', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Guest': {'g1_2'}, 'Booking': {'b1_2'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e15', 'ocel:activity': 'Register Guest', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Guest': {'g1_3'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e16', 'ocel:activity': 'Create Booking', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Guest': {'g1_3'}, 'Booking': {'b1_3'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e17', 'ocel:activity': 'Reserve Room', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Booking': {'b1_3'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e18', 'ocel:activity': 'Check In', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Guest': {'g1_3'}, 'Booking': {'b1_3'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e19', 'ocel:activity': 'Check Out', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Guest': {'g1_3'}, 'Booking': {'b1_3'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e20', 'ocel:activity': 'Register Guest', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Guest': {'g1_4'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e21', 'ocel:activity': 'Create Booking', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 491870), 'ocel:omap': {'Guest': {'g1_4'}, 'Booking': {'b1_4'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e22', 'ocel:activity': 'Reserve Room', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 493911), 'ocel:omap': {'Booking': {'b1_4'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e23', 'ocel:activity': 'Check In', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 493911), 'ocel:omap': {'Guest': {'g1_4'}, 'Booking': {'b1_4'}}, 'ocel:vmap': {}}\n{'ocel:eid': 'e24', 'ocel:activity': 'Check Out', 'ocel:timestamp': datetime.datetime(2020, 0, 0, 9, 45, 19, 493911), 'ocel:omap': {'Guest': {'g1_4'}, 'Booking': {'b1_4'}}, 'ocel:vmap': {}}\n</code></pre>"},{"location":"pybeamline/sources/mqtt_source/","title":"mqttxes_source","text":"<p>Source that connects to an MQTT endpoint and expects events to be published according to the MQTT-XES format.</p>"},{"location":"pybeamline/sources/mqtt_source/#parameters","title":"Parameters","text":"<ul> <li>broker: <code>str</code>   The url of the MQTT broker.</li> <li>port: <code>int</code>   The port of the MQTT broker.</li> <li>base_topic: <code>str</code>   The base topic for the MQTT-XES source</li> </ul>"},{"location":"pybeamline/sources/mqtt_source/#example","title":"Example","text":"<pre><code>from pybeamline.sources import mqttxes_source\nfrom pybeamline.sinks.print_sink import print_sink\n\nmqttxes_source('broker.mqtt.cool', 1883, 'base/topic/') \\\n    .subscribe(print_sink())\n\ninput()\n</code></pre> <p>Where <code>broker.mqtt.cool</code> is the URL of the MQTT broker, <code>1883</code> is the broker port, and <code>base/topic/</code> is the base topic. Please note the <code>input()</code> at the end, which is necessary to avoid that the application terminates thus not receiving any more events.</p>"},{"location":"pybeamline/sources/ocel2_log_source_from_file/","title":"ocel2_log_source_from_file","text":"<p>Loads an OCEL 2.0 log from a file path and returns it as a stream of <code>BOEvent</code>s.</p>"},{"location":"pybeamline/sources/ocel2_log_source_from_file/#parameters","title":"Parameters","text":"<ul> <li>log_path: <code>str</code>   The path of the OCEL 2.0 file.</li> </ul>"},{"location":"pybeamline/sources/ocel2_log_source_from_file/#example","title":"Example","text":"<pre><code>from pybeamline.sources.ocel2_log_source_from_file import ocel2_log_source_from_file\nfrom pybeamline.sinks.print_sink import print_sink\n\nocel2_log_source_from_file(\"test.jsonocel\") \\\n    .subscribe(print_sink())\n</code></pre>"},{"location":"pybeamline/sources/string_test_source/","title":"string_test_source","text":"<p>Source that considers each trace as a string provided in the constructor and each event as one character of the string.</p>"},{"location":"pybeamline/sources/string_test_source/#parameters","title":"Parameters","text":"<ul> <li>raw_log: <code>Iterable[str]</code>   The collection of traces to be streamed. Each <code>str</code> represents a complete trace, where each character is an activity.</li> </ul>"},{"location":"pybeamline/sources/string_test_source/#example","title":"Example","text":"<pre><code>from pybeamline.sources import string_test_source\nfrom pybeamline.sinks.print_sink import print_sink\n\nstring_test_source([\"ABC\", \"ACB\", \"EFG\"]) \\\n    .subscribe(print_sink())\n</code></pre>"},{"location":"pybeamline/sources/xes_log_source/","title":"xes_log_source","text":"<p>Emits all events from an XES event log.</p>"},{"location":"pybeamline/sources/xes_log_source/#parameters","title":"Parameters","text":"<ul> <li>raw_log: <code>Union[EventLog, pd.DataFrame]</code>   The raw event log from PM4PY.</li> </ul>"},{"location":"pybeamline/sources/xes_log_source/#example","title":"Example","text":"<pre><code>import pm4py\nfrom pybeamline.sources import xes_log_source\nfrom pybeamline.sinks.print_sink import print_sink\n\nxes_log_source(pm4py.read_xes(\"test.xes\")) \\\n    .subscribe(print_sink())\n</code></pre>"},{"location":"pybeamline/sources/xes_log_source_from_file/","title":"xes_log_source_from_file","text":"<p>Emits all events from an XES event log.</p>"},{"location":"pybeamline/sources/xes_log_source_from_file/#parameters","title":"Parameters","text":"<ul> <li>log: <code>str</code>   The file containing the log.</li> </ul>"},{"location":"pybeamline/sources/xes_log_source_from_file/#example","title":"Example","text":"<pre><code>from pybeamline.sources import xes_log_source_from_file\nfrom pybeamline.sinks.print_sink import print_sink\n\nxes_log_source_from_file(\"test.xes\") \\\n    .subscribe(print_sink())\n</code></pre>"},{"location":"pybeamline/sources-real/ais_source/","title":"ais_source","text":"Extra package required! <p>To use this source you need to install package <code>pybeamline-real-sources</code> with: <pre><code>pip install pybeamline-real-sources\n</code></pre></p> <p>The automatic identification system (AIS) is an automatic tracking system that uses transceivers on ships and is used by vessel traffic services. This source considers the MMSI as the case id and the navigation status (when available) as the activity. While it is possible connect to any AIS data provider (by passing <code>host</code> and <code>port</code> parameters), by default, the source connects to the Norwegian Coastal Administration server, which publishes data for the from vessels within the Norwegian economic zone and the protection zones off Svalbard and Jan Mayen (see https://www.kystverket.no/en/navigation-and-monitoring/ais/access-to-ais-data/).</p> <p>ATTENTION: while a lot of events are produced by this source, traces are very short and it can take a long time before two events with the same case id are actually observed.</p>"},{"location":"pybeamline/sources-real/ais_source/#parameters","title":"Parameters","text":"<ul> <li> <p>host <code>str</code> default: <code>'153.44.253.27'</code>   IP Address of the AIS provider.</p> </li> <li> <p>port <code>int</code> default: <code>5631</code>    Port of the AIS provider.</p> </li> </ul>"},{"location":"pybeamline/sources-real/ais_source/#example","title":"Example","text":"<pre><code>from pybeamline.sinks.print_sink import print_sink\nfrom pybeamline_real_sources.ais import ais_source\n\nais_source().pipe(\n\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>(Undefined, 258007330, AIS, 2020-00-00 14:49:31.101265 - {'mmsi': 258007330, 'second': 29, 'heading': 511, 'lon': 5.312967, 'accuracy': False, 'speed': 0.0, 'course': 326.1, 'lat': 60.392442} - {} - {})\n(Moored, 257215400, AIS, 2020-00-00 14:49:31.101265 - {'mmsi': 257215400, 'second': 63, 'heading': 511, 'lon': 181.0, 'accuracy': False, 'speed': 102.3, 'course': 360.0, 'lat': 91.0} - {} - {})\n(UnderWayUsingEngine, 257264900, AIS, 2020-00-00 14:49:31.102276 - {'mmsi': 257264900, 'second': 29, 'heading': 511, 'lon': 9.027405, 'accuracy': True, 'speed': 0.0, 'course': 5.1, 'lat': 63.652173} - {} - {})\n(UnderWayUsingEngine, 257033030, AIS, 2020-00-00 14:49:31.102276 - {'mmsi': 257033030, 'second': 29, 'heading': 335, 'lon': 17.335573, 'accuracy': False, 'speed': 0.0, 'course': 215.0, 'lat': 68.723927} - {} - {})\n(UnderWayUsingEngine, 257153000, AIS, 2020-00-00 14:49:31.102276 - {'mmsi': 257153000, 'second': 29, 'heading': 237, 'lon': 15.819412, 'accuracy': False, 'speed': 2.3, 'course': 245.3, 'lat': 69.479643} - {} - {})\n(UnderWayUsingEngine, 257198000, AIS, 2020-00-00 14:49:31.102276 - {'mmsi': 257198000, 'second': 30, 'heading': 279, 'lon': 5.076527, 'accuracy': False, 'speed': 0.0, 'course': 66.1, 'lat': 60.201458} - {} - {})\n(UnderWayUsingEngine, 257076900, AIS, 2020-00-00 14:49:31.102276 - {'mmsi': 257076900, 'second': 30, 'heading': 511, 'lon': 15.11809, 'accuracy': False, 'speed': 0.0, 'course': 171.8, 'lat': 67.657533} - {} - {})\n(UnderWayUsingEngine, 259031700, AIS, 2020-00-00 14:49:31.102276 - {'mmsi': 259031700, 'second': 29, 'heading': 68, 'lon': 4.97066, 'accuracy': True, 'speed': 6.7, 'course': 66.8, 'lat': 61.239747} - {} - {})\n(Moored, 258364000, AIS, 2020-00-00 14:49:31.102276 - {'mmsi': 258364000, 'second': 29, 'heading': 141, 'lon': 5.259447, 'accuracy': False, 'speed': 0.0, 'course': 244.1, 'lat': 59.411605} - {} - {})\n(Moored, 257158400, AIS, 2020-00-00 14:49:31.102276 - {'mmsi': 257158400, 'second': 30, 'heading': 511, 'lon': 10.757402, 'accuracy': True, 'speed': 0.0, 'course': 360.0, 'lat': 59.902088} - {} - {})\n(EngagedInFishing, 258247000, AIS, 2020-00-00 14:49:31.103287 - {'mmsi': 258247000, 'second': 31, 'heading': 205, 'lon': 10.121003, 'accuracy': False, 'speed': 8.7, 'course': 209.0, 'lat': 64.159853} - {} - {})\n</code></pre>"},{"location":"pybeamline/sources-real/rejseplanen_source/","title":"rejseplanen_source","text":"Extra package required! <p>To use this source you need to install package <code>pybeamline-real-sources</code> with: <pre><code>pip install pybeamline-real-sources\n</code></pre></p> <p>This source provides the data from the Danish railway system. Traces are represented as individual trains and events are trains reaching a certain station. The data is continuously generate (updated every 5 seconds, see https://www.rejseplanen.dk/bin/help.exe/mn?L=vs_dot.vs_livemap&amp;tpl=fullscreenmap). The current source retrieves information about regional and light train (letbane).</p>"},{"location":"pybeamline/sources-real/rejseplanen_source/#parameters","title":"Parameters","text":"<ul> <li>None</li> </ul>"},{"location":"pybeamline/sources-real/rejseplanen_source/#example","title":"Example","text":"<pre><code>from pybeamline.sinks.print_sink import print_sink\nfrom pybeamline_real_sources.rejseplanen import rejseplanen_source\n\nrejseplanen_source().pipe(\n\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>(Skibstrup St., 84/46798/18/19/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 2, 'train-previous-stop': 'Saunte St.'} - {'destination': 'Helsing\u00f8r St.', 'train-name': 'Lokalbane 940R'} - {})\n(Favrholm St., 84/23923/18/27/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 4, 'train-previous-stop': 'Sk\u00e6vinge St.'} - {'destination': 'Hiller\u00f8d St.', 'train-name': 'Lokalbane 920E'} - {})\n(Vig St., 84/23881/18/24/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 1, 'train-previous-stop': 'Grevinge St.'} - {'destination': 'Nyk\u00f8bing Sj St.', 'train-name': 'Lokalbane 510R'} - {})\n(Nr. Asmindrup St., 84/23879/18/24/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 0, 'train-previous-stop': 'Sommerland Sj. St.'} - {'destination': 'Holb\u00e6k St.', 'train-name': 'Lokalbane 510R'} - {})\n(Vall\u00f8 St., 84/23818/18/38/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 2, 'train-previous-stop': 'Grubberholm St.'} - {'destination': 'Roskilde St.', 'train-name': 'Lokalbane 210R'} - {})\n(Li.Linde St., 84/23794/18/38/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 2, 'train-previous-stop': 'Karise St.'} - {'destination': 'K\u00f8ge St.', 'train-name': 'Lokalbane 110R'} - {})\n(Lille Kregme St., 84/23663/18/27/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 1, 'train-previous-stop': 'Kregme St.'} - {'destination': 'Hundested Havn St.', 'train-name': 'Lokalbane 920R'} - {})\n(Brede St., 84/23622/18/47/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 0, 'train-previous-stop': 'Fuglevad St.'} - {'destination': 'N\u00e6rum St.', 'train-name': 'Lokalbane 910'} - {})\n(Jyderup St., 84/1883/18/20/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 0, 'train-previous-stop': 'Sveb\u00f8lle St.'} - {'destination': '\u00d8sterport St.', 'train-name': 'Re 1540'} - {})\n(Humleb\u00e6k St., 84/1697/18/19/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 0, 'train-previous-stop': 'Esperg\u00e6rde St.'} - {'destination': 'Holb\u00e6k St.', 'train-name': 'Re 4561'} - {})\n(Hellerup St., 84/1681/18/19/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 0, 'train-previous-stop': 'Klampenborg St.'} - {'destination': 'Holb\u00e6k St.', 'train-name': 'Re 2559'} - {})\n(Trekroner St., 84/1631/18/19/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 0, 'train-previous-stop': 'Roskilde St.'} - {'destination': 'Helsing\u00f8r St.', 'train-name': 'Re 4536'} - {})\n(K\u00f8benhavn H, 84/1430/18/19/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 0, 'train-previous-stop': 'N\u00f8rreport St.'} - {'destination': 'N\u00e6stved St.', 'train-name': 'Re 2257'} - {})\n(Vedb\u00e6k St., 84/1426/18/19/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 0, 'train-previous-stop': 'Rungsted Kyst St.'} - {'destination': 'N\u00e6stved St.', 'train-name': 'Re 4259'} - {})\n(Bedsted Thy St., 84/48192/18/19/86, Rejseplanen, 2020-00-00 14:53:54.051580 - {'train-delay': 0, 'train-previous-stop': 'Hurup Thy St.'} - {'destination': 'Thisted St.', 'train-name': 'RA 5541'} - {})\n</code></pre>"},{"location":"pybeamline/sources-real/wikimedia_source/","title":"wikimedia_source","text":"Extra package required! <p>To use this source you need to install package <code>pybeamline-real-sources</code> with: <pre><code>pip install pybeamline-real-sources\n</code></pre></p> <p>Source that connects to the stream of recent change operations happening on the Media Wiki websites (see https://wikitech.wikimedia.org/wiki/Event_Platform/EventStreams_HTTP_Service and https://www.mediawiki.org/wiki/Manual:RCFeed).</p> <p>ATTENTION: it is advisable to apply a filter operation to consider only events relevant to one of the websites.</p>"},{"location":"pybeamline/sources-real/wikimedia_source/#parameters","title":"Parameters","text":"<ul> <li>None</li> </ul>"},{"location":"pybeamline/sources-real/wikimedia_source/#example","title":"Example","text":"<pre><code>from pybeamline.filters import retains_on_event_attribute_equal_filter\nfrom pybeamline.sinks.print_sink import print_sink\nfrom pybeamline_real_sources.wikimedia import wikimedia_source\n\nwikimedia_source().pipe(\n    retains_on_event_attribute_equal_filter(\"wiki\", [\"dewiki\"])\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>(edit, f7ed88659d276caef4e00a0fabb6c3bd, dewiki, 2020-00-00 15:23:19.704655 - {'user': 'Tohma', 'revision': {'old': 263529160, 'new': 263529200}, 'comment': '/* Redakteur des verschw\u00f6rungstheoretischen Blogs NachDenkSeiten. */', 'server_name': 'de.wikipedia.org', 'server_url': 'https://de.wikipedia.org', 'namespace': 1, 'timestamp': 1769005398, 'wiki': 'dewiki', 'bot': False, 'length': {'old': 5727, 'new': 5843}, 'title': 'Diskussion:Florian Warweg'} - {} - {})\n(edit, 5d668c42da72ea67bcc61ed3209efdde, dewiki, 2020-00-00 15:23:22.484338 - {'user': 'Urmelbeauftragter', 'revision': {'old': 263529080, 'new': 263529197}, 'comment': '/* 56. Jahrestreffen 2026 */ Update', 'server_name': 'de.wikipedia.org', 'server_url': 'https://de.wikipedia.org', 'namespace': 0, 'timestamp': 1769005389, 'wiki': 'dewiki', 'bot': False, 'length': {'old': 244004, 'new': 245149}, 'title': 'Weltwirtschaftsforum'} - {} - {})\n(edit, 73a2f591a258857bc8c56334a1df47dc, dewiki, 2020-00-00 15:23:26.428809 - {'user': 'Kriddl', 'revision': {'old': 263529045, 'new': 263529201}, 'comment': '/* Oscarverleihung 1988 */', 'server_name': 'de.wikipedia.org', 'server_url': 'https://de.wikipedia.org', 'namespace': 100, 'timestamp': 1769005404, 'wiki': 'dewiki', 'bot': False, 'length': {'old': 27431, 'new': 27440}, 'title': 'Portal:Film und Fernsehen/Fehlende Oscar-Artikel'} - {} - {})\n(edit, 2667808e53e036566cd4f1a4792a7bd6, dewiki, 2020-00-00 15:23:28.048902 - {'user': '~2026-45554-3', 'revision': {'old': 262793578, 'new': 263529202}, 'comment': '', 'server_name': 'de.wikipedia.org', 'server_url': 'https://de.wikipedia.org', 'namespace': 0, 'timestamp': 1769005405, 'wiki': 'dewiki', 'bot': False, 'length': {'old': 328988, 'new': 328980}, 'title': 'Liste griechischer Sagen'} - {} - {})\n(edit, 1d119f1541ad69b9ebdddfbc21ca717f, dewiki, 2020-00-00 15:23:29.800785 - {'user': 'Sp\u00fcrnase2013', 'revision': {'old': 263529171, 'new': 263529203}, 'comment': '', 'server_name': 'de.wikipedia.org', 'server_url': 'https://de.wikipedia.org', 'namespace': 2, 'timestamp': 1769005408, 'wiki': 'dewiki', 'bot': False, 'length': {'old': 806, 'new': 2114}, 'title': 'Benutzer:Sp\u00fcrnase2013/Mailand\u2013Sanremo 1957'} - {} - {})\n(edit, 227de05cfe03a8b4bfe29cdfd9103a7a, dewiki, 2020-00-00 15:23:35.704019 - {'user': '~2026-35153-1', 'revision': {'old': 263528936, 'new': 263529204}, 'comment': 'Amt ihres Bruders hinzugef\u00fcgt', 'server_name': 'de.wikipedia.org', 'server_url': 'https://de.wikipedia.org', 'namespace': 0, 'timestamp': 1769005414, 'wiki': 'dewiki', 'bot': False, 'length': {'old': 11176, 'new': 11212}, 'title': 'D\u00e9sir\u00e9e Silfverschi\u00f6ld'} - {} - {})\n(categorize, dd49cdd04189d39f52fbac66c34e022e, dewiki, 2020-00-00 15:23:36.159790 - {'user': 'Urmelbeauftragter', 'comment': '[[:Weltwirtschaftsforum]] zur Kategorie hinzugef\u00fcgt', 'server_name': 'de.wikipedia.org', 'server_url': 'https://de.wikipedia.org', 'namespace': 14, 'timestamp': 1769005389, 'wiki': 'dewiki', 'bot': False, 'title': 'Kategorie:Wikipedia:Vorlagenfehler/Vorlage:Internetquelle'} - {} - {})\n(edit, 23e6825eec7f2b30aa0f9abb80299990, dewiki, 2020-00-00 15:23:36.695967 - {'user': 'Bernd Rohlfs', 'revision': {'old': 263529131, 'new': 263529205}, 'comment': '/* Strafverfahren */', 'server_name': 'de.wikipedia.org', 'server_url': 'https://de.wikipedia.org', 'namespace': 0, 'timestamp': 1769005414, 'wiki': 'dewiki', 'bot': False, 'length': {'old': 22962, 'new': 23095}, 'title': 'Christina Block'} - {} - {})\n</code></pre>"},{"location":"pybeamline/utility-ops/RxOperator/","title":"RxOperator","text":"<p>Converts any ReactiveX operator into an operator that can be used in pyBeamline.</p>"},{"location":"pybeamline/utility-ops/RxOperator/#parameters","title":"Parameters","text":"<ul> <li>ops: <code>Callable[[Any], Any]</code>   The ReactiveX operator to be converted.</li> </ul>"},{"location":"pybeamline/utility-ops/RxOperator/#example","title":"Example","text":"<pre><code>from pybeamline.sinks.print_sink import print_sink\nfrom pybeamline.sources import log_source\nfrom pybeamline.stream.rx_operator import RxOperator\nfrom reactivex.operators import window_with_count\n\nlog_source([\"ABC\", \"ABD\"]).pipe(\n    RxOperator(window_with_count(3))\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>[&lt;pybeamline.bevent.BEvent object at 0x000001D77EAF0E80&gt;, &lt;pybeamline.bevent.BEvent object at 0x000001D77EAF0F10&gt;, &lt;pybeamline.bevent.BEvent object at 0x000001D77EAF0FA0&gt;]\n[&lt;pybeamline.bevent.BEvent object at 0x000001D77EAE9790&gt;, &lt;pybeamline.bevent.BEvent object at 0x000001D77EAE9FA0&gt;, &lt;pybeamline.bevent.BEvent object at 0x000001D77EAF0E50&gt;]\n[]\n</code></pre>"},{"location":"pybeamline/utility-ops/lambda_operator/","title":"lambda_operator","text":"<p>Allows the injection of a lambda function as an operator.</p>"},{"location":"pybeamline/utility-ops/lambda_operator/#parameters","title":"Parameters","text":"<ul> <li>func: <code>Callable[[Any], Any]</code>   The lambda function to call on each event.</li> </ul>"},{"location":"pybeamline/utility-ops/lambda_operator/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.algorithms.lambda_operator import lambda_operator\nfrom pybeamline.sinks.print_sink import print_sink\n\nlog_source([\"ABC\",\"DEF\"]).pipe(\n    lambda_operator(lambda x: 'CURRENT ACTIVITY IS ' + x.get_event_name()),\n    lambda_operator(lambda x: x.lower())\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>current activity is a\ncurrent activity is b\ncurrent activity is c\ncurrent activity is d\ncurrent activity is e\ncurrent activity is f\n</code></pre>"},{"location":"pybeamline/utility-ops/print_operator/","title":"print_operator","text":"<p>Allows the print the results during the computation. This is useful for debugging pipelines.</p>"},{"location":"pybeamline/utility-ops/print_operator/#parameters","title":"Parameters","text":"<ul> <li>format_string: <code>str</code> default: <code>None</code>   String format.</li> </ul>"},{"location":"pybeamline/utility-ops/print_operator/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.mappers.print_operator import print_operator\nfrom pybeamline.sinks.print_sink import print_sink\n\nlog_source([\"ABC\", \"ABD\"]).pipe(\n    print_operator(\"DEBUG&gt; {0}\"),\n    skip_events(3)\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>DEBUG&gt; (A, case_1, Process, 2020-00-00 17:00:57.197822 - {} - {} - {})\nDEBUG&gt; (B, case_1, Process, 2020-00-00 17:00:57.197822 - {} - {} - {})\nDEBUG&gt; (C, case_1, Process, 2020-00-00 17:00:57.197822 - {} - {} - {})\n(C, case_1, Process, 2020-00-00 17:00:57.197822 - {} - {} - {})\nDEBUG&gt; (A, case_2, Process, 2020-00-00 17:00:57.197822 - {} - {} - {})\nDEBUG&gt; (B, case_2, Process, 2020-00-00 17:00:57.197822 - {} - {} - {})\nDEBUG&gt; (D, case_2, Process, 2020-00-00 17:00:57.197822 - {} - {} - {})\n(D, case_2, Process, 2020-00-00 17:00:57.197822 - {} - {} - {})\n</code></pre>"},{"location":"pybeamline/utility-ops/skip_events/","title":"skip_events","text":"<p>Lets the pipeline skips the provided number of events.</p>"},{"location":"pybeamline/utility-ops/skip_events/#parameters","title":"Parameters","text":"<ul> <li>events_to_skip: <code>int</code>   The number of events to skip before continuing the flow.</li> </ul>"},{"location":"pybeamline/utility-ops/skip_events/#example","title":"Example","text":"<pre><code>from pybeamline.sources import log_source\nfrom pybeamline.utils.skip_events import skip_events\nfrom pybeamline.sinks.print_sink import print_sink\n\nlog_source([\"ABC\", \"DEF\"]).pipe(\n    skip_events(2)\n).subscribe(print_sink())\n</code></pre> <p>Output:</p> <pre><code>(B, case_1, Process, 2020-00-00 16:33:26.790591 - {} - {} - {})\n(D, case_2, Process, 2020-00-00 16:33:26.791592 - {} - {} - {})\n(F, case_2, Process, 2020-00-00 16:33:26.791592 - {} - {} - {})\n</code></pre>"}]}