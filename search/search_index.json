{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Beamline Framework","text":"<p>Beamline is a framework designed to facilitate the prototyping and the development of streaming process mining algorithms.</p> <p>The framework comprises two libraries: Beamline (Java) and pyBeamline (Python).</p> <p>Beamline, the Java library, is designed on top of Apache Flink which makes it suitable for extremely efficient computation due to the distributed and stateful nature of its components. The Beamline consists of both algorithms as well as data structures, sources, and sinks to facilitate the development of process mining applications. While redefining the concept of event, Beamline tries to maintain compatibility with OpenXES and the IEEE XES standard.</p> <p>pyBeamline is built on ReactiveX and its Python implementation, RxPY - a library for composing asynchronous, event-driven programs using observable sequences and pipable query operators. pyBeamline is suitable for prototyping algorithm very quickly, without necessarily bothering with performance aspects. It also simplifies collaboration by, for example, leveraging online notebook services (like Google Colab).</p>"},{"location":"#streaming-process-mining","title":"Streaming process mining","text":"<p>Process mining is a well establish discipline, aiming at bridging data science and process science together, with the ultimate goal of improving processes and their corresponding executions.</p> <p>Classical process mining techniques take as input so-called event log files: static files containing executions to be analyzed. These event log files are typically structured as XML files according to the IEEE XES standard. These files contain events referring to a fixed period of time and, therefore, the results of the process mining analyses refer to the same time frame.</p> <p>In streaming process mining, the input is not a static file, but an event stream. As in event stream processing, in streaming process mining the goal is to analyze data immediately and update the analysis immediately.</p> <p>The picture below refers to the control-flow discovery case but, obviously, the same principle applies when conformance checking or enhancement algorithms are considered.</p> <p> </p> <p>Conceptualization of the streaming process discovery.</p> <p> Image adapted from: A. Burattin, A. Sperduti, and W. van der Aalst. Control- flow Discovery from Event Streams. In Proc. of IEEE WCCI-CEC, 2014.</p>"},{"location":"#beamline","title":"Beamline","text":"<p>Beamline is a framework meant to simplify the research and the development of streaming process mining, by providing a set of tools that can lift researchers from the burden of setting up streams and running experiments.</p> <p>On the name Beamline</p> <p>The term Beamline is borrowed from high energy physics, where it indicates the physical structure used to define experiments, i.e., where the accelerated particles travel. In the streaming process mining case, Beamline is used to set up experiments where process mining events are processed and consumed.</p> <p>Beamline comprises utility classes as well as some algorithms already implemented that can be used for comparing new techniques with the state of the art.</p>"},{"location":"#citation","title":"Citation","text":"<p>Please, cite this work as:</p> <ul> <li>Andrea Burattin. \"Beamline: A comprehensive toolkit for research and development of streaming process mining\". In Software Impacts, vol. 17 (2023).</li> </ul> BibTeX for citation <pre><code>@article{BURATTIN2023100551,\n  title = {Beamline: A comprehensive toolkit for research and development of streaming process mining},\n  journal = {Software Impacts},\n  volume = {17},\n  pages = {100551},\n  year = {2023},\n  issn = {2665-9638},\n  doi = {https://doi.org/10.1016/j.simpa.2023.100551},\n  url = {https://www.sciencedirect.com/science/article/pii/S266596382300088X},\n  author = {Andrea Burattin},\n  keywords = {Process mining, Streaming process mining, Apache Flink, Reactive programming},\n  abstract = {Beamline is a software library to support the research and development of streaming process mining algorithms. Specifically, it comprises a Java library, built on top of Apache Flink, which fosters high performance and deployment. The second component is a Python library (called pyBeamline, built using ReactiveX) which allows the quick prototyping and development of new streaming process mining algorithms. The two libraries share the same underlying data structures (BEvent) as well as the same fundamental principles, thus making the prototypes (built by researchers using pyBeamline) quickly transferrable to full-fledged and highly scalable applications (using Java Beamline).}\n}\n</code></pre>"},{"location":"about/","title":"About","text":"<p>Beamline is a project developed at the Technical University of Denmark. For further information you can contact</p> <p>Andrea Burattin https://andrea.burattin.net andbur@dtu.dk</p>"},{"location":"about/#citation","title":"Citation","text":"<p>Please, cite this work as:</p> <ul> <li>Andrea Burattin. \"Beamline: A comprehensive toolkit for research and development of streaming process mining\". In Software Impacts, vol. 17 (2023).</li> </ul> BibTeX for citation <pre><code>@article{BURATTIN2023100551,\n  title = {Beamline: A comprehensive toolkit for research and development of streaming process mining},\n  journal = {Software Impacts},\n  volume = {17},\n  pages = {100551},\n  year = {2023},\n  issn = {2665-9638},\n  doi = {https://doi.org/10.1016/j.simpa.2023.100551},\n  url = {https://www.sciencedirect.com/science/article/pii/S266596382300088X},\n  author = {Andrea Burattin},\n  keywords = {Process mining, Streaming process mining, Apache Flink, Reactive programming},\n  abstract = {Beamline is a software library to support the research and development of streaming process mining algorithms. Specifically, it comprises a Java library, built on top of Apache Flink, which fosters high performance and deployment. The second component is a Python library (called pyBeamline, built using ReactiveX) which allows the quick prototyping and development of new streaming process mining algorithms. The two libraries share the same underlying data structures (BEvent) as well as the same fundamental principles, thus making the prototypes (built by researchers using pyBeamline) quickly transferrable to full-fledged and highly scalable applications (using Java Beamline).}\n}\n</code></pre> <p>Another relevant publication where the framework is presented is:</p> <ul> <li>Andrea Burattin. \"Streaming Process Mining with Beamline (Extended Abstract). In Proceedings of ICPM Doctoral Consortium and Tool Demonstration Track, CEUR Workshop Proceedings, 2022: 75-79. </li> </ul> <p>Implemented techniques have corresponding citation information on their documentation page.</p>"},{"location":"additional-libraries/","title":"Additional libraries","text":"<p>This page lists some additional libraries that are useful for the development of Beamline:</p> <ul> <li>MQTT-XES</li> <li>Simple PNML</li> </ul>"},{"location":"getting-started/","title":"Getting started","text":""},{"location":"getting-started/#installing-the-library","title":"Installing the library","text":"<p>To use the Beamline framework in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the package repository: <pre><code>&lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;jitpack.io&lt;/id&gt;\n        &lt;url&gt;https://jitpack.io&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n</code></pre> Then you can include the dependency to the version you are interested, for example: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;framework&lt;/artifactId&gt;\n    &lt;version&gt;x.y.z&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See https://jitpack.io/#beamline/framework for further details (e.g., using it with Gradle).</p> <p></p>"},{"location":"getting-started/#hello-world-stream-mining","title":"Hello world stream mining","text":"<p>The following code represents a minimum running example that, once implemented in the <code>main</code> method of a Java class should provide some basic understanding of the concepts:</p> <pre><code>// step 1: configuration of the event source (in this case a static file, for reproducibility)\nXesLogSource source = new XesLogSource(\"log-file.xes\");\n\n// step 2: configuration of the algorithm\nDiscoveryMiner miner = new DiscoveryMiner();\nminer.setMinDependency(0.3);\n\n// step 3: construction of the dataflow from the environment\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv.addSource(source)\n   .keyBy(BEvent::getProcessName)\n   .flatMap(miner)\n   .addSink(new SinkFunction&lt;ProcessMap&gt;(){\n       public void invoke(ProcessMap value, Context context) throws Exception {\n           value.generateDot().exportToSvg(new File(\"output.svg\"));\n       };\n   });\n\n// step 4: consumption of the results\nenv.execute();\n</code></pre> <p>In step 1 the stream source is configured and, in this specific case, the stream is defined as coming from a static IEEE XES file. In step 2, an hypothetical miner is created and configured, using custom methods (such as the <code>setMinDependency</code> method). Step 3 consists of the definition of the chain of operations to be performed on each event of the stream. In this case, after the source is connected (<code>addSource</code>), we inform Flink that events can be distributed but all those that belong to the same process should be treated together (<code>keyBy</code>); then the events are <code>flatMap</code>ped - meaning that not all events will result in a mining result - by the miner; and finally a sink is connected to save the SVG map to file (<code>addSink</code>). In step 4, the defined pipeline is finally executed.</p>"},{"location":"getting-started/#basic-concepts","title":"Basic concepts","text":"<p>In this section the basic concepts of the Beamline framework are presented.</p>"},{"location":"getting-started/#streaming-dataflow","title":"Streaming dataflow","text":"<p>Each application based on Apache Flink relies on the concept of streaming dataflow. A streaming dataflow consists of the basic transformations applied to each event, from its origin (called source) until the end (called sink). In between, different operators can be chained together in order to transform the data according to the requirements. Once this pipeline of operations is defined, it can be deployed and Apache Flink will take care of the actual execution, including parallelizing possible operations and distributing the data across the network.</p> <p> </p> <p>Conceptualization of the streaming dataflow as operated by Apache Flink. Picture from https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/learn-flink/overview.   </p>"},{"location":"getting-started/#events","title":"Events","text":"<p>While Apache Flink can be designed to transmit any type of event, the Beamline framework comes with its own definition of event, called <code>BEvent</code>. Here some of the corresponding methods are highlighted:</p>  classDiagram class BEvent {     +Map~String, Serializable~ processAttributes     +Map~String, Serializable~ traceAttributes     +Map~String, Serializable~ eventAttributes     +getProcessName(): String     +getTraceName(): String     +getEventName(): String     +getEventTime(): Date     +setProcessAttribute(String name, XAttribute value)     +setTraceAttribute(String name, XAttribute value)     +setEventAttribute(String name, XAttribute value) }  <p>Essentially, a Beamline event, consists of 3 maps for attributes referring to the process, to the trace, and to the event itself. While it's possible to set all the attributes individually, some convenience methods are proposed as well, such as <code>getTraceName</code> which returns the name of the trace (i.e., the case id). Internally, a <code>BEvent</code> stores the basic information using as attribute names the same provided by the standard extension of OpenXES. Additionally, setters for attributes defined in the context of OpenXES are provided too, thus providing some level of interoperability between the platforms.</p> <p>Comparison with OpenXES</p> <p>While the usage of OpenXES has been considered, it has been decided that it is better to have a proper definition of event which embeds all information. This is due to the fact that in streaming processing each event is an atomic independent unit, i.e., it is not really possible to have collections of traces or collections of events part of the same happening.</p>"},{"location":"getting-started/#sources","title":"Sources","text":"<p>In the context of Beamline it is possible to define sources to create any possible type of event. The framework comes with some sources already defined for the generation of <code>BEvent</code>s. The base class of all sources is called <code>BeamlineAbstractSource</code> which implements a <code>RichSourceFunction</code>. In Apache Flink, a \"rich\" function is a function which can have access to the distributed state and thus become stateful. Sources already implemented are <code>XesLogSource</code>, <code>MQTTXesSource</code>, <code>CSVLogSource</code>, and <code>StringTestSource</code>. A <code>XesLogSource</code> creates a source from a static log (useful for testing purposes). An <code>MQTTXesSource</code> generates an source from an MQTT-XES stream. <code>CSVLogSource</code> is a source which reads events from a text file, and <code>StringTestSource</code> allows the definition of simple log directly in its constructor (useful for testing purposes). The class diagram of the observable sources available in Beamline Framework is reported below:</p>  classDiagram RichSourceFunction~OUT~ &lt;|-- BeamlineAbstractSource : \u00abbind\u00bb OUT\ua789\ua789BEvent BeamlineAbstractSource &lt;|.. XesLogSource BeamlineAbstractSource &lt;|.. CSVLogSource BeamlineAbstractSource &lt;|.. MQTTXesSource BeamlineAbstractSource &lt;|.. StringTestSource RichSourceFunction : +run(SourceContext~OUT~ ctx) void  &lt;&lt; abstract &gt;&gt; RichSourceFunction BeamlineAbstractSource  <p>In order to use any source, it is possible to provide it to the <code>addSource</code> method: <pre><code>BeamlineAbstractSource source = ...\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nDataStream&lt;BEvent&gt; stream = env.addSource(source);\n// add all other transformation operators here...\nenv.execute();\n</code></pre></p> Details on <code>XesLogSource</code> <p>Emits all events from an XES event log. Example usage: <pre><code>XLog l = ...\nXesLogSource source = new XesLogSource(l);\n</code></pre> Or, alternatively, providing directly the path to the log file: <pre><code>XesLogSource source = new XesLogSource(\"path/to/log.xes\"); // any file format supported by OpenXES can be used\n</code></pre></p> Details on <code>CSVLogSource</code> <p>Emits all events from a CSV file, column numbers for case id and activity name must be provided in the constructor. Example usage: <pre><code>int caseIdColumn = 0;\nint activityColumn = 1;\nCSVLogSource source = new CSVLogSource(\"filename.csv\", caseIdColumn, activityColumn);\n</code></pre> Additional configuration parameters can be provided, like the separator: <pre><code>CSVLogSource source = new CSVLogSource(\n    \"filename.csv\",\n    caseIdColumn,\n    activityColumn,\n    new CSVLogSource.ParserConfiguration().withSeparator('|'));\n</code></pre></p> Details on <code>MQTTXesSource</code> <p>Forwards all events on an MQTT broker respecting the MQTT-XES protocol. Example usage: <pre><code>MQTTXesSource source = new MQTTXesSource(\"tcp://broker.hivemq.com:1883\", \"root\", \"processName\");\nsource.prepare();\n</code></pre></p> Details on <code>StringTestSource</code> <p>Source that considers each trace as a string provided in the constructor and each event as one character of the string. Example usage: <pre><code>StringTestSource s = new StringTestSource(\"ABC\", \"ADCE\");\n</code></pre> This source is going to emit 7 events as part of 2 traces.</p>"},{"location":"getting-started/#filters","title":"Filters","text":"<p>The filter operators, in Apache Flink, do not change the type of  stream, but filters the events so that only those passing a predicate test can pass. In Beamline there are some filters already implemented that can be used as follows:</p> <pre><code>BeamlineAbstractSource source = ...\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .filter(new RetainActivitiesFilter(\"A\", \"B\", \"C\"))\n    // add all other transformation operators here...\nenv.execute();\n</code></pre> <p>In line 5 a filter is specified so that only events referring to activities <code>A</code>, <code>B</code>, and <code>C</code> are maintained (while all others are discarded).</p> <p>Filters can operate on event attributes or trace attributes and the following are currently available:</p> Details on <code>RetainOnEventAttributeEqualityFilter</code> <p>Retains events based on the equality of an event attribute. Example: <pre><code>FilterFunction filter = new RetainOnEventAttributeEqualityFilter&lt;String&gt;(\"attribute-name\", \"v1\", \"v2\");\n</code></pre></p> Details on <code>ExcludeOnEventAttributeEqualityFilter</code> <p>Exclude events based on the equality of an event attribute. <pre><code>FilterFunction filter = new ExcludeOnEventAttributeEqualityFilter&lt;String&gt;(\"attribute-name\", \"v1\", \"v2\");\n</code></pre></p> Details on <code>RetainOnCaseAttributeEqualityFilter</code> <p>Retains events based on the equality of a trace attribute. <pre><code>FilterFunction filter = new RetainOnCaseAttributeEqualityFilter&lt;String&gt;(\"attribute-name\", \"v1\", \"v2\");\n</code></pre></p> Details on <code>ExcludeOnCaseAttributeEqualityFilter</code> <p>Excludes events based on the equality of a trace attribute. <pre><code>FilterFunction filter = new ExcludeOnCaseAttributeEqualityFilter&lt;String&gt;(\"attribute-name\", \"v1\", \"v2\");\n</code></pre></p> Details on <code>RetainActivitiesFilter</code> <p>Retains activities base on their name (<code>concept:name</code>). <pre><code>FilterFunction filter = new RetainActivitiesFilter(\"act-1\", \"act2\");\n</code></pre></p> Details on <code>ExcludeActivitiesFilter</code> <p>Excludes activities base on their name (<code>concept:name</code>). <pre><code>FilterFunction filter = new ExcludeActivitiesFilter(\"act-1\", \"act2\");\n</code></pre></p> <p>Please note that filters can be chained together in order to achieve the desired result.</p>"},{"location":"getting-started/#mining-algorithms","title":"Mining algorithms","text":"<p>A mining algorithm is a <code>flatMap</code>er consuming events generated from a source. All mining algorithms must extend the abstract class <code>StreamMiningAlgorithm</code>. This class is structured as:</p>  classDiagram class RichFlatMapFunction~IN, OUT~ class StreamMiningAlgorithm~T extends Response~ &lt;&lt; abstract &gt;&gt; StreamMiningAlgorithm StreamMiningAlgorithm:+ingest(BEvent event)* T StreamMiningAlgorithm:+getProcessedEvents() long  &lt;&lt; abstract &gt;&gt; RichFlatMapFunction  RichFlatMapFunction &lt;|-- StreamMiningAlgorithm : \u00abbind\u00bb IN\ua789\ua789BEvent  <p>The generic types <code>T</code> refers to the type of the generated output (i.e., the result of the mining algorithm). The only abstract method that needs to be implemented by a mining algorithm is <code>ingest(BEvent event) : K</code> which receives an event as actual parameter and returns the result of the ingestion of the event as value or the special value <code>null</code>. If <code>null</code> is returned, nothing will be propagated down to the pipeline, for example, it might not be interesting to mine a process for each event observed, but maybe every 100 events (and thus the reason for having a <code>flatMap</code>). The other method offered is <code>getProcessedEvents() : long</code> that returns the number of events processed up to now.</p> <p>Since a <code>StreamMiningAlgorithm</code> is a \"rich\" function, it is possible to have access to the status information. Additionally, since this operator might be distributed, it is necessary to apply it on a keyed stream. A key can be used to split the stream into independent \"branches\" that can be processed in parallel by different instances of the operators occurring afterwards. It is therefore extremely important to choose wisely how to key a stream. Instances of the same operator that are applied on different \"branches\" (obtained by keying the stream) cannot communicate between each other. Examples of keys in different contexts:</p> <ul> <li>If the goal is to perform control-flow discovery, probably it is necessary to key the stream based on the process name (using <code>keyBy(BEvent::getProcessName)</code>): all events that belong to the same process should be considered by the same instance of the mining algorithm to extract the same process;</li> <li>If the goal is to perform conformance checking, probably it is enough to key the stream based on the process instance (a.k.a., trace name or case id; using <code>keyBy(BEvent::getTraceName)</code>): in a streaming context, each trace is independent from the others with respect to the goal of calculating their conformance, and hence there is no need to share information regarding the whole process.</li> </ul> <p>In the core of the Beamline library there is only one mining algorithm implemented (though other are available as additional dependencies):</p> Details on <code>InfiniteSizeDirectlyFollowsMapper</code> <p>An algorithm that transforms each pair of consequent event appearing in the same case as a directly follows operator (generating an object with type <code>DirectlyFollowsRelation</code>). This mapper is called infinite because it's memory footprint will grow as the case ids grow. The mapper produces results as <code>DirectlyFollowsRelation</code>s.</p> <p>An example of how the algorithm can be used is the following:</p> <pre><code>BeamlineAbstractSource source = ...\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .keyBy(BEvent::getProcessName)\n    .flatMap(new InfiniteSizeDirectlyFollowsMapper())\n    .addSink(new SinkFunction&lt;DirectlyFollowsRelation&gt;() {\n        public void invoke(ProcessMap value, Context context) throws Exception {\n            System.out.println(value.getFrom() + \" -&gt; \" + value.getTo());\n        };\n    });\nenv.execute();\n</code></pre>"},{"location":"getting-started/#responses","title":"Responses","text":"<p>Responses are produced by miners as events are processed. Currently, Beamline supports an empty <code>Response</code> class which might be extended to custom behavior as well as a Graphviz graphical representation in a <code>GraphvizResponse</code> abstract class and some others. On all <code>Response</code> objects it is possible to invoke the <code>getProcessedEvents()</code> method, which indicates how many events that response has processed. Hence this is the hierarchy of results:</p>  classDiagram class Response &lt;&lt; abstract &gt;&gt; Response Response : getProcessedEvents() long  class StringResponse StringResponse : get() String  class GraphvizResponse &lt;&lt; abstract &gt;&gt; GraphvizResponse GraphvizResponse : generateDot()* Dot  class DirectlyFollowsRelation DirectlyFollowsRelation : getCaseId() String DirectlyFollowsRelation : getFrom() BEvent DirectlyFollowsRelation : getTo() BEvent  Response &lt;|-- StringResponse Response &lt;|-- DirectlyFollowsRelation Response &lt;|-- GraphvizResponse  <p>An example of a way to consume these results is reported in the following code:</p> <pre><code>BeamlineAbstractSource source = ...\nDiscoveryMiner miner = new DiscoveryMiner();\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner)\n    .addSink(new SinkFunction&lt;GraphvizResponse&gt;() {\n        public void invoke(GraphvizResponse value, Context context) throws Exception {\n            value.generateDot().exportToSvg(new File(\"output-\" + value.getProcessedEvents() + \".svg\"));\n        };\n    });\nenv.execute();\n</code></pre> <p>In this code, we assume the existence of a miner called <code>DiscoveryMiner</code> which produces output as an object with (sub)type <code>GraphvizResponse</code>.</p>"},{"location":"getting-started/#citation","title":"Citation","text":"<p>Please, cite this work as:</p> <ul> <li>Andrea Burattin. \"Beamline: A comprehensive toolkit for research and development of streaming process mining\". In Software Impacts, vol. 17 (2023).</li> </ul>"},{"location":"mqtt-xes/","title":"MQTT-XES","text":"<p>MQTT-XES is a lightweight library for real-time logging over MQTT, for process mining purposes.  The MQTT-XES library is described in the corresponding paper:</p> <ul> <li>MQTT-XES: Real-time Telemetry for Process Event Data A. Burattin, M. Eigenmann, R. Seiger, B. Weber In Online Proceedings of the BPM Demo Track 2020; Sevilla, Spain; September, 13-18 2020; CEUR-WS.org 2020.</li> </ul>"},{"location":"mqtt-xes/#installing-the-library","title":"Installing the library","text":"<p>To use the library in your Maven project it is necessary to include, in the <code>pom.xml</code> file, the package repository: <pre><code>&lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;jitpack.io&lt;/id&gt;\n        &lt;url&gt;https://jitpack.io&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n</code></pre> Then you can include the dependency to the version you are interested, for example: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;mqtt-xes&lt;/artifactId&gt;\n    &lt;version&gt;0.3.5&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See https://jitpack.io/#beamline/mqtt-xes for further details (e.g., using it with Gradle).</p>"},{"location":"mqtt-xes/#sending-events","title":"Sending events","text":"<p>To generate events to be sent using MQTT-XES it is possible to use the following code snippet, first to create the client: <pre><code>XesMqttProducer client = new XesMqttProducer(\"broker.hivemq.com\", \"BASE\");\n</code></pre> It is also necessary to create the event that has to be sent: <pre><code>XesMqttEvent event = new XesMqttEvent(\"source-id\", \"case-id\", \"activity\")\n    .addTraceAttribute(\"name\", \"value\")\n    .addEventAttribute(\"name\", \"value\");\n</code></pre> Finally, it is possible to send the event using the client object previously defined: <pre><code>client.connect();\nclient.send(event);\nclient.disconnect();\n</code></pre></p>"},{"location":"mqtt-xes/#consuming-events","title":"Consuming events","text":"<p>To consume events, it is first necessary to create a consumer client, using the following code snippet: <pre><code>XesMqttConsumer client = new XesMqttConsumer(\"broker.hivemq.com\", \"BASE\");\n</code></pre> Once the client is set, it is possible to subscribe to the MQTT-XES events being sent and a callback class need to be provided. Please note that the <code>accept</code> method of <code>XesMqttEventCallback</code> receives a XesMqttEvent: <pre><code>client.subscribe(new XesMqttEventCallback() {\n    @Override\n    public void accept(XesMqttEvent e) {\n        System.out.println(e.getProcessName() + \" - \" + e.getCaseId() + \" - \" + e.getActivityName());\n    }\n});\n</code></pre></p>"},{"location":"pybeamline/","title":"pyBeamline","text":"<p>pyBeamline is a Python version of Beamline. While the same set of ideas and principles of Beamline have been ported into pyBeamline, the underlying goal and technology are very different.</p> <p>pyBeamline is based on ReactiveX and its Python binding RxPY. RxPY is a library for composing asynchronous and event-based programs using observable sequences and pipable query operators in Python. Using pyBeamline it is possible to inject process mining operators into the computation.</p> <p>A complete Jupyter notebook presenting all implemented techniques is available at https://github.com/beamline/pybeamline/blob/master/tutorial.ipynb.</p> <p> </p>"},{"location":"pybeamline/#pybeamline-designer","title":"pyBeamline Designer","text":"<p>To help getting started, you can try the pyBeamline Designer, available at https://beamline.github.io/pybeamline-designer/:</p> <p> </p> https://beamline.github.io/pybeamline-designer/"},{"location":"pybeamline/#goals-and-differences-with-beamline","title":"Goals and differences with Beamline","text":"<p>The main difference between Beamline and pyBeamline is the language they are built in (Beamline is written in Java, pyBeamline is written in Python). However, differences do not stop here. In particular, Beamline is built on top of Apache Flink, which makes it suitable for extremely efficient computation due to the distributed and stateful nature of its components. pyBeamline, on the other end, is built on top of ReactiveX which is</p> <p>an extension of the observer pattern to support sequences of data and/or events and adds operators that allow you to compose sequences together declaratively while abstracting away concerns about things like low-level threading, synchronization, thread-safety, concurrent data structures, and non-blocking I/O. (From https://reactivex.io/intro.html)</p> <p>Therefore, pyBeamline is suited for prototyping algorithm very quickly, without necessarily bothering with performance aspects. In a sense, it simplifies the construction of proof of concepts, before translating the algorithms into Beamline for proper testing and verification. Also, it simplifies collaboration by, for example, leveraging online services (like Google Colab).</p> <p>To give an example of such simplicity, this is the complete code to discover a DFG using a sliding window from a stream generated from a <code>test.xes</code> file (a file is used instead of a proper stream, as we are in a very controlled setting):</p> <pre><code>from pybeamline.sources import xes_log_source_from_file\nfrom pybeamline.mappers import sliding_window_to_log\nfrom reactivex.operators import window_with_count\nfrom pm4py import discover_dfg_typed\n\nxes_log_source_from_file(\"test.xes\").pipe(\n    window_with_count(6),\n    sliding_window_to_log()\n).subscribe(lambda log: print(discover_dfg_typed(log)))\n</code></pre>"},{"location":"pybeamline/#differences-with-pm4py","title":"Differences with PM4PY","text":"<p>PM4PY has a package dedicated to streaming algorithms. This package, however, does not allow the construction of the dataflow for the processing of the events. Instead, it allows the application of a single algorithm on a defined stream. While this might be useful in certain situation, having the ability to construct the dataflow represents a fundamental architecture for stream processing.</p> What is a dataflow? <p>Here is the definition from the corresponding Wikipedia page:</p> <p>In computing, dataflow is a broad concept, which has various meanings depending on the application and context. In the context of software architecture, data flow relates to stream processing or reactive programming.</p> <p>[...]</p> <p>Dataflow computing is a software paradigm based on the idea of representing computations as a directed graph, where nodes are computations and data flow along the edges. Dataflow can also be called stream processing or reactive programming.</p> <p>There have been multiple data-flow/stream processing languages of various forms (see Stream processing). Data-flow hardware (see Dataflow architecture) is an alternative to the classic von Neumann architecture. The most obvious example of data-flow programming is the subset known as reactive programming with spreadsheets. As a user enters new values, they are instantly transmitted to the next logical \"actor\" or formula for calculation.</p> <p>Distributed data flows have also been proposed as a programming abstraction that captures the dynamics of distributed multi-protocols. The data-centric perspective characteristic of data flow programming promotes high-level functional specifications and simplifies formal reasoning about system components.</p>"},{"location":"pybeamline/#installing-the-library","title":"Installing the library","text":"<p>To use pyBeamline on any OS, install it using <code>pip</code>: <pre><code>pip install pybeamline\n</code></pre> More information are available at https://pypi.org/project/pybeamline/.</p>"},{"location":"pybeamline/#basic-concepts","title":"Basic concepts","text":"<p>In this section the basic concepts of pyBeamline are presented.</p>"},{"location":"pybeamline/#events","title":"Events","text":"<p>The pyBeamline framework comes with its own definition of event, called <code>BEvent</code>, similarly to what is defined in Beamline. Here some of the corresponding methods are highlighted:</p>  classDiagram class BEvent {     +dict process_attributes     +dict trace_attributes     +dict event_attributes     +get_process_name(): str     +get_trace_name(): str     +get_event_name(): str     +get_event_time(): datetime }  <p>Essentially, a Beamline event, consists of 3 maps for attributes referring to the process, to the trace, and to the event itself. While it's possible to set all the attributes individually, some convenience methods are proposed as well, such as <code>getTraceName</code> which returns the name of the trace (i.e., the case id). Internally, a <code>BEvent</code> stores the basic information using as attribute names the same provided by the standard extension of OpenXES. Additionally, setters for attributes defined in the context of OpenXES are provided too, thus providing some level of interoperability between the platforms.</p>"},{"location":"pybeamline/#observables-and-sources","title":"Observables and Sources","text":"<p>An observer subscribes to an Observable. Then that observer reacts to whatever item or sequence of items the Observable emits. This pattern facilitates concurrent operations because it does not need to block while waiting for the Observable to emit objects, but instead it creates a sentry in the form of an observer that stands ready to react appropriately at whatever future time the Observable does so. -- Text from https://reactivex.io/documentation/observable.html.</p>"},{"location":"pybeamline/#general-sources","title":"General sources","text":"<p>In the context of Beamline it is possible to define observables of any type. The framework comes with some observables already defined. Sources already implemented are <code>xes_log_source</code>, <code>xes_log_source_from_file</code>, and <code>string_test_source</code>. A <code>xes_log_source</code> creates a source from a static log (useful for testing purposes), <code>xes_log_source_from_file</code> creates a source from an XES file, and <code>string_test_source</code> allows the definition of simple log directly in its constructor (useful for testing purposes).</p> Details on <code>xes_log_source</code> and <code>xes_log_source_from_file</code> <p>Emits all events from an XES event log. Example usage: <pre><code>import pm4py\nfrom pybeamline.sources import xes_log_source\n\nxes_log_source(pm4py.read_xes(\"test.xes\")) \\\n    .subscribe(lambda x: print(str(x)))\n</code></pre></p> <p>A shortcut to load from a file is: <pre><code>import pm4py\nfrom pybeamline.sources import xes_log_source_from_file\n\nxes_log_source_from_file(\"test.xes\") \\\n    .subscribe(lambda x: print(str(x)))\n</code></pre></p> Details on <code>string_test_source</code> <p>Source that considers each trace as a string provided in the constructor and each event as one character of the string. Example usage: <pre><code>from pybeamline.sources import string_test_source\n\nstring_test_source([\"ABC\", \"ACB\", \"EFG\"]) \\\n    .subscribe(lambda x: print(str(x)))\n</code></pre></p> Details on <code>log_source</code> <p>Example of usages: <pre><code>log_source(\"test.xes\") # This is equivalent to xes_log_source_from_file(\"test.xes\")\n</code></pre> <pre><code>log = pm4py.read_xes(\"test.xes\")\nlog_source(log) # This is equivalent to xes_log_source(log)\n</code></pre> <pre><code>log_source([\"ABC\", \"ACB\", \"EFG\"]) # This is equivalent to string_test_source([\"ABC\", \"ACB\", \"EFG\"])\n</code></pre></p> <p>The following sources offer connections to external services:</p> Details on <code>mqttxes_source</code> <p>Source that connects to an MQTT endpoint and expects events to be published according to the MQTT-XES format (see https://beamline.cloud/mqtt-xes/). Example usage: <pre><code>from pybeamline.sources import mqttxes_source\n\nmqttxes_source('broker.mqtt.cool', 1883, 'base/topic/') \\\n    .subscribe(lambda x: print(str(x)))\n\ninput()\n</code></pre> Where <code>broker.mqtt.cool</code> is the URL of the MQTT broker, 1883 is the broker port, and <code>base/topic/</code> is the base topic. Please note the <code>input()</code> at the end, which is necessary to avoid that the application terminates thus not receiving any more events.</p>"},{"location":"pybeamline/#real-world-sources","title":"Real-world sources","text":"<p>In addition to the previous sources these are also implemented. The following sources observe real data and hence are not controllable and maybe not suitable for testing.</p> Details on <code>wikimedia_source</code> <p>Source that connects to the stream of recent change operations happening on the Media Wiki websites (see https://wikitech.wikimedia.org/wiki/Event_Platform/EventStreams_HTTP_Service and https://www.mediawiki.org/wiki/Manual:RCFeed). Example usage: <pre><code>from pybeamline.sources.real_world_sources import wikimedia_source\n\nwikimedia_source() \\\n    .subscribe(lambda x: print(str(x)))\n\ninput()\n</code></pre> It is advisable to apply a filter operation to consider only events relevant to one of the websites, such as: <pre><code>from pybeamline.sources.real_world_sources import wikimedia_source\nfrom pybeamline.filters import retains_on_event_attribute_equal_filter\n\nwikimedia_source().pipe(\n    retains_on_event_attribute_equal_filter(\"wiki\", [\"dewiki\"]),\n).subscribe(lambda x: print(str(x)))\n\ninput()\n</code></pre></p> Details on <code>ais_source</code> <p>The automatic identification system (AIS) is an automatic tracking system that uses transceivers on ships and is used by vessel traffic services. This source considers the MMSI (https://en.wikipedia.org/wiki/Maritime_Mobile_Service_Identity) as the case id and the navigation status (when available) as the activity (https://en.wikipedia.org/wiki/Automatic_identification_system#Broadcast_information). While it is possible connect to any AIS data provider (by passing <code>host</code> and <code>port</code> parameters), by default, the source connects to the Norwegian Coastal Administration server, which publishes data for the from vessels within the Norwegian economic zone and the protection zones off Svalbard and Jan Mayen (see https://www.kystverket.no/en/navigation-and-monitoring/ais/access-to-ais-data/).</p> <p>ATTENTION: while a lot of events are produced by this source, traces are very short and it can take a long time before two events with the same case id are actually observed.</p> <p>Example usage: <pre><code>from pybeamline.sources.real_world_sources import ais_source\n\nais_source() \\\n    .subscribe(lambda x: print(str(x)))\n</code></pre></p> Details on <code>rejseplanen_source</code> <p>This source provides the data from the Danish railway system. Traces are represented as individual trains and events are trains reaching a certain station. The data is continuously generate (updated every 5 seconds, see https://www.rejseplanen.dk/bin/help.exe/mn?L=vs_dot.vs_livemap&amp;tpl=fullscreenmap). The current source retrieves information about regional and light train (letbane).</p> <p>Example usage: <pre><code>from pybeamline.sources.real_world_sources import rejseplanen_source\n\nrejseplanen_source() \\\n    .subscribe(lambda x: print(str(x)))\n</code></pre></p>"},{"location":"pybeamline/#combining-sources","title":"Combining sources","text":"<p>In order to build tests where drifts occur in a controlled setting, it is possible to concatenate different sources together. See the example below: <pre><code>from reactivex import concat\nfrom pybeamline.sources import xes_log_source_from_file, log_source\n\nsrc1 = xes_log_source_from_file(\"tests/log.xes\")\nsrc2 = log_source([\"ABCD\", \"ABCD\"])\nsrc3 = xes_log_source_from_file(\"tests/log.xes\")\n\nconcat = concat(src1, src2, src3)\nconcat \\\n    .subscribe(lambda x: print(str(x)))\n</code></pre></p>"},{"location":"pybeamline/#filters","title":"Filters","text":"<p>The filter operator, in ReactiveX, does not change the stream, but filters the events so that only those passing a predicate test can pass. In Beamline there are some filters already implemented that can be used as follows:</p> <pre><code>from pybeamline.sources import log_source\nfrom pybeamline.filters import excludes_activity_filter, retains_activity_filter\n\nlog_source([\"ABC\", \"ACB\", \"EFG\"]).pipe(\n    excludes_activity_filter(\"A\"),\n    retains_activity_filter(\"G\")\n).subscribe(lambda x: print(str(x)))\n</code></pre> <p>Filters can operate on event attributes or trace attributes and the following are currently available:</p> Details on <code>retains_on_event_attribute_equal_filter</code> <p>Retains events based on the equality of an event attribute. Example: <pre><code>from pybeamline.sources import log_source\nfrom pybeamline.filters import retains_on_event_attribute_equal_filter\n\nlog_source(\"test.xes\").pipe(\n    retains_on_event_attribute_equal_filter(\"event-attrib\", [\"ev\", \"ab\"]),\n).subscribe(lambda x: print(str(x)))\n</code></pre></p> Details on <code>excludes_on_event_attribute_equal_filter</code> <p>Exclude events based on the equality of an event attribute. <pre><code>from pybeamline.sources import log_source\nfrom pybeamline.filters import excludes_on_event_attribute_equal_filter\n\nlog_source(\"test.xes\").pipe(\n    excludes_on_event_attribute_equal_filter(\"event-attrib\", [\"ev\", \"ab\"]),\n).subscribe(lambda x: print(str(x)))\n</code></pre></p> Details on <code>retains_on_trace_attribute_equal_filter</code> <p>Retains events based on the equality of a trace attribute. <pre><code>from pybeamline.sources import log_sourcelog_source\nfrom pybeamline.filters import retains_on_trace_attribute_equal_filter\n\nlog_source(\"test.xes\").pipe(\n    retains_on_trace_attribute_equal_filter(\"trace-attrib\", [\"tv\", \"ab\"]),\n).subscribe(lambda x: print(str(x)))\n</code></pre></p> Details on <code>excludes_on_trace_attribute_equal_filter</code> <p>Excludes events based on the equality of a trace attribute. <pre><code>from pybeamline.sources import log_source\nfrom pybeamline.filters import excludes_on_trace_attribute_equal_filter\n\nlog_source(\"test.xes\").pipe(\n    excludes_on_trace_attribute_equal_filter(\"trace-attrib\", [\"tv\", \"ab\"]),\n).subscribe(lambda x: print(str(x)))\n</code></pre></p> Details on <code>retains_activity_filter</code> <p>Retains activities base on their name (<code>concept:name</code>). <pre><code>from pybeamline.sources import log_source\nfrom pybeamline.filters import retains_activity_filter\n\nlog_source([\"ABC\", \"ACB\", \"EFG\"]).pipe(\n    retains_activity_filter(\"G\")\n).subscribe(lambda x: print(str(x)))\n</code></pre></p> Details on <code>excludes_activity_filter</code> <p>Excludes activities base on their name (<code>concept:name</code>). <pre><code>from pybeamline.sources import log_source\nfrom pybeamline.filters import excludes_activity_filter\n\nlog_source([\"ABC\", \"ACB\", \"EFG\"]).pipe(\n    excludes_activity_filter(\"A\"),\n).subscribe(lambda x: print(str(x)))\n</code></pre></p> <p>Please note that filters can be chained together in order to achieve the desired result.</p>"},{"location":"pybeamline/#mappers-and-mining-algorithms","title":"Mappers and mining algorithms","text":"<p>pyBeamline comes with some mining algorithms, which are essentially instantiations of <code>map</code> and <code>flatMap</code> operators. This section reports some detail on these.</p>"},{"location":"pybeamline/#discovery-techniques","title":"Discovery techniques","text":"<p>In the core of the pyBeamline library, currently, there is only one mining algorithm implemented:</p> Details on <code>infinite_size_directly_follows_mapper</code> <p>An algorithm that transforms each pair of consequent event appearing in the same case as a directly follows operator (generating a tuple with the two event names). This mapper is called infinite because it's memory footprint will grow as the case ids grow.</p> <p>An example of how the algorithm can be used is the following:</p> <p><pre><code>from pybeamline.sources import log_source\nfrom pybeamline.mappers import infinite_size_directly_follows_mapper\n\nlog_source([\"ABC\", \"ACB\"]).pipe(\n    infinite_size_directly_follows_mapper()\n).subscribe(lambda x: print(str(x)))\n</code></pre> This code will print: <pre><code>('A', 'B')\n('B', 'C')\n('A', 'C')\n('C', 'B')\n</code></pre></p> Details on <code>simple_dfg_miner</code> <p>An algorithm that simply constructs the DFG considering infinite amount of memory available. It has 2 parameters: the <code>model_update_frequency</code> that determines how often the model should be updated, and the <code>min_relative_frequency</code> that determines the minimum relative frequency that a directly follow relations should have to be generated.</p> <p>An example of how the algorithm can be used is the following: <pre><code>from pybeamline.sources.real_world_sources import wikimedia_source\nfrom pybeamline.algorithms.discovery.dfg_miner import simple_dfg_miner\n\nwikimedia_source().pipe(\n    simple_dfg_miner()\n).subscribe(lambda x: print(str(x)))\n</code></pre></p> Details on <code>heuristics_miner_lossy_counting</code> <p>An algorithm to mine a Heuristics Net using the Lossy Counting algorithm. The Heuristics Net is the same type as in the PM4PY library (see https://pm4py.fit.fraunhofer.de/documentation#item-3-3)</p> <p>An example of how the algorithm can be used is the following:</p> <p><pre><code>from pybeamline.algorithms.discovery import heuristics_miner_lossy_counting\n\nlog_source([\"ABCD\", \"ABCD\"]).pipe(\n    heuristics_miner_lossy_counting(model_update_frequency=4)\n).subscribe(lambda x: print(str(x)))\n</code></pre> This code will print: <pre><code>{'A': (node:A connections:{B:[0.5]}), 'B': (node:B connections:{C:[0.5]}), 'C': (node:C connections:{})}\n{'C': (node:C connections:{D:[0.5]}), 'D': (node:D connections:{}), 'A': (node:A connections:{B:[0.6666666666666666]}), 'B': (node:B connections:{C:[0.6666666666666666]})}\n</code></pre></p> <p>The algorithm is describe in publications:</p> <ul> <li>Control-flow Discovery from Event Streams A. Burattin, A. Sperduti, W. M. P. van der Aalst In Proceedings of the Congress on Evolutionary Computation (IEEE WCCI CEC 2014); Beijing, China; July 6-11, 2014.</li> <li>Heuristics Miners for Streaming Event Data A. Burattin, A. Sperduti, W. M. P. van der Aalst In CoRR abs/1212.6383, Dec. 2012.</li> </ul> Details on <code>heuristics_miner_lossy_counting_budget</code> <p>An algorithm to mine a Heuristics Net using the Lossy Counting with Budget algorithm. The Heuristics Net is the same type as in the PM4PY library (see https://pm4py.fit.fraunhofer.de/documentation#item-3-3)</p> <p>An example of how the algorithm can be used is the following:</p> <p><pre><code>from pybeamline.algorithms.discovery import heuristics_miner_lossy_counting_budget\n\nlog_source([\"ABCD\", \"ABCD\"]).pipe(\n    heuristics_miner_lossy_counting_budget(model_update_frequency=4)\n).subscribe(lambda x: print(str(x)))\n</code></pre> This code will print: <pre><code>{'A': (node:A connections:{B:[0.5]}), 'B': (node:B connections:{C:[0.5]}), 'C': (node:C connections:{D:[0.5]}), 'D': (node:D connections:{})}\n{'A': (node:A connections:{B:[0.6666666666666666]}), 'B': (node:B connections:{C:[0.6666666666666666]}), 'C': (node:C connections:{D:[0.6666666666666666]}), 'D': (node:D connections:{})}\n</code></pre></p> <p>The algorithm is describe in publications:</p> <ul> <li>Control-flow Discovery from Event Streams A. Burattin, A. Sperduti, W. M. P. van der Aalst In Proceedings of the Congress on Evolutionary Computation (IEEE WCCI CEC 2014); Beijing, China; July 6-11, 2014.</li> <li>Heuristics Miners for Streaming Event Data A. Burattin, A. Sperduti, W. M. P. van der Aalst In CoRR abs/1212.6383, Dec. 2012.</li> </ul>"},{"location":"pybeamline/#conformance-checking-techniques","title":"Conformance checking techniques","text":"<p>Currently only conformance checking using behavioral profiles is supported.</p> Details on <code>behavioral_conformance</code> <p>An algorithm to compute the conformance using behavioral patterns.</p> <p>An example of how the algorithm can be used is the following:</p> <p><pre><code>from pybeamline.algorithms.conformance import mine_behavioral_model_from_stream, behavioral_conformance\n\nsource = log_source([\"ABCD\", \"ABCD\"])\nreference_model = mine_behavioral_model_from_stream(source)\nprint(reference_model)\n\nlog_source([\"ABCD\", \"ABCD\"]).pipe(\n    excludes_activity_filter(\"A\"),\n    behavioral_conformance(reference_model)\n).subscribe(lambda x: print(str(x)))\n</code></pre> This code will print: <pre><code>([('A', 'B'), ('B', 'C'), ('C', 'D')], {('A', 'B'): (0, 0), ('B', 'C'): (1, 1), ('C', 'D'): (2, 2)}, {('A', 'B'): 2, ('B', 'C'): 1, ('C', 'D'): 0})\n(1.0, 0.5, 1)\n(1.0, 1.0, 1)\n(1.0, 0.5, 1)\n(1.0, 1.0, 1)\n</code></pre> The algorithm is describe in the publication:</p> <ul> <li>Online Conformance Checking Using Behavioural Patterns A. Burattin, S. van Zelst, A. Armas-Cervantes, B. van Dongen, J. Carmona In Proceedings of BPM 2018; Sydney, Australia; September 2018.</li> </ul>"},{"location":"pybeamline/#windowing-techniques","title":"Windowing techniques","text":"<p>ReactiveX comes with a very rich set of windowing operators that can be fully reused in pyBeamline. Applying a windowing techniques allows the reusage of offline algorithms (for example implemented in PM4PY) as each window is converted into a Pandas DataFrame.</p> <p>To transform the window into a DataFrame, the <code>sliding_window_to_log</code> operators need to be piped to the source.</p> Details on <code>sliding_window_to_log</code> <p>Let's assume, that we want to apply the DFG discovery implemented on PM4PY on a stream usind a tumbling window of size 3. We can pipe the window operator to the <code>sliding_window_to_log</code> so that we can subscribe to <code>EventLog</code>s objects.</p> <p>An example is shown in the following: <pre><code>from pybeamline.sources import log_source\nfrom pybeamline.mappers import sliding_window_to_log\nfrom reactivex.operators import window_with_count\nimport pm4py\n\ndef mine(log):\n    print(pm4py.discover_dfg_typed(x))\n\nlog_source([\"ABC\", \"ABD\"]).pipe(\n    window_with_count(3),\n    sliding_window_to_log()\n).subscribe(mine)\n</code></pre> This code will print: <pre><code>Counter({('A', 'B'): 1, ('B', 'C'): 1})\nCounter({('A', 'B'): 1, ('B', 'D'): 1})\n</code></pre> As can be seen the 2 DFGs are mined from the 2 traces separately (as the tumbling window has size 3, which corresponds to the size of each trace). Using a tumbling window of size 6 (i.e., <code>window_with_count(6)</code>) will produce the following: <pre><code>Counter({('A', 'B'): 2, ('B', 'C'): 1, ('B', 'D'): 1})\n</code></pre> In this case, the only model extracted embeds both traces inside.</p>"},{"location":"pybeamline/#utilities","title":"Utilities","text":"<p>There are some utilities functionalities implemented in the library. They are listed below:</p> Details on <code>lambda_operator</code> <p>This function allows the definition of an operator according to a function defined somewhere else. It is the most flexible operator and, in case a value is return, then the pipeline will continue. If <code>None</code> is returned, then the pipeline does not continue.</p> <p>The example below shows how this operator can be used to define custom filters and custom miners: <pre><code>from pybeamline.algorithms.lambda_operator import lambda_operator\nfrom pybeamline.sources.string_test_source import string_test_source\n\n\ndef my_filter(event):\n    return event if (event.get_event_name() == \"A\") else None\n\n\ndef my_miner(event):\n    return [('Start', event.get_event_name())]\n\n\nstring_test_source([\"ABCDE\", \"ACBDE\"]).pipe(\n    lambda_operator(my_filter),\n    lambda_operator(my_miner)\n).subscribe(lambda x: print(str(x)))\n</code></pre></p> Details on <code>dfg_to_graphviz</code> <p>This function allows the transformation of the DFG produced with the <code>simple_dfg_miner</code> into the corresponding Graphviz string. It can be used for visualization of the model.</p> <p>An example is shown in the following: <pre><code>from pybeamline.sources.real_world_sources import wikimedia_source\nfrom pybeamline.algorithms.discovery.dfg_miner import simple_dfg_miner\nfrom pybeamline.utils import dfg_to_graphviz\n\ndef display(graphviz_string):\n    print(graphviz_string) # In reality, a more advance processing is expected here :)\n\nwikimedia_source().pipe(\n    simple_dfg_miner()\n).subscribe(lambda x: display(dfg_to_graphviz(x)))\n</code></pre></p>"},{"location":"pybeamline/#integration-with-other-libraries","title":"Integration with other libraries","text":""},{"location":"pybeamline/#river","title":"River","text":"<p>River (https://riverml.xyz/) is a library to build online machine learning models. Such models operate on data streams. River includes several online machine learning algorithms that can be used for several tasks, including classification, regression, anomaly detection, time series forecasting, etc. The ideology behind River is to be a generic machine learning which allows to perform these tasks in a streaming manner. Indeed, many batch machine learning algorithms have online equivalents. Note that River also supports some more basic tasks. For instance, you might just want to calculate a running average of a data stream.</p> <p>It is possible to integrate pyBeamline's result into River to leverage its ML capabilities. For example, let's say we want to use concept drift detection using the ADWIN algorithm. In particular, we are interested in computing if the frequency of the directly follows relation <code>BC</code> changes over time. To accomplish this task, let's first build a log where we artificially inject two of such drifts:</p> <p><pre><code>import random\n\nlog_original = [\"ABCD\"]*10000 + [\"ACBD\"]*500\nrandom.shuffle(log_original)\n\nlog_after_drift = [\"ABCD\"]*500 + [\"ACBD\"]*10000\nrandom.shuffle(log_after_drift)\n\nlog_with_drift = log_source(log_original + log_after_drift + log_original)\n</code></pre> In this case, we built two logs (<code>log_original</code> and <code>log_after_drift</code>) which include the same process variants but that differ in the number of occurrences. Finally, we construct our pyBeamline log source <code>log_with_drift</code> by concatenating <code>log_original + log_after_drift + log_original</code>.</p> <p>After that we can use the capabilities of pyBeamline and reactivex to construct a pipeline that produce a sequence of frequencies corresponding to the frequency of directly follows relation <code>BC</code> in window with length 40 (which is chosen as all our traces have length 4). Also note that we leverage the fact that in all our events when <code>B</code> and <code>C</code> appear they are always in the same trace (because of how <code>log_source</code> generates the observable). We will later define a function <code>check_for_drift</code>:</p> <p><pre><code>import reactivex\nfrom reactivex import operators as ops\n\nlog_with_drift.pipe(\n  ops.buffer_with_count(40),\n  ops.flat_map(lambda events: reactivex.from_iterable(events).pipe(\n      ops.pairwise(),\n      ops.filter(lambda x: x[0].get_trace_name() == x[1].get_trace_name() and x[0].get_event_name() == \"B\" and x[1].get_event_name() == \"C\"),\n      ops.count()\n      )\n  )\n).subscribe(lambda x: print(x))\n</code></pre> After this we can define our function for drift detection and collection of points and drift indexes using: <pre><code>from reactivex import operators as ops\nfrom river import drift\n\ndrift_detector = drift.ADWIN()\ndata = []\ndrifts = []\n\ndef check_for_drift():\n  index = 0\n\n  def _process(x):\n    nonlocal index\n    drift_detector.update(x)\n    index = index + 1\n    if drift_detector.drift_detected:\n      drifts.append(index)\n\n  def _check_for_drift(obs):\n    return obs.pipe(ops.do_action(lambda value: _process(value)))\n\n  return _check_for_drift\n</code></pre> With this function available, <code>check_for_drift</code> can now be piped to the previous computation. Plotting the frequencies and the concept drifts will result in the following:</p> <p></p> <p>For a complete working example, see https://github.com/beamline/pybeamline/blob/master/tutorial.ipynb.</p>"},{"location":"pybeamline/#citation","title":"Citation","text":"<p>Please, cite this work as:</p> <ul> <li>Andrea Burattin. \"Beamline: A comprehensive toolkit for research and development of streaming process mining\". In Software Impacts, vol. 17 (2023).</li> </ul>"},{"location":"simple-pnml/","title":"Simple PNML","text":"<p><code>simple-pnml</code> is a library to describe Petri nets and [de]serialize them as PNML XML files.</p> <p>Attention: this library is actually the porting of the ProM PetriNets package, which has been isolated out of the ProM environment and has been made available as Maven dependency. Therefore, the authors of this simple-pnml library are the authors of the ProM version of the PetriNets package (module some changes made by Andrea Burattin for isolating the library from ProM and making it self-contained). The ProM package PetriNets is licensed as L-GPL so this distribution is as well. The original source code of the ProM PetriNets package is located at https://svn.win.tue.nl/repos/prom/Packages/PetriNets/. The ProM packages licenses are discussed in http://www.promtools.org/doku.php?id=packlicense and for general information on ProM you can visit http://www.promtools.org/.</p>"},{"location":"simple-pnml/#installing-the-library","title":"Installing the library","text":"<p>To use the library in your Maven project it is necessary to include, in the <code>pom.xml</code> file, the package repository: <pre><code>&lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;jitpack.io&lt;/id&gt;\n        &lt;url&gt;https://jitpack.io&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n</code></pre> Then you can include the dependency to the version you are interested, for example: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;simple-pnml&lt;/artifactId&gt;\n    &lt;version&gt;0.0.1&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See https://jitpack.io/#beamline/simple-pnml for further details (e.g., using it with Gradle).</p>"},{"location":"simple-pnml/#importing-a-petri-net-from-a-pnml-file","title":"Importing a Petri net from a PNML file","text":"<p>To import a Petri net from a PNML file you can use the following code:</p> <pre><code>Object[] i = PnmlImportNet.importFromStream(new FileInputStream(new File(\"file.pnml\")));\n\nPetrinet net = (Petrinet) i[0];\nMarking marking = (Marking) i[1];\n</code></pre>"},{"location":"simple-pnml/#importing-a-petri-net-from-a-tpn-file","title":"Importing a Petri net from a TPN file","text":"<p>To import a Petri net from a TPN file you can use the following code:</p> <pre><code>Object[] i = TpnImport.importFromStream(new FileInputStream(new File(\"file.tpn\")));\n\nPetrinet net = (Petrinet) i[0];\nMarking marking = (Marking) i[1];\n</code></pre>"},{"location":"simple-pnml/#exporting-a-petri-net-into-a-pnml-file","title":"Exporting a Petri net into a PNML file","text":"<p>To export a Petri net into a PNML file you can use the following code:</p> <pre><code>Petrinet net = ...;\nMarking marking = ...;\n\nPnmlExportNetToPNML.exportPetriNetToPNMLFile(net, marking, new File(\"file.pnml\"));\n</code></pre>"},{"location":"examples/","title":"Introduction","text":"<p>The pages on the left menu contain examples with possible usages of the Beamline library.</p>"},{"location":"examples/monitoring-windows/","title":"Monitoring active windows (for Windows systems)","text":"<p>One possible usage of streaming process mining could involve the monitoring of the current system. One possible way of achieving this goal is to monitor the window currently active (i.e., with the focus) as a proxy for the application being used by the user<sup>1</sup>.</p> <p>To achieve this goal it is possible to define a new <code>XesSource</code> which observes the windows currently active and, whenever there is a new window in focus, emits an event. To accomplish this goal, in the following we make use of the JNA (Java Native Access) library which gives us access to the native shared libraries of the operating system. To have access to the library we need, first of all, to include it in our Maven dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;net.java.dev.jna&lt;/groupId&gt;\n    &lt;artifactId&gt;jna&lt;/artifactId&gt;\n    &lt;version&gt;5.10.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;net.java.dev.jna&lt;/groupId&gt;\n    &lt;artifactId&gt;jna-platform&lt;/artifactId&gt;\n    &lt;version&gt;5.10.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre></p> <p>Once the library is include we can define the method that will return the name of the currently active window on the screen (this works and has been tested on Windows 10 Enterprise):</p> <p><pre><code>class Informer {\n    public static String getWindowName() {\n        int MAX_TITLE_LENGTH = 1024;\n        char[] buffer = new char[MAX_TITLE_LENGTH * 2];\n        HWND hwnd = User32.INSTANCE.GetForegroundWindow();\n        User32.INSTANCE.GetWindowText(hwnd, buffer, MAX_TITLE_LENGTH);\n\n        IntByReference pid = new IntByReference();\n        User32.INSTANCE.GetWindowThreadProcessId(hwnd, pid);\n        HANDLE p = Kernel32.INSTANCE.OpenProcess(\n                Kernel32.PROCESS_QUERY_INFORMATION | Kernel32.PROCESS_VM_READ,\n                false,\n                pid.getValue());\n        Psapi.INSTANCE.GetModuleBaseNameW(p, null, buffer, MAX_TITLE_LENGTH);\n\n        return Native.toString(buffer);\n    }\n\n    public interface Psapi extends StdCallLibrary {\n        @SuppressWarnings(\"deprecation\")\n        Psapi INSTANCE = (Psapi) Native.loadLibrary(\"Psapi\", Psapi.class);\n        WinDef.DWORD GetModuleBaseNameW(HANDLE hProcess, HANDLE hModule, char[] lpBaseName, int nSize);\n    }\n}\n</code></pre> The documentation on the system calls used here can be found on the MSDN documentation (here, for example, the documentation for the <code>GetForegroundWindow</code> function).</p> <p>With this information it is now possible to wrap the code in a proper source: <pre><code>public class WindowsWindowMonitorSource implements BeamlineAbstractSource {\n\n   private static final int POLLING_DELAY = 100; // milliseconds between checks of the active window\n\n   @Override\n   public void run(SourceContext&lt;BEvent&gt; ctx) throws Exception {\n      Queue&lt;BEvent&gt; buffer = new LinkedList&lt;&gt;();\n\n      String caseId = UUID.randomUUID().toString();\n      new Thread(new Runnable() {\n         @Override\n         public void run() {\n            String latestProcess = \"\";\n            while(isRunning()) {\n               String currentProcess = getWindowName();\n               if (!currentProcess.isEmpty() &amp;&amp; !currentProcess.equals(latestProcess)) {\n                  latestProcess = currentProcess;\n                  try {\n                     buffer.add(BEvent.create(\"window\", caseId, currentProcess));\n                  } catch (EventException e) { }\n               }\n\n               try {\n                  Thread.sleep(POLLING_DELAY);\n               } catch (InterruptedException e) { }\n            }\n         }\n      }).start();\n\n      while(isRunning()) {\n         while (isRunning() &amp;&amp; buffer.isEmpty()) {\n            Thread.sleep(100l);\n         }\n         if (isRunning()) {\n            synchronized (ctx.getCheckpointLock()) {\n               BEvent e = buffer.poll();\n               ctx.collect(e);\n            }\n         }\n      }\n   }\n}\n</code></pre> The basic idea is to check every <code>POLLING_DELAY</code> milliseconds for the name of the window currently on focus and, if this has changed, then a new event is published.</p> <p>An example run of the application utilizing the Trivial Miner and the following code: <pre><code>public class WindowsWindowMonitor {\n   public static void main(String[] args) throws Exception {\n      StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n      env\n         .addSource(new WindowsWindowMonitorSource())\n         .keyBy(BEvent::getProcessName)\n         .flatMap(new DirectlyFollowsDependencyDiscoveryMiner().setModelRefreshRate(1).setMinDependency(0))\n         .addSink(new SinkFunction&lt;ProcessMap&gt;(){\n            public void invoke(ProcessMap value, Context context) throws Exception {\n               value.generateDot().exportToSvg(new File(\"src/main/resources/output/output.svg\"));\n            };\n         });\n      env.execute();\n   }\n}\n</code></pre></p> <p>Produces the following map:</p> G e3e9b1010-99f2-42f2-9a8b-b87c95a37494-&gt;e886f2ff8-9c79-453a-b67e-a8ab38501ee0  1.0 (1) e3e9b1010-99f2-42f2-9a8b-b87c95a37494-&gt;ef91712ff-1664-431b-9547-561693db89c9  1.0 (1) e98d60a8f-7389-47c7-aea3-7b135deb82db-&gt;e3e9b1010-99f2-42f2-9a8b-b87c95a37494  1.0 (1) e886f2ff8-9c79-453a-b67e-a8ab38501ee0-&gt;e98d60a8f-7389-47c7-aea3-7b135deb82db  1.0 (1) e3c37b245-6359-445f-b594-77d60b1ea9c8-&gt;e3e9b1010-99f2-42f2-9a8b-b87c95a37494  1.0 (1) ef91712ff-1664-431b-9547-561693db89c9-&gt;e3e9b1010-99f2-42f2-9a8b-b87c95a37494  1.0 (1) ef949dfe4-9d22-4d8e-8a7a-04df7737f67d-&gt;e3c37b245-6359-445f-b594-77d60b1ea9c8 e3e9b1010-99f2-42f2-9a8b-b87c95a37494 eclipse.exe 1.0 (3) e98d60a8f-7389-47c7-aea3-7b135deb82db OUTLOOK.EXE 0.33 (1) e886f2ff8-9c79-453a-b67e-a8ab38501ee0 explorer.exe 0.33 (1) e3c37b245-6359-445f-b594-77d60b1ea9c8 chrome.exe 0.33 (1) ef91712ff-1664-431b-9547-561693db89c9 cmd.exe 0.33 (1) ef949dfe4-9d22-4d8e-8a7a-04df7737f67d <p>The complete code of this example is available in the GitHub repository https://github.com/beamline/examples/tree/master/src/main/java/beamline/examples/windowsWindowMonitor.</p> <ol> <li> <p>It is important to emphasize that the active window might not really be the one that the user is currently using. For example, a user might be reading a webpage in a browser or a PDF document or another text document while having active another window.\u00a0\u21a9</p> </li> </ol>"},{"location":"examples/no-process-mining-as-input/","title":"Raw data as input (non-process mining ready)","text":"<p>Let's say we have a certain file that we want to consider for processing using Beamline but this file does not meet any of the sources already implemented. Then, this example shows how to process such a file using Beamline.</p> <p>For the sake of simplicity let's consider a file where each line refers to one event but, within the line, the first 3 characters identify the case id, while the rest is the activity name. This is an example of such a file (where <code>001</code> and <code>002</code> are the case ids, and <code>ActA</code>, <code>B</code> and <code>Act_C</code> are the activity names):</p> <pre><code>002ActA\n001ActA\n002B\n002Act_C\n001B\n001Act_C\n</code></pre> <p>To accomplish our goal, we need first to define a source capable of processing the file: <pre><code>BeamlineAbstractSource customSource = new BeamlineAbstractSource() {\n   @Override\n   public void run(SourceContext&lt;BEvent&gt; ctx) throws Exception {\n      Files.lines(Path.of(logFile)).forEach(line -&gt; {\n         String caseId = line.substring(0, 3);\n         String activityName = line.substring(3);\n\n         try {\n            ctx.collect(BEvent.create(\"my-process-name\", caseId, activityName));\n         } catch (EventException e) { }\n      });\n   }\n};\n</code></pre></p> <p>Now, a stream of <code>BEvent</code>s is available and can be processed with any miner available, for example, using the Trivial discovery miner:</p> <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n   .addSource(customSource)\n   .keyBy(BEvent::getProcessName)\n   .flatMap(new DirectlyFollowsDependencyDiscoveryMiner().setModelRefreshRate(1).setMinDependency(0.1))\n   .addSink(new SinkFunction&lt;ProcessMap&gt;() {\n      @Override\n      public void invoke(ProcessMap value, Context context) throws Exception {\n         value.generateDot().exportToSvg(new File(\"src/main/resources/output/output.svg\"));\n      };\n   });\nenv.execute();\n</code></pre> <p>In this case, we configured the miner to consume all events and, once the stream is completed (in this case we do know that the stream will terminate) we dump the result of the miner into a file <code>output.svg</code> which will contain the following model:</p> G e6def0aa8-a25c-48d9-8be2-b6873af41849-&gt;e6fd0d0c8-9bf8-41b4-b32c-27d996d529ec  1.0 (2) e6fd0d0c8-9bf8-41b4-b32c-27d996d529ec-&gt;efed7b698-4a16-44d5-99db-2afa47a4c8e4  1.0 (2) efed7b698-4a16-44d5-99db-2afa47a4c8e4-&gt;e05520936-aa17-4739-bad0-7d560003a923 ef4d5585f-76e4-451b-badf-d504407d9581-&gt;e6def0aa8-a25c-48d9-8be2-b6873af41849 e6def0aa8-a25c-48d9-8be2-b6873af41849 ActA 1.0 (2) e6fd0d0c8-9bf8-41b4-b32c-27d996d529ec B 1.0 (2) efed7b698-4a16-44d5-99db-2afa47a4c8e4 Act_C 1.0 (2) ef4d5585f-76e4-451b-badf-d504407d9581 e05520936-aa17-4739-bad0-7d560003a923 <p>The complete code of this example is available in the GitHub repository https://github.com/beamline/examples/tree/master/src/main/java/beamline/examples/rawData.</p>"},{"location":"examples/open-sky-monitoring/","title":"OpenSky monitoring","text":"<p>OpenSky Network is a non profit project which</p> <p>[...] consists of a multitude of sensors connected to the Internet by volunteers, industrial supporters, and academic/governmental organizations. All collected raw data is archived in a large historical database. The database is primarily used by researchers from different areas to analyze and improve air traffic control technologies and processes.</p> <p>-- Description from https://opensky-network.org/about/about-us</p> <p>Essentially, each airplane uses a transponder to transmit data regarding their status (squawk) as well as their callsign and current position. All this information is collected by OpenSky Network and made available though their APIs.</p> <p>The underlying idea of this example is that each flight (i.e., an airplane callsign) represents the instance of a flight process. The different squawks a plane goes through indicate the activities involved in the process.</p> <p>To achieve this goal, it is necessary to write a new source which periodically queries the OpenSky Network APIs to retrieve the live status of airplanes in a certain area. First it's necessary to create the actual source and initialize the <code>OpenSkyApi</code> wrapper: <pre><code>public class OpenSkySource extends BeamlineAbstractSource {\n    private OpenSkyApi api;\n\n    @Override\n    public void open(Configuration parameters) throws Exception {\n        Properties prop = new Properties();\n        prop.load(new FileInputStream(\"./openskyCredentials.properties\"));\n        api = new OpenSkyApi(prop.getProperty(\"USERNAME\"), prop.getProperty(\"PASSWORD\"));\n    }\n</code></pre> Please note that in this case we use the Java API (imported from JitPack) and we assume the presence of a file <code>openskyCredentials.properties</code> containing username and password for accessing the APIs.</p> <p>Once the system is properly connected to the APIs, then in the <code>run</code> method it is possible to define a separate thread in charge of querying the APIs every 15 seconds and put the events into a buffer which is then used for dispatching them. In the case highlighted the APIs are queried to retrieve flights over the central Europe (lines 19-20). In addition the squawks are parsed to provide some more understandable interpretation (according to the interpretation reported here https://www.flightradars.eu/squawkcodes.html, the actual code of method <code>squawkToString</code> is omitted in this page but is available on the GitHub repository).</p> <pre><code>    @Override\n    public void run(SourceContext&lt;BEvent&gt; ctx) throws Exception {\n        Queue&lt;BEvent&gt; buffer = new LinkedList&lt;&gt;();\n\n        new Thread(() -&gt; {\n            while(isRunning()) {\n                try {\n                    OpenSkyStates os = api.getStates(0, null,\n                        new OpenSkyApi.BoundingBox(\n                            35.0518857, 62.4097744,\n                            -5.8468354, 34.3186395));\n                    if (os != null) {\n                        for (StateVector sv : os.getStates()) {\n                            try {\n                                if (!sv.getCallsign().isBlank()) {\n                                    buffer.add(\n                                        BEvent.create(\n                                            \"squawk\",\n                                            sv.getCallsign().trim(),\n                                            squawkToString(sv.getSquawk())));\n                                }\n                            } catch (EventException e) {\n                                e.printStackTrace();\n                            }\n                        }\n                    } else {\n                        System.out.println(\"No new information...\");\n                    }\n                    Thread.sleep(15000l);\n                } catch (Exception e) {\n                    // nothing to see here\n                    e.printStackTrace();\n                }\n            }\n        }).start();\n\n        while(isRunning()) {\n            while (isRunning() &amp;&amp; buffer.isEmpty()) {\n                Thread.sleep(100l);\n            }\n            if (isRunning()) {\n                synchronized (ctx.getCheckpointLock()) {\n                    BEvent e = buffer.poll();\n                    ctx.collect(e);\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>A simple consumer, in this case the Trivial discovery miner, can then be attached to the source with: <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n   .addSource(new OpenSkySource())\n   .keyBy(BEvent::getProcessName)\n   .flatMap(new DirectlyFollowsDependencyDiscoveryMiner().setModelRefreshRate(10).setMinDependency(0))\n   .addSink(new SinkFunction&lt;ProcessMap&gt;(){\n      public void invoke(ProcessMap value, Context context) throws Exception {\n         value.generateDot().exportToSvg(new File(\"src/main/resources/output/output.svg\"));\n      };\n   });\nenv.execute();\n</code></pre></p> <p>After running the system for about a few minutes, the following map was produced, where essentially only transit squawks were observed:</p> G eec7010c0-450a-418f-b0be-fa2d42391974-&gt;eec7010c0-450a-418f-b0be-fa2d42391974  1.0 (334) eec7010c0-450a-418f-b0be-fa2d42391974 Transit 1.0 (359) <p>The complete code of this example is available in the GitHub repository https://github.com/beamline/examples/tree/master/src/main/java/beamline/examples/opensky.</p>"},{"location":"examples/open-sky-monitoring/#scientific-literature","title":"Scientific literature","text":"<ul> <li>Bringing Up OpenSky: A Large-scale ADS-B Sensor Network for Research.  Matthias Sch\u00e4fer, Martin Strohmeier, Vincent Lenders, Ivan Martinovic and Matthias Wilhelm.  In Proceedings of the 13th IEEE/ACM International Symposium on Information Processing in Sensor Networks (IPSN), pages 83-94, April 2014.</li> </ul>"},{"location":"examples/pybeamline-full-cicle/","title":"pyBeamline full cycle","text":"<p>In this example we are going to see how to use <code>pyBeamline</code> to go all the way from the simulation of an MQTT-XES stream to its mining and the visualization of the results as a Petri net that changes over time.</p> <p>The picture below depicts the architecture of the example.</p>  sequenceDiagram     Emitter -&gt;&gt; MQTT Broker: new event     MQTT Broker -&gt;&gt; Miner: notifies event     activate Miner     Miner --&gt;&gt; MQTT Broker: new model     deactivate Miner     MQTT Broker -&gt;&gt; Results Visualizer: notifies new model  <p>There is an MQTT Broker at the center. The <code>Emitter</code> is in charge of generating the events as MQTT-XES. The <code>Miner</code>, which is subscribed to the MQTT-XES, consumes the events and performs the discovery. It also publishes the models (as Graphviz DOR render of a Petri net) back into the MQTT broker. The <code>ResultVisualizer</code> is a static webpage that connects to the MQTT Broker and subscribes to the models which are rendered and presented as output.</p> <p>All these components can be tested without the need to install anything: it is possible to use a public MQTT broker, the <code>Emitter</code> and the <code>Miner</code> can be hosted on Google Colab (see links below in each section), and a deployment of <code>ResultVisualizer</code> is also available (see link below).</p>"},{"location":"examples/pybeamline-full-cicle/#the-emitter-component","title":"The <code>Emitter</code> component","text":"<p>The <code>Emitter</code> first defines the destination of the MQTT messages, after that a list of all possible traces (referring to a process that contains a sequence, a parallel split/join and an XOR split/join) is reported and finally the system connects to the MQTT broker and starts an infinite loop that publishes one event after the other according to the MQTT-XES specification.</p> <p>Here is the complete code of the <code>Emitter</code>:</p> <pre><code>import paho.mqtt.client as mqtt\nimport time\n\nmqtt_source = {\n    \"broker\": 'broker.emqx.io',\n    \"port\": 1883,\n    \"topic\": 'pybeamline/source'\n}\n\ntraces = []\ntraces.append([\"A\", \"B\", \"C\"])\ntraces.append([\"A\", \"C\", \"B\"])\ntraces.append([\"A\", \"B\", \"C\", \"F\", \"D\"])\ntraces.append([\"A\", \"C\", \"B\", \"F\", \"E\"])\ntraces.append([\"A\", \"B\", \"C\", \"F\", \"E\", \"G\", \"I\"])\ntraces.append([\"A\", \"C\", \"B\", \"F\", \"D\", \"H\", \"I\"])\n\nc = mqtt.Client()\nc.connect(mqtt_source[\"broker\"], mqtt_source[\"port\"], 60)\n\nprocess_name = \"test\"\ntrace_id = 0\nwhile True:\n    for trace in traces:\n        trace_id += 1\n        for activity in trace:\n            c.publish(mqtt_source[\"topic\"] + \"/\" + process_name + \"/C\" + str(trace_id) + \"/\" + activity, \"{}\")\n            time.sleep(0.5)\n</code></pre> <p>Currently, between each event, the scripts waits for 0.5 seconds.</p> <p>Please note that this code is not terminating on purpose: the goal is that events are continuously generated and the generation stops when the script is forced to terminate.</p>"},{"location":"examples/pybeamline-full-cicle/#the-miner-component","title":"The <code>Miner</code> component","text":"<p>In order to configure the <code>Miner</code> component it is necessary to specify the two MQTT endpoints referring to where the event messages are sent and where the model updates should be published.</p> <pre><code>mqtt_source = {\n    \"broker\": 'broker.emqx.io',\n    \"port\": 1883,\n    \"topic\": 'pybeamline/source'\n}\n\nmqtt_target = {\n    \"broker\": 'broker.emqx.io',\n    \"port\": 1883,\n    \"topic\": 'pybeamline/output'\n}\n</code></pre> <p>The script ensures a connection to the MQTT endpoint, then it defines a function to transform the Heuristics Net (produced by <code>heuristics_miner_lossy_counting_budget</code> into the Graphviz DOT representation of the translated Petri net) leveraging the PM4PY functions. At the very end, the <code>pyBeamline</code> pipeline is defined: it connects to the <code>mqttxes_source</code> and defines a pipeline that only contains <code>heuristics_miner_lossy_counting_budget</code>. The results are then processes in a <code>lambda</code> function that converts it to Petri net and publishes them to the MQTT broker.</p> <p>Here is the complete code of the <code>Miner</code>:</p> <pre><code>from pybeamline.sources import mqttxes_source\nfrom pybeamline.algorithms.discovery import heuristics_miner_lossy_counting_budget\nfrom pm4py.objects.conversion.heuristics_net import converter as conversion_factory\nfrom pm4py.visualization.petri_net import visualizer as petri_net_visualizer\nimport paho.mqtt.client as mqtt\n\nclient = mqtt.Client()\nclient.connect(mqtt_target[\"broker\"], mqtt_target[\"port\"], 60)\nclient.loop_start()\n\ndef conversion_from_HN_to_Graphviz(heuristics_net):\n  petri_net, initial_marking, final_marking = conversion_factory.apply(heuristics_net)\n  gviz = petri_net_visualizer.apply(petri_net, initial_marking, final_marking)\n  return str(gviz)\n\nmqttxes_source(mqtt_source[\"broker\"], mqtt_source[\"port\"], mqtt_source[\"topic\"]).pipe(\n    heuristics_miner_lossy_counting_budget(model_update_frequency=4, budget=1000, dependency_threshold=0.75)\n).subscribe(lambda x: client.publish(mqtt_target[\"topic\"], conversion_from_HN_to_Graphviz(x)))\n\ninput()\n</code></pre> <p>Please note that the <code>input()</code> at the very end ensures that the script does not terminate.</p>"},{"location":"examples/pybeamline-full-cicle/#the-result-visualizer-component","title":"The <code>Result Visualizer</code> component","text":"<p>This component is just a static HTML page that connects to the MQTT broker (via web sockets, which must be enabled on the MQTT broker) and subscribes to messages on a certain topics. The payload of the message is assumed to be a Graphviz DOT string (as produced by the <code>Miner</code>) and is then converted into and SVG picture which is displayed and updated with each message.</p> <p>A deployment of such component is available at https://people.compute.dtu.dk/andbur/mqtt-graphviz/ and source code is available at https://github.com/beamline/examples-pybeamline/blob/main/full-cycle-example/mqtt-graphviz-visualizer.html. A screenshot of such page is below:</p> <p></p> <p>The complete code of this example is available in the GitHub repository https://github.com/beamline/examples-pybeamline/tree/main/full-cycle-example.</p>"},{"location":"examples/speech-recognition/","title":"Speech recognition","text":"<p>In this example, we are going to explore a possible usage of streaming process mining in the context of speech recognition: each word a person is saying can be recognized as an activity and the sentences these words belong to can be the process instances. Every time a person waits a considerable amount of time between words, we can assume a new sentence is being said and thus a new case should be generated.</p> <p>To accomplish our goal we need to define a new <code>BeamlineAbstractSource</code> which can listen to the microphone, perform the speech recognition, and generate corresponding events. For the speech recognition we are going to use the Vosk speech recognition toolkit. We also going to use the <code>vosk-model-small-en-us-0.15</code> model which is available on the library website.</p> <p>First we need to setup the Maven dependencies by setting them in the <code>pom.xml</code> file: <pre><code>&lt;dependency&gt;\n   &lt;groupId&gt;com.alphacephei&lt;/groupId&gt;\n   &lt;artifactId&gt;vosk&lt;/artifactId&gt;\n   &lt;version&gt;0.3.33&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n   &lt;groupId&gt;org.json&lt;/groupId&gt;\n   &lt;artifactId&gt;json&lt;/artifactId&gt;\n   &lt;version&gt;20211205&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre></p> <p>Then, once the model folder is properly set, we can configure the source <code>SpeechRecognizerSource</code>. The main idea is to construct a new thread which remains listening for speech and translates it to a string. this has to be inserted into a (potentially never-ending) loop. Within the loop, we can extract the array of all words said until now with:</p> <pre><code>// getPartialResult returns a json object that we convert into its only string object\nString text = (String) new JSONObject(recognizer.getPartialResult()).get(\"partial\");\nif (text.isEmpty()) {\n   // if the text is empty we can skip this round\n   continue;\n}\n// split the sentence into the individual words\nString[] words = text.split(\" \");\n</code></pre> <p>After the new words being said are identified (code not reported here), it is possible to construct the event with: <pre><code>// processing new case ids\nif (lastWordMillisecs + MILLISECS_FOR_NEW_CASE &lt; System.currentTimeMillis()) {\n   caseId++;\n}\nlastWordMillisecs = System.currentTimeMillis();\n\n// prepare the actual event\nbuffer.offer(BEvent.create(\"speech\", \"case-\" + caseId, word));\n</code></pre></p> <p>Where <code>buffer</code> is a buffer used for storing events before they are dispatched to the other operators and <code>MILLISECS_FOR_NEW_CASE</code> is a <code>long</code> indicating how many milliseconds separate each sentence (and hence creates a new case identifier).</p> <p>A simple consumer, in this case the Trivial discovery miner, can then be attached to the source with: <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n   .addSource(new SpeechRecognitionSource())\n   .keyBy(BEvent::getProcessName)\n   .flatMap(new DirectlyFollowsDependencyDiscoveryMiner()\n         .setModelRefreshRate(1)\n         .setMinDependency(0))\n   .addSink(new SinkFunction&lt;ProcessMap&gt;(){\n      public void invoke(ProcessMap value, Context context) throws Exception {\n         System.out.println(value.getProcessedEvents());\n         value.generateDot().exportToSvg(new File(\"src/main/resources/output/output.svg\"));\n      };\n   });\nenv.execute();\n</code></pre></p> <p>In the following example, I tested the system saying two sentences: </p> <ul> <li>\"hello my name is peter\"</li> <li>\"good morning my name is bob\"</li> </ul> <p>The result of the processing is shown below:</p> image/svg+xml G e76ff4afd-c262-4cfe-904d-0468d17f3e76-&gt;eb7dc8274-6332-4dc7-9522-b778782e936f eb73e3c89-127b-4ee2-9704-b2c34178ec08-&gt;e7642d3c2-398a-436c-bd9a-06bd01cbe9b3  0.50 (1) e8af4e578-ab29-42d8-a4e0-ac2ca9f416b0-&gt;e889af76b-8c58-4b36-be88-97ae59fc4b1f  1.0 (2) e889af76b-8c58-4b36-be88-97ae59fc4b1f-&gt;e76ff4afd-c262-4cfe-904d-0468d17f3e76  0.50 (1) e889af76b-8c58-4b36-be88-97ae59fc4b1f-&gt;e9f0d9c0c-45bb-43f2-8fd2-1d1114895797  0.50 (1) e7585ada9-8ea0-49d2-b46a-cae864aa78ae-&gt;e7642d3c2-398a-436c-bd9a-06bd01cbe9b3  0.50 (1) e7642d3c2-398a-436c-bd9a-06bd01cbe9b3-&gt;e8af4e578-ab29-42d8-a4e0-ac2ca9f416b0  1.0 (2) e9f0d9c0c-45bb-43f2-8fd2-1d1114895797-&gt;eb7dc8274-6332-4dc7-9522-b778782e936f eafc5561b-c3c5-452e-8123-b8bfdc453ee2-&gt;eb73e3c89-127b-4ee2-9704-b2c34178ec08 eafc5561b-c3c5-452e-8123-b8bfdc453ee2-&gt;e7585ada9-8ea0-49d2-b46a-cae864aa78ae e76ff4afd-c262-4cfe-904d-0468d17f3e76 peter 0.50 (1) eb73e3c89-127b-4ee2-9704-b2c34178ec08 good morning 0.50 (1) e8af4e578-ab29-42d8-a4e0-ac2ca9f416b0 name 1.0 (2) e889af76b-8c58-4b36-be88-97ae59fc4b1f is 1.0 (2) e7585ada9-8ea0-49d2-b46a-cae864aa78ae hello 0.50 (1) e7642d3c2-398a-436c-bd9a-06bd01cbe9b3 my 1.0 (2) e9f0d9c0c-45bb-43f2-8fd2-1d1114895797 bob 0.50 (1) eafc5561b-c3c5-452e-8123-b8bfdc453ee2 eb7dc8274-6332-4dc7-9522-b778782e936f <p>The two sentences are recognized properly. It is worth noticing that on the second sentence the first 2 words (good morning) have been recognized together, probably because I've said them very quickly, one next to the other.</p> <p>The complete code of this example is available in the GitHub repository https://github.com/beamline/examples/tree/master/src/main/java/beamline/examples/speechRecognition.</p>"},{"location":"examples/wikipedia-edits/","title":"Wikipedia edits","text":"<p>All edits actions happening on Wikipedia are recorded and available as a stream of data (see https://wikitech.wikimedia.org/wiki/Event_Platform/EventStreams for further details). A possible way of process mine the stream of edits happening is by considering the page being edited as the instance of the editing process and the edit \"action\" as the actual activity name.</p> <p>To achieve this goal we can write a new <code>BeamlineAbstractSource</code> that consumes the stream of edits and produces a stream of <code>BEvent</code>s that can then be forwarded to one of the miners. So we can first define our source as well as the set of websites we want to filter (in this case we will focus on edits happening on the English version of Wikipedia, i.e., <code>enwiki</code>):</p> <pre><code>List&lt;String&gt; processesToStream = Arrays.asList(\"enwiki\");\n</code></pre> <p>After then we can write the code to transform the JSON produced by the Wikipedia stream into a stream of <code>XTrace</code>s. </p> <pre><code>Client client = ClientBuilder.newClient();\nWebTarget target = client.target(\"https://stream.wikimedia.org/v2/stream/recentchange\");\nSseEventSource source = SseEventSource.target(target).reconnectingEvery(5, TimeUnit.SECONDS).build();\nsource.register(new Consumer&lt;InboundSseEvent&gt;() {\n   @Override\n   public void accept(InboundSseEvent t) {\n      String data = t.readData();\n      if (data != null) {\n         JSONObject obj = new JSONObject(data);\n\n         String processName = obj.getString(\"wiki\");\n         String caseId = obj.getString(\"title\");\n         String activityName = obj.getString(\"type\");\n\n         if (processesToStream.contains(processName)) {\n            // prepare the actual event\n            try {\n               buffer.add(BEvent.create(processName, caseId, activityName));\n            } catch (EventException e) {\n               e.printStackTrace();\n            }\n         }\n      }\n   }\n});\nsource.open();\n</code></pre> <p>This code can be wrapped in a thread that executes all the time, and stores each event in a buffer for further dispatching:</p> <pre><code>public class WikipediaEditSource extends BeamlineAbstractSource {\n\n   private static final long serialVersionUID = 608025607423103621L;\n   private static List&lt;String&gt; processesToStream = Arrays.asList(\"enwiki\");\n\n   public void run(SourceContext&lt;BEvent&gt; ctx) throws Exception {\n      Queue&lt;BEvent&gt; buffer = new LinkedList&lt;&gt;();\n\n      new Thread(new Runnable() {\n         @Override\n         public void run() {\n            // code from previous listing\n            // ...\n         }\n      }).start();\n\n      while(isRunning()) {\n         while (isRunning() &amp;&amp; buffer.isEmpty()) {\n            Thread.sleep(100l);\n         }\n         if (isRunning()) {\n            synchronized (ctx.getCheckpointLock()) {\n               BEvent e = buffer.poll();\n               ctx.collect(e);\n            }\n         }\n      }\n   }\n}\n</code></pre> <p>A simple consumer, in this case the Trivial discovery miner, can then be attached to the source with: <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n   .addSource(new WikipediaEditSource())\n   .keyBy(BEvent::getProcessName)\n   .flatMap(new DirectlyFollowsDependencyDiscoveryMiner().setModelRefreshRate(10).setMinDependency(0))\n   .addSink(new SinkFunction&lt;ProcessMap&gt;(){\n      public void invoke(ProcessMap value, Context context) throws Exception {\n         value.generateDot().exportToSvg(new File(\"src/main/resources/output/output.svg\"));\n      };\n   });\nenv.execute();\n</code></pre></p> <p>After running the system for about a couple of minutes, the following map was produced:</p> G e9f086037-f263-4023-a09a-65194c88011b-&gt;e0615c600-1e15-47f0-94f6-9ce57be6cab9  0.018 (3) e9f086037-f263-4023-a09a-65194c88011b-&gt;eb542aaf4-fda2-48c0-96c2-b404ab6e59ce  0.0058 (1) ecdf5f385-1425-4bad-8feb-175f435d6826-&gt;e9f086037-f263-4023-a09a-65194c88011b  0.0058 (1) ecdf5f385-1425-4bad-8feb-175f435d6826-&gt;ecdf5f385-1425-4bad-8feb-175f435d6826  0.21 (36) ecdf5f385-1425-4bad-8feb-175f435d6826-&gt;e0615c600-1e15-47f0-94f6-9ce57be6cab9  0.099 (17) e0615c600-1e15-47f0-94f6-9ce57be6cab9-&gt;ecdf5f385-1425-4bad-8feb-175f435d6826  0.053 (9) e0615c600-1e15-47f0-94f6-9ce57be6cab9-&gt;e0615c600-1e15-47f0-94f6-9ce57be6cab9  0.87 (149) eb542aaf4-fda2-48c0-96c2-b404ab6e59ce-&gt;e9f086037-f263-4023-a09a-65194c88011b  0.0058 (1) eb542aaf4-fda2-48c0-96c2-b404ab6e59ce-&gt;e0615c600-1e15-47f0-94f6-9ce57be6cab9  0.0058 (1) eb542aaf4-fda2-48c0-96c2-b404ab6e59ce-&gt;eb542aaf4-fda2-48c0-96c2-b404ab6e59ce  1.0 (171) e5c219b19-76ba-4a89-81e8-472c2f157271-&gt;e9f086037-f263-4023-a09a-65194c88011b e5c219b19-76ba-4a89-81e8-472c2f157271-&gt;ecdf5f385-1425-4bad-8feb-175f435d6826 e5c219b19-76ba-4a89-81e8-472c2f157271-&gt;e0615c600-1e15-47f0-94f6-9ce57be6cab9 e5c219b19-76ba-4a89-81e8-472c2f157271-&gt;eb542aaf4-fda2-48c0-96c2-b404ab6e59ce e9f086037-f263-4023-a09a-65194c88011b new 0.035 (34) ecdf5f385-1425-4bad-8feb-175f435d6826 log 0.13 (121) e0615c600-1e15-47f0-94f6-9ce57be6cab9 edit 1.0 (963) eb542aaf4-fda2-48c0-96c2-b404ab6e59ce categorize 0.43 (412) e5c219b19-76ba-4a89-81e8-472c2f157271 <p>The complete code of this example is available in the GitHub repository https://github.com/beamline/examples/tree/master/src/main/java/beamline/examples/wikipedia.</p>"},{"location":"implemented-techniques/","title":"Introduction","text":"<p>This page lists the streaming process mining techniques currently implemented in the Beamline Framework. To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the package repository: <pre><code>&lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;jitpack.io&lt;/id&gt;\n        &lt;url&gt;https://jitpack.io&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n</code></pre> Then, for each technique to be used, corresponding depepdencies should be includeded as well.</p> <p>Control-flow discovery techniques implemented:</p> <ul> <li>Trivial miner</li> <li>Heuristics miner</li> <li>Declare miner</li> <li>DCR Miner</li> <li>Soft Conformance Model Miner</li> <li>Split Miner</li> </ul> <p>Conformance checking techniques implemented:</p> <ul> <li>Behavioural Patterns</li> <li>Soft Conformance</li> </ul> <p>Random generation of processes and simulation:</p> <ul> <li>Simulation with PLG</li> </ul>"},{"location":"implemented-techniques/conformance-behavioural-patterns/","title":"Behavioural Patterns","text":""},{"location":"implemented-techniques/conformance-behavioural-patterns/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;conformance-behavioural-patterns&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the introduction page for further instructions.</p> <p></p>"},{"location":"implemented-techniques/conformance-behavioural-patterns/#usage","title":"Usage","text":"<p>To use the technique you need to create the conformance checker object using:</p> <pre><code>Petrinet net = ...;\nMarking marking = ...;\nint maxCasesToStore = 1000; // max expected number of parallel process instances\n\nBehavioralConformance conformance = new BehavioralConformance(net, marking, maxCasesToStore);\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .keyBy(BEvent::getTraceName)\n    .flatMap(conformance)\n    .addSink(new SinkFunction&lt;OnlineConformanceScore&gt;(){\n        public void invoke(OnlineConformanceScore value) throws Exception {\n            System.out.println(\n                value.getConformance() + \" - \" +\n                value.getCompleteness() + \" - \" +\n                value.getConfidence());\n        };\n    });\nenv.execute();\n</code></pre> <p>It is worth highlighting that since each trace can be processed independently from the others, it is possible to increase the parallelism by keying the stream based on the case identifier (<code>BEvent::getTraceName</code>, line 9).</p> <p>In the current version, the reference model must be provided as a Petri Net.</p> <p>Importing a Petri net</p> <p>To import a Petri net it is possible to use the <code>simple-pnml</code> library: <pre><code>Object[] i = PnmlImportNet.importFromStream(new FileInputStream(new File(\"petri-net-model.pnml\")));\nPetrinet net = (Petrinet) i[0];\nMarking marking = (Marking) i[1];\n</code></pre></p>"},{"location":"implemented-techniques/conformance-behavioural-patterns/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Online Conformance Checking Using Behavioural Patterns A. Burattin, S. van Zelst, A. Armas-Cervantes, B. van Dongen, J. Carmona In Proceedings of BPM 2018; Sydney, Australia; September 2018.</li> </ul>"},{"location":"implemented-techniques/conformance-soft/","title":"Soft Conformance","text":""},{"location":"implemented-techniques/conformance-soft/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;soft-conformance&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the introduction page for further instructions.</p> <p></p>"},{"location":"implemented-techniques/conformance-soft/#usage","title":"Usage","text":"<p>This conformance approach uses a descriptive model (i.e., a pattern of the observed behavior over a certain amount of time) which is not necessarily referring to the control-flow (e.g., it can be based on the social network of handover of work). To create such a model you need to specify the states and the probability of transitioning. Additionally, it is necessary to specify the likelihood of a random walk (i.e., the parameter \u03b1):</p> <p><pre><code>PDFA reference = new PDFA();\nreference.addNode(\"A\");\nreference.addNode(\"B\");\nreference.addNode(\"C\");\nreference.addEdge(\"A\", \"A\", 0.2);\nreference.addEdge(\"A\", \"B\", 0.8);\nreference.addEdge(\"B\", \"C\", 1);\n</code></pre> This model can be visualized with: <pre><code>PDFAVisualizer.getDot(reference).exportToSvg(new File(\"test.svg\"));\n</code></pre> And here is the output:</p> G e12bcafde-7737-4297-8e45-971bef8040b2 A e12bcafde-7737-4297-8e45-971bef8040b2-&gt;e12bcafde-7737-4297-8e45-971bef8040b2 0.2 e57c465e7-ec29-4da2-9d3e-e1362a897715 B e12bcafde-7737-4297-8e45-971bef8040b2-&gt;e57c465e7-ec29-4da2-9d3e-e1362a897715 0.8 e87bdcf03-5fcf-4aa6-b098-e2ab971bca74 C e57c465e7-ec29-4da2-9d3e-e1362a897715-&gt;e87bdcf03-5fcf-4aa6-b098-e2ab971bca74 1 <p>As can be seen, the model does not allow for any deviation, so it is possible to add weights for possible deviations by using: <pre><code>reference = WeightsNormalizer.normalize(reference, alpha);\n</code></pre> Which transforms the model into:</p> G edf5adbb8-1495-49f7-bf4d-dae11812ecf2 A edf5adbb8-1495-49f7-bf4d-dae11812ecf2-&gt;edf5adbb8-1495-49f7-bf4d-dae11812ecf2 0.27 eab3fce2a-df45-43e8-9b62-89ce28ff3320 B edf5adbb8-1495-49f7-bf4d-dae11812ecf2-&gt;eab3fce2a-df45-43e8-9b62-89ce28ff3320 0.57 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 C edf5adbb8-1495-49f7-bf4d-dae11812ecf2-&gt;ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 0.17 eab3fce2a-df45-43e8-9b62-89ce28ff3320-&gt;edf5adbb8-1495-49f7-bf4d-dae11812ecf2 0.17 eab3fce2a-df45-43e8-9b62-89ce28ff3320-&gt;eab3fce2a-df45-43e8-9b62-89ce28ff3320 0.17 eab3fce2a-df45-43e8-9b62-89ce28ff3320-&gt;ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 0.67 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4-&gt;edf5adbb8-1495-49f7-bf4d-dae11812ecf2 0.17 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4-&gt;eab3fce2a-df45-43e8-9b62-89ce28ff3320 0.17 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4-&gt;ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 0.17 <p>Please note that these models can also be mined. Once a model is available, it is possible to use it for conformance checking with:</p> <pre><code>PDFA reference = ...;\nint maxCasesToStore = 1000; // max expected number of parallel process instances\n\nPDFAConformance conformance = new PDFAConformance(reference, maxCasesToStore);\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .keyBy(BEvent::getTraceName)\n    .flatMap(conformance)\n    .addSink(new SinkFunction&lt;SoftConformanceReport&gt;(){\n        public void invoke(SoftConformanceReport value) throws Exception {\n            for(String caseId : value.keySet()) {\n                System.out.println(\n                    \"Case: \" + caseId + \"\\t\" +\n                    \"soft conformance: \" + value.get(caseId).getSoftConformance() + \"\\t\" +\n                    \"mean of probs: \" + value.get(caseId).getMeanProbabilities());\n            }\n        };\n    });\nenv.execute();\n</code></pre> <p>It is worth highlighting that since each trace can be processed independently from the others, it is possible to increase the parallelism by keying the stream based on the case identifier (<code>BEvent::getTraceName</code>, line 16).</p>"},{"location":"implemented-techniques/conformance-soft/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Online Soft Conformance Checking: Any Perspective Can Indicate Deviations A. Burattin In arXiv:2201.09222, Jan. 2022.</li> </ul>"},{"location":"implemented-techniques/discovery-dcr/","title":"Discovery DCR","text":""},{"location":"implemented-techniques/discovery-dcr/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;discovery-dcr&lt;/artifactId&gt;\n    &lt;version&gt;beamline-framework-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the introduction page for further instructions.</p> <p></p>"},{"location":"implemented-techniques/discovery-dcr/#usage","title":"Usage","text":"<p>To construct a DCR miner it is possible to construct it with the following code:</p> <p><pre><code>Reflections reflections = new Reflections(\"beamline\");\nDFGBasedMiner miner = new DFGBasedMiner(reflections.getTypesAnnotatedWith(ExposedDcrPattern.class));\n</code></pre> In this case we use <code>Reflections</code> to identify and provide all the classes annoted with the <code>@ExposedDcrPattern</code>.</p> <p>It is possible (though not necessary) to configure the miner with the following parameters:</p> <pre><code>// configuration of the refresh rate (i.e., how many events between models update)\nmodel.setModelRefreshRate(1);\n\n// configuration of list of patters\nminer.setDcrPatternsForMining(\"Response\", \"Condition\", \"Include\", \"Exclude\");\n\n// configuration of the miner type\nminer.setStreamMinerType(new UnlimitedStreamMiner());\n//miner.setStreamMinerType(new SlidingWindowStreamMiner(15, 500));\n\n// configure which constraints to visualize\nminer.setDcrConstraintsForVisualization(RELATION.CONDITION, RELATION.RESPONSE);\n\n// configure the threshold\nminer.setRelationsThreshold(0);\n\n// configure the transitive reduction\nminer.setTransitiveReductionList(RELATION.CONDITION, RELATION.RESPONSE);\n</code></pre> <p>Once the miner is properly configured, it can be used as any other consumer. For example, using the following code: <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(new StringTestSource(\"ABCDF\", \"ABCEF\"))\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner)\n    .addSink(new SinkFunction&lt;DeclareModelView&gt;(){\n        public void invoke(DeclareModelView value, Context context) throws Exception {\n            value.generateDot().exportToSvg(new File(\"output.svg\"));\n        };\n    });\nenv.execute();\n</code></pre></p> <p>An example of the output produced is:</p> G e578f0930-aba5-467e-880d-bca6ba0b097a B e67c9c115-c541-48e8-80e5-6901bb8b4734 C e578f0930-aba5-467e-880d-bca6ba0b097a-&gt;e67c9c115-c541-48e8-80e5-6901bb8b4734 e578f0930-aba5-467e-880d-bca6ba0b097a-&gt;e67c9c115-c541-48e8-80e5-6901bb8b4734 e3677451c-681d-46aa-94c8-b6a991735be3 D e67c9c115-c541-48e8-80e5-6901bb8b4734-&gt;e3677451c-681d-46aa-94c8-b6a991735be3 e67c9c115-c541-48e8-80e5-6901bb8b4734-&gt;e3677451c-681d-46aa-94c8-b6a991735be3 ec24f6d71-e3be-4240-8cc5-18467c2ba26e K e67c9c115-c541-48e8-80e5-6901bb8b4734-&gt;ec24f6d71-e3be-4240-8cc5-18467c2ba26e e67c9c115-c541-48e8-80e5-6901bb8b4734-&gt;ec24f6d71-e3be-4240-8cc5-18467c2ba26e eba1a3825-bd6b-4990-bb2a-9995b74ff782 E e3677451c-681d-46aa-94c8-b6a991735be3-&gt;eba1a3825-bd6b-4990-bb2a-9995b74ff782 e3677451c-681d-46aa-94c8-b6a991735be3-&gt;eba1a3825-bd6b-4990-bb2a-9995b74ff782 e4b48c5a5-016c-458c-b830-243e25a8c96d A e4b48c5a5-016c-458c-b830-243e25a8c96d-&gt;e578f0930-aba5-467e-880d-bca6ba0b097a e4b48c5a5-016c-458c-b830-243e25a8c96d-&gt;e578f0930-aba5-467e-880d-bca6ba0b097a"},{"location":"implemented-techniques/discovery-dcr/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Uncovering Change: A Streaming Approach for Declarative Processes  A. Burattin, H. A. L\u00f3pez, L. Starklit In Proceedings of ICPM Workshop (SA4PM), 2022.</li> </ul>"},{"location":"implemented-techniques/discovery-declare/","title":"Declare Miner","text":""},{"location":"implemented-techniques/discovery-declare/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;discovery-declare&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the introduction page for further instructions.</p> <p></p>"},{"location":"implemented-techniques/discovery-declare/#usage","title":"Usage","text":"<p>It is possible to call the two miners <code>beamline.miners.declare.DeclareMinerLossyCounting</code> and <code>beamline.miners.declare.DeclareMinerBudgetLossyCounting</code> using the following:</p> <p><pre><code>DeclareMinerLossyCounting miner = new DeclareMinerLossyCounting(\n    0.001, // the maximal approximation error\n    10 // the number of declare constraints to show\n);\n</code></pre> <pre><code>DeclareMinerBudgetLossyCounting miner = new DeclareMinerBudgetLossyCounting(\n    1000, // the available budget\n    10 // the number of declare constraints to show\n);\n</code></pre></p> <p>After the miner is configured, both can be used to produce a CNet which can be either exported into a <code>.cnet</code> file or visualized (currently the visualization does not support the bindings):</p> <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner.setModelRefreshRate(100))\n    .addSink(new SinkFunction&lt;DeclareModelView&gt;(){\n        public void invoke(DeclareModelView value, Context context) throws Exception {\n            value.generateDot().exportToSvg(new File(\"output.svg\"));\n        };\n    });\nenv.execute();\n</code></pre>"},{"location":"implemented-techniques/discovery-declare/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Online Discovery of Declarative Process Models from Event Streams A. Burattin, M. Cimitile, F. Maggi, A. Sperduti In IEEE Transactions on Services Computing, vol. 8 (2015), no. 6, pp. 833-846.</li> </ul>"},{"location":"implemented-techniques/discovery-heuristics-miner/","title":"Heuristics Miner","text":""},{"location":"implemented-techniques/discovery-heuristics-miner/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;discovery-heuristics&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the introduction page for further instructions.</p> <p></p>"},{"location":"implemented-techniques/discovery-heuristics-miner/#usage","title":"Usage","text":"<p>This miner contains two version of the streaming Heuristics miner. One is based on the Lossy Counting algorithm, the other is based on the Lossy Counting with Budget. These can be accessed with the following parameters:</p> <pre><code>HeuristicsMinerLossyCounting miner = new HeuristicsMinerLossyCounting(\n    0.0001, // the maximal approximation error\n    0.8, // the minimum dependency threshold\n    10, // the positive observation threshold\n    0.1 // the and threshold\n);\n</code></pre> <pre><code>HeuristicsMinerBudgetLossyCounting miner = new HeuristicsMinerBudgetLossyCounting(\n    100000, // the total budget available\n    0.8, // the minimum dependency threshold\n    10, // the positive observation threshold\n    0.1 // the and threshold\n);\n</code></pre> <p>After the miner is configured, both can be used to produce a CNet which can be either exported into a <code>.cnet</code> file or visualized (currently the visualization does not support the bindings):</p> <pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(source)\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner.setModelRefreshRate(100))\n    .addSink(new SinkFunction&lt;StreamingCNet&gt;(){\n        public void invoke(StreamingCNet value, Context context) throws Exception {\n            new CNetSimplifiedModelView(value.getCnet()).exportToSvg(new File(\"output.svg\"));\n        };\n    });\nenv.execute();\n</code></pre>"},{"location":"implemented-techniques/discovery-heuristics-miner/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Control-flow Discovery from Event Streams A. Burattin, A. Sperduti, W. M. P. van der Aalst In Proceedings of the Congress on Evolutionary Computation (IEEE WCCI CEC 2014); Beijing, China; July 6-11, 2014.</li> <li>Heuristics Miners for Streaming Event Data A. Burattin, A. Sperduti, W. M. P. van der Aalst In CoRR abs/1212.6383, Dec. 2012.</li> </ul>"},{"location":"implemented-techniques/discovery-soft/","title":"Soft Conformance Model Miner","text":""},{"location":"implemented-techniques/discovery-soft/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;soft-conformance&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the introduction page for further instructions.</p> <p></p>"},{"location":"implemented-techniques/discovery-soft/#usage","title":"Usage","text":"<p>This miner can be used to extract a model to be used with the Soft Conformance technique. These models are not necessarily referring to the control-flow (e.g., they can be based on the social network of handover of work).</p> <p>This miner extracts just a dependency map leveraging the directly follows relations observed in the stream. Once a <code>XesSource</code> is available, the miner can be configured and used as follows:</p> <pre><code>PDFAMiner miner = new PDFAMiner();\nminer.setModelRefreshRate(1); // configure how ofter the mining algorithm should emit a new model\n\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(new StringTestSource(\"AABC\", \"ABC\", \"ABC\", \"ABC\"))\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner)\n    .addSink(new SinkFunction&lt;PDFA&gt;(){\n        public void invoke(PDFA value, Context context) throws Exception {\n            PDFAVisualizer.getDot(value).exportToSvg(new File(\"output.svg\"));\n        };\n    });\nenv.execute();\n</code></pre> <p>This code will produce the following model:</p> G edf5adbb8-1495-49f7-bf4d-dae11812ecf2 A edf5adbb8-1495-49f7-bf4d-dae11812ecf2-&gt;edf5adbb8-1495-49f7-bf4d-dae11812ecf2 0.27 eab3fce2a-df45-43e8-9b62-89ce28ff3320 B edf5adbb8-1495-49f7-bf4d-dae11812ecf2-&gt;eab3fce2a-df45-43e8-9b62-89ce28ff3320 0.57 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 C edf5adbb8-1495-49f7-bf4d-dae11812ecf2-&gt;ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 0.17 eab3fce2a-df45-43e8-9b62-89ce28ff3320-&gt;edf5adbb8-1495-49f7-bf4d-dae11812ecf2 0.17 eab3fce2a-df45-43e8-9b62-89ce28ff3320-&gt;eab3fce2a-df45-43e8-9b62-89ce28ff3320 0.17 eab3fce2a-df45-43e8-9b62-89ce28ff3320-&gt;ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 0.67 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4-&gt;edf5adbb8-1495-49f7-bf4d-dae11812ecf2 0.17 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4-&gt;eab3fce2a-df45-43e8-9b62-89ce28ff3320 0.17 ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4-&gt;ea8b69327-9b41-4ca2-90b3-b6c8a50b04d4 0.17"},{"location":"implemented-techniques/discovery-soft/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Online Soft Conformance Checking: Any Perspective Can Indicate Deviations A. Burattin In arXiv:2201.09222, Jan. 2022.</li> </ul>"},{"location":"implemented-techniques/discovery-splitminer/","title":"Discovery with Split Miner","text":""},{"location":"implemented-techniques/discovery-splitminer/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;discovery-splitminer&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the introduction page for further instructions.</p> <p></p>"},{"location":"implemented-techniques/discovery-splitminer/#usage","title":"Usage","text":"<p>This miner can be used to extract a BPMN process model in a similar way as performed by the Split Miner.</p> <p>Once a <code>XesSource</code> is available, the miner can be configured and used as follows:</p> <pre><code>LossyCountingBudgetSplitMiner miner = new LossyCountingBudgetSplitMiner(\n    10, // the budget for cases\n    10, // the budget for relations\n    0.01, // concurrency threshold\n    0.01, // the frequency threshold\n    5); // the sliding window size\n\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(new StringTestSource(\"ABCDF\", \"ABCEF\"))\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner)\n    .addSink(new SinkFunction&lt;BPMNTemplateResponse&gt;() {\n        public void invoke(BPMNTemplateResponse value, Context context) throws Exception {\n            PaliaLikeBPMNDiagramGenerator.fromBPMNTemplate(\n                \"process\",\n                value.getBpmnTemplate(),\n                \"output.svg\");\n        }\n    });\nenv.execute();\n</code></pre> <p>This code will produce the following model:</p> G e53a1df30-9705-4b08-b0a8-3263f4319ccc-&gt;e19ab2931-dc04-48da-bc8b-a6445506d5c4 e19ab2931-dc04-48da-bc8b-a6445506d5c4-&gt;e808aba30-b5eb-469b-b542-d5a27f4588b7 e808aba30-b5eb-469b-b542-d5a27f4588b7-&gt;eeab80efd-180c-4fe1-8e69-9934b9ea0b09 ee7b841cb-464c-419a-8bae-3f806f9ec5c9-&gt;e6ae57bba-eded-484d-af11-a5a1989a71ee eeab80efd-180c-4fe1-8e69-9934b9ea0b09-&gt;ea1411cd2-ee63-41c7-a2dc-1c7840253baa e808e2a5f-5092-4189-90b5-8395b10cce91-&gt;ebc3567e8-38c0-4f5e-ae50-e43c49309c44 eaf32a996-30c2-4603-b9ef-ae197503fc9b-&gt;ebc3567e8-38c0-4f5e-ae50-e43c49309c44 ea1411cd2-ee63-41c7-a2dc-1c7840253baa-&gt;e808e2a5f-5092-4189-90b5-8395b10cce91 ea1411cd2-ee63-41c7-a2dc-1c7840253baa-&gt;eaf32a996-30c2-4603-b9ef-ae197503fc9b ebc3567e8-38c0-4f5e-ae50-e43c49309c44-&gt;ee7b841cb-464c-419a-8bae-3f806f9ec5c9 e53a1df30-9705-4b08-b0a8-3263f4319ccc e19ab2931-dc04-48da-bc8b-a6445506d5c4 A e808aba30-b5eb-469b-b542-d5a27f4588b7 B ee7b841cb-464c-419a-8bae-3f806f9ec5c9 F eeab80efd-180c-4fe1-8e69-9934b9ea0b09 C e808e2a5f-5092-4189-90b5-8395b10cce91 E eaf32a996-30c2-4603-b9ef-ae197503fc9b D ea1411cd2-ee63-41c7-a2dc-1c7840253baa \u00d7 ebc3567e8-38c0-4f5e-ae50-e43c49309c44 \u00d7 e6ae57bba-eded-484d-af11-a5a1989a71ee"},{"location":"implemented-techniques/discovery-splitminer/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Split Miner process discovery technique in streaming process mining environments A. Jarmolkowicz Master Thesis, DTU, Jun. 2023.</li> </ul> <p>The Split Miner algorithm is presented in:</p> <ul> <li>Split miner: automated discovery of accurate and simple business process models from event logs Augusto, A., Conforti, R., Dumas, M. et al.  In Knowledge and Information Systems 59, 251-284 (2019)</li> </ul>"},{"location":"implemented-techniques/discovery-trivial/","title":"Trivial Miner","text":""},{"location":"implemented-techniques/discovery-trivial/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;discovery-trivial&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the introduction page for further instructions.</p> <p></p>"},{"location":"implemented-techniques/discovery-trivial/#usage","title":"Usage","text":"<p>This miner extracts just a dependency map leveraging the directly follows relations observed in the stream. Once a <code>XesSource</code> is available, the miner can be configured and used as follows:</p> <pre><code>DirectlyFollowsDependencyDiscoveryMiner miner = new DirectlyFollowsDependencyDiscoveryMiner();\nminer.setModelRefreshRate(1); // configure how ofter the mining algorithm should emit a new model\nminer.setMinDependency(0.8); // configure the dependency threshold\n\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(new StringTestSource(\"ABCDF\", \"ABCEF\"))\n    .keyBy(BEvent::getProcessName)\n    .flatMap(miner)\n    .addSink(new SinkFunction&lt;ProcessMap&gt;(){\n        public void invoke(ProcessMap value, Context context) throws Exception {\n            value.generateDot().exportToSvg(new File(\"output.svg\"));\n        };\n    });\nenv.execute();\n</code></pre>"},{"location":"implemented-techniques/discovery-trivial/#scientific-literature","title":"Scientific literature","text":"<p>The techniques implemented in this package are described in:</p> <ul> <li>Process Mining Techniques in Business Environments A. Burattin Springer, 2015.</li> </ul>"},{"location":"implemented-techniques/simulation-plg/","title":"Simulation with PLG","text":""},{"location":"implemented-techniques/simulation-plg/#dependency","title":"Dependency","text":"<p>To use these algorithms in your Java Maven project it is necessary to include, in the <code>pom.xml</code> file, the dependency: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.beamline&lt;/groupId&gt;\n    &lt;artifactId&gt;simulation-plg&lt;/artifactId&gt;\n    &lt;version&gt;master-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> See the introduction page for further instructions.</p> <p></p>"},{"location":"implemented-techniques/simulation-plg/#usage","title":"Usage","text":"<p>This wrapper of the PLG library allows the generation of random processes as well as their simulation. Processes can also be imported and exported. The following snipped of code generates a random process and streams it:</p> <pre><code>Process p = new Process(\"\");\nProcessGenerator.randomizeProcess(p, RandomizationConfiguration.BASIC_VALUES);\n\nLogGenerator logGenerator = new LogGenerator(p, new SimulationConfiguration(100), new ProgressAdapter());\nXLog log = logGenerator.generateLog();\n\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv\n    .addSource(new XesLogSource(log))\n    .keyBy(BEvent::getProcessName)\n    .print();\nenv.execute();\n</code></pre>"},{"location":"implemented-techniques/simulation-plg/#scientific-literature","title":"Scientific literature","text":"<p>The technique implemented in this package is described in:</p> <ul> <li>PLG2: Multiperspective Process Randomization with Online and Offline Simulations Andrea Burattin In Online Proceedings of the BPM Demo Track 2016; Rio de Janeiro, Brasil; September, 18 2016; CEUR-WS.org 2016.</li> </ul> <p>Other relevant publications:</p> <ul> <li>PLG: a Framework for the Generation of Business Process Models and their Execution Logs Andrea Burattin and Alessandro Sperduti In Proceedings of the 6th International Workshop on Business Process Intelligence (BPI 2010); Stevens Institute of Technology; Hoboken, New Jersey, USA; September 13, 2010. 10.1007/978-3-642-20511-8_20.</li> <li>PLG2: Multiperspective Processes Randomization and Simulation for Online and Offline Settings Andrea Burattin In CoRR abs/1506.08415, Jun. 2015.</li> </ul> <p>Further information are also availalbe at the Wiki of the PLG project.</p>"}]}